{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumo do código cocó\n",
    "\n",
    "### <u>Código que gera os ficheiros para estudo do comportamento da Delta</u>\n",
    "---\n",
    "O objectivo é receber dados da Delta e devolver um conjunto de métricas para prever roturas. Devolve um ficheiro que pode entrar no código 1 para juntar aos dados dos ninjas.\n",
    "\n",
    "---\n",
    "- Inputs\n",
    "\n",
    "> __Dados completos da Delta em pastas de ficheiros__ (de azul a verde)\n",
    "> - Stocks e trânsito, Sellout do dia anterior\n",
    "\n",
    "                    ou\n",
    "\n",
    "> __Ficheiro já completo__ (de vermelho a verde)\n",
    "> - Stocks e trânsito, Sellout do dia anterior\n",
    "\n",
    "- Outputs\n",
    "\n",
    "> __Ficheiro com produtos em causa__ em formato Long\n",
    "\n",
    "> __Métricas novas:__\n",
    "> - Roturas de Stock e Pré-rotura\n",
    "> - Sinal\n",
    "> - Ciclos e Adequação de Stock\n",
    "> - MSA (média de sellouts 10 dias antes)\n",
    "> - STK (Stock disponível + trânsito)\n",
    "> - (Novo) Balanço médio, mediano, liberal e conservador \n",
    "> - (Novo) Dias para a rotura de stock e de prateleira\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 422 ms\n",
      "Wall time: 766 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "\n",
    "def escrever_csv(dfa, nome): \n",
    "    dfa.to_csv(f'D:\\\\B&N Dados\\\\Delta\\\\Stocks\\\\StocksTotal\\\\{nome}.csv', index=False)\n",
    "\n",
    "def escrever_txt(dfa, nome): \n",
    "    dfa.to_csv(f'D:\\\\B&N Dados\\\\Delta\\\\Stocks\\\\StocksTotal\\\\{nome}.txt', index=False, header=False)\n",
    "\n",
    "def escrever_excel(dfa, nome):\n",
    "    dfa.to_excel(f'D:\\\\B&N Dados\\\\Delta\\\\Stocks\\\\StocksTotal\\\\{nome}.xlsx' , index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:red\"><u>Ler Ficheiro Completo</u> </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 18.8 s\n",
      "Wall time: 20.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Ler os ficheiros\n",
    "df_2022 = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Stocks\\\\Stocks2022\\\\Stocks_Delta_2022_Limpo.csv')\n",
    "df_2023 = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Diário\\\\Stocks_Delta_2023_Limpo.csv')\n",
    "\n",
    "# Juntar as bases\n",
    "dataframes = [df_2022, df_2023]\n",
    "df_Fusão = pd.concat(dataframes, ignore_index=True)\n",
    "df_Fusão['DATA']= pd.to_datetime(df_Fusão['DATA'], format='%Y-%m-%d')\n",
    "\n",
    "\n",
    "\n",
    "# # Ficheiro de previsão\n",
    "# df_Prophet = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Forecast\\\\Prophet.csv')\n",
    "# df_Prophet['DATA']= pd.to_datetime(df_Prophet['DATA'], format='%Y-%m-%d')\n",
    "\n",
    "# df_XGBoost = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Forecast\\\\XGBoost.csv')\n",
    "# df_XGBoost['DATA']= pd.to_datetime(df_XGBoost['DATA'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA</th>\n",
       "      <th>EAN</th>\n",
       "      <th>DESC_ARTIGO</th>\n",
       "      <th>STORE</th>\n",
       "      <th>STORE_NAME</th>\n",
       "      <th>INTRANSIT</th>\n",
       "      <th>EXPECTED</th>\n",
       "      <th>PRES_STOCK</th>\n",
       "      <th>STOCK</th>\n",
       "      <th>STOCK_1_Dias_Antes</th>\n",
       "      <th>SELLOUT</th>\n",
       "      <th>SELLOUT_1_Dias_Antes</th>\n",
       "      <th>INTRANSIT_1_Dias_Antes</th>\n",
       "      <th>EXPECTED_1_Dias_Antes</th>\n",
       "      <th>PRES_STOCK_1_Dias_Antes</th>\n",
       "      <th>FLUXO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-23</td>\n",
       "      <td>5600692769695</td>\n",
       "      <td>100% SALICÓRNIA MOIDA 45G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-24</td>\n",
       "      <td>5600692769695</td>\n",
       "      <td>100% SALICÓRNIA MOIDA 45G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>5600692769695</td>\n",
       "      <td>100% SALICÓRNIA MOIDA 45G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>5600692769695</td>\n",
       "      <td>100% SALICÓRNIA MOIDA 45G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-27</td>\n",
       "      <td>5600692769695</td>\n",
       "      <td>100% SALICÓRNIA MOIDA 45G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATA            EAN                DESC_ARTIGO  STORE      STORE_NAME  \\\n",
       "0 2022-03-23  5600692769695  100% SALICÓRNIA MOIDA 45G      1  CNT MATOSINHOS   \n",
       "1 2022-03-24  5600692769695  100% SALICÓRNIA MOIDA 45G      1  CNT MATOSINHOS   \n",
       "2 2022-03-25  5600692769695  100% SALICÓRNIA MOIDA 45G      1  CNT MATOSINHOS   \n",
       "3 2022-03-26  5600692769695  100% SALICÓRNIA MOIDA 45G      1  CNT MATOSINHOS   \n",
       "4 2022-03-27  5600692769695  100% SALICÓRNIA MOIDA 45G      1  CNT MATOSINHOS   \n",
       "\n",
       "   INTRANSIT  EXPECTED  PRES_STOCK  STOCK  STOCK_1_Dias_Antes  SELLOUT  \\\n",
       "0        0.0       0.0        10.0   23.0                23.0      0.0   \n",
       "1        0.0       0.0        10.0   22.0                23.0      1.0   \n",
       "2        0.0       0.0        10.0   22.0                22.0      0.0   \n",
       "3        0.0       0.0        10.0   22.0                22.0      0.0   \n",
       "4        0.0       0.0        10.0   22.0                22.0      0.0   \n",
       "\n",
       "   SELLOUT_1_Dias_Antes  INTRANSIT_1_Dias_Antes  EXPECTED_1_Dias_Antes  \\\n",
       "0                     0                     NaN                    NaN   \n",
       "1                     0                     NaN                    NaN   \n",
       "2                     1                     NaN                    NaN   \n",
       "3                     0                     NaN                    NaN   \n",
       "4                     0                     NaN                    NaN   \n",
       "\n",
       "   PRES_STOCK_1_Dias_Antes FLUXO  \n",
       "0                      NaN   NaN  \n",
       "1                      NaN   NaN  \n",
       "2                      NaN   NaN  \n",
       "3                      NaN   NaN  \n",
       "4                      NaN   NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Fusão.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2023-06-01T00:00:00.000000000', '2023-06-02T00:00:00.000000000',\n",
       "       '2023-06-03T00:00:00.000000000', '2023-06-04T00:00:00.000000000',\n",
       "       '2023-06-05T00:00:00.000000000', '2023-06-06T00:00:00.000000000',\n",
       "       '2023-06-07T00:00:00.000000000', '2023-06-08T00:00:00.000000000',\n",
       "       '2023-06-09T00:00:00.000000000', '2023-06-10T00:00:00.000000000',\n",
       "       '2023-06-11T00:00:00.000000000', '2023-06-12T00:00:00.000000000',\n",
       "       '2023-06-13T00:00:00.000000000', '2023-06-14T00:00:00.000000000',\n",
       "       '2023-06-15T00:00:00.000000000', '2023-06-16T00:00:00.000000000',\n",
       "       '2023-06-17T00:00:00.000000000', '2023-06-18T00:00:00.000000000',\n",
       "       '2023-06-19T00:00:00.000000000', '2023-06-20T00:00:00.000000000',\n",
       "       '2023-06-21T00:00:00.000000000', '2023-06-22T00:00:00.000000000',\n",
       "       '2023-06-23T00:00:00.000000000', '2023-06-24T00:00:00.000000000',\n",
       "       '2023-06-25T00:00:00.000000000', '2023-06-26T00:00:00.000000000',\n",
       "       '2023-06-27T00:00:00.000000000', '2023-06-28T00:00:00.000000000',\n",
       "       '2023-06-29T00:00:00.000000000', '2023-06-30T00:00:00.000000000',\n",
       "       '2023-07-01T00:00:00.000000000', '2023-07-02T00:00:00.000000000',\n",
       "       '2023-07-03T00:00:00.000000000', '2023-07-04T00:00:00.000000000',\n",
       "       '2023-07-05T00:00:00.000000000', '2023-07-06T00:00:00.000000000',\n",
       "       '2023-07-07T00:00:00.000000000', '2023-07-08T00:00:00.000000000',\n",
       "       '2023-07-09T00:00:00.000000000', '2023-07-10T00:00:00.000000000',\n",
       "       '2023-07-11T00:00:00.000000000', '2023-07-12T00:00:00.000000000',\n",
       "       '2023-07-13T00:00:00.000000000', '2023-07-14T00:00:00.000000000',\n",
       "       '2023-07-15T00:00:00.000000000', '2023-07-16T00:00:00.000000000',\n",
       "       '2023-07-17T00:00:00.000000000', '2023-07-18T00:00:00.000000000',\n",
       "       '2023-07-19T00:00:00.000000000', '2023-07-20T00:00:00.000000000',\n",
       "       '2023-07-21T00:00:00.000000000', '2023-07-22T00:00:00.000000000',\n",
       "       '2023-07-23T00:00:00.000000000', '2023-07-24T00:00:00.000000000',\n",
       "       '2023-07-25T00:00:00.000000000', '2023-07-26T00:00:00.000000000',\n",
       "       '2023-07-27T00:00:00.000000000', '2023-07-28T00:00:00.000000000',\n",
       "       '2023-07-29T00:00:00.000000000', '2023-07-30T00:00:00.000000000',\n",
       "       '2023-07-31T00:00:00.000000000', '2023-08-01T00:00:00.000000000',\n",
       "       '2023-08-02T00:00:00.000000000', '2023-08-04T00:00:00.000000000',\n",
       "       '2023-08-05T00:00:00.000000000', '2023-09-22T00:00:00.000000000',\n",
       "       '2023-09-23T00:00:00.000000000', '2023-09-24T00:00:00.000000000',\n",
       "       '2023-09-25T00:00:00.000000000', '2023-09-26T00:00:00.000000000',\n",
       "       '2023-09-27T00:00:00.000000000', '2023-09-28T00:00:00.000000000',\n",
       "       '2023-09-29T00:00:00.000000000', '2023-09-30T00:00:00.000000000',\n",
       "       '2023-10-01T00:00:00.000000000', '2023-10-02T00:00:00.000000000',\n",
       "       '2023-10-03T00:00:00.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Fusão[(df_Fusão.STORE_NAME==\"CNT BRAGA N. ARCADA\") & (df_Fusão.DESC_ARTIGO==\"DOUBLE ESPRESSO GO CHILL DELTA 230ML\") & (df_Fusão.DATA>\"2023-01-03\")].DATA.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red>Opcional:</font> Definir produtos em causa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Produtos específicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clickhouse_connect\n",
    "client = clickhouse_connect.get_client(host='ch.brandsandninjas.com', \n",
    "                                       port=443, \n",
    "                                       username='chninja', \n",
    "                                       password='ku43ueqnB5Q0AYb2C4FsJRTc7qX',\n",
    "                                       database = \"Delta\")\n",
    "\n",
    "#Ler o ficheiro\n",
    "\n",
    "dfClick = client.query_df('SELECT * FROM GoChill4SemFotos2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA</th>\n",
       "      <th>STORE_NAME</th>\n",
       "      <th>FDS</th>\n",
       "      <th>Dia_da_Semana</th>\n",
       "      <th>DESC_ARTIGO</th>\n",
       "      <th>STORE_NAME2</th>\n",
       "      <th>Color</th>\n",
       "      <th>LatLong</th>\n",
       "      <th>Vendedor</th>\n",
       "      <th>STORE</th>\n",
       "      <th>Num_Produtos</th>\n",
       "      <th>Order_FDS</th>\n",
       "      <th>NinjaInfo</th>\n",
       "      <th>Rotura</th>\n",
       "      <th>Rotura_Consecutiva</th>\n",
       "      <th>Percentagem_de_Presenca</th>\n",
       "      <th>Order_Dia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>Continente Modelo Portalegre</td>\n",
       "      <td>9-10 Setembro</td>\n",
       "      <td>Sábado</td>\n",
       "      <td>CAFFELATTE GO CHILL DELTA 230 ML</td>\n",
       "      <td>Continente Modelo Portalegre</td>\n",
       "      <td>Produto Presente</td>\n",
       "      <td>39.2776511 , -7.4317202</td>\n",
       "      <td>Andreia Gonçalves</td>\n",
       "      <td>218.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>Continente Covilhã</td>\n",
       "      <td>9-10 Setembro</td>\n",
       "      <td>Sábado</td>\n",
       "      <td>CAFFELATTE GO CHILL DELTA 230 ML</td>\n",
       "      <td>Continente Covilhã</td>\n",
       "      <td>Produto Presente</td>\n",
       "      <td>40.2713171 , -7.5024285</td>\n",
       "      <td>Bruno Gomes</td>\n",
       "      <td>212.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>Continente Colombo</td>\n",
       "      <td>9-10 Setembro</td>\n",
       "      <td>Sábado</td>\n",
       "      <td>CAFFELATTE GO CHILL DELTA 230 ML</td>\n",
       "      <td>Continente Colombo</td>\n",
       "      <td>Produto em Rotura</td>\n",
       "      <td>38.755174144937996 , -9.189612569714395</td>\n",
       "      <td>Brizida Almeida</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>Continente Leiria</td>\n",
       "      <td>9-10 Setembro</td>\n",
       "      <td>Sábado</td>\n",
       "      <td>CAFFELATTE GO CHILL DELTA 230 ML</td>\n",
       "      <td>Continente Leiria</td>\n",
       "      <td>Produto Presente</td>\n",
       "      <td>39.73288936955392 , -8.82407364242947</td>\n",
       "      <td>Filipa Dias</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>Continente Modelo Portalegre</td>\n",
       "      <td>9-10 Setembro</td>\n",
       "      <td>Sábado</td>\n",
       "      <td>CAPPUCCINO GO CHILL DELTA 230 ML</td>\n",
       "      <td>Continente Modelo Portalegre</td>\n",
       "      <td>Produto Presente</td>\n",
       "      <td>39.2776511 , -7.4317202</td>\n",
       "      <td>Andreia Gonçalves</td>\n",
       "      <td>218.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATA                    STORE_NAME            FDS Dia_da_Semana  \\\n",
       "0 2023-09-09  Continente Modelo Portalegre  9-10 Setembro        Sábado   \n",
       "1 2023-09-09            Continente Covilhã  9-10 Setembro        Sábado   \n",
       "2 2023-09-09            Continente Colombo  9-10 Setembro        Sábado   \n",
       "3 2023-09-09             Continente Leiria  9-10 Setembro        Sábado   \n",
       "4 2023-09-09  Continente Modelo Portalegre  9-10 Setembro        Sábado   \n",
       "\n",
       "                        DESC_ARTIGO                   STORE_NAME2  \\\n",
       "0  CAFFELATTE GO CHILL DELTA 230 ML  Continente Modelo Portalegre   \n",
       "1  CAFFELATTE GO CHILL DELTA 230 ML            Continente Covilhã   \n",
       "2  CAFFELATTE GO CHILL DELTA 230 ML            Continente Colombo   \n",
       "3  CAFFELATTE GO CHILL DELTA 230 ML             Continente Leiria   \n",
       "4  CAPPUCCINO GO CHILL DELTA 230 ML  Continente Modelo Portalegre   \n",
       "\n",
       "               Color                                  LatLong  \\\n",
       "0   Produto Presente                  39.2776511 , -7.4317202   \n",
       "1   Produto Presente                  40.2713171 , -7.5024285   \n",
       "2  Produto em Rotura  38.755174144937996 , -9.189612569714395   \n",
       "3   Produto Presente    39.73288936955392 , -8.82407364242947   \n",
       "4   Produto Presente                  39.2776511 , -7.4317202   \n",
       "\n",
       "            Vendedor  STORE  Num_Produtos  Order_FDS  NinjaInfo  Rotura  \\\n",
       "0  Andreia Gonçalves  218.0           2.0        1.0        1.0     0.0   \n",
       "1        Bruno Gomes  212.0           4.0        1.0        1.0     0.0   \n",
       "2    Brizida Almeida    9.0           1.0        1.0        0.0     1.0   \n",
       "3        Filipa Dias    5.0           4.0        1.0        1.0     0.0   \n",
       "4  Andreia Gonçalves  218.0           2.0        1.0        1.0     0.0   \n",
       "\n",
       "   Rotura_Consecutiva  Percentagem_de_Presenca  Order_Dia  \n",
       "0                 0.0                      0.4        6.0  \n",
       "1                 0.0                      0.8        6.0  \n",
       "2                 0.0                      0.2        6.0  \n",
       "3                 0.0                      0.8        6.0  \n",
       "4                 0.0                      0.4        6.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfClick.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Fazer **dfFinal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "produtos = dfClick.DESC_ARTIGO.unique()\n",
    "lojas = dfClick.STORE_NAME.unique()\n",
    "codlojas = dfClick.STORE.unique()\n",
    "\n",
    "dfFinal = df_Fusão[(df_Fusão[\"DESC_ARTIGO\"].isin(produtos)) & (df_Fusão[\"STORE\"].isin(codlojas))].copy()\n",
    "dfFinal = pd.merge(dfFinal, dfClick[[\"STORE\",\"DATA\",\"DESC_ARTIGO\",\"NinjaInfo\", \"Percentagem_de_Presenca\"]], how=\"outer\", on = [\"STORE\",\"DATA\",\"DESC_ARTIGO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfVendedor=pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Vendedor2.xlsx\", sheet_name = \"Lojas Sonae para o desafio\")\n",
    "dfVendedor = dfVendedor.rename(columns={\"Cód. Loja\":\"STORE\"})\n",
    "\n",
    "# Criar coluna de reposição\n",
    "dfFinal = pd.merge(dfFinal, dfVendedor[[\"STORE\",\"Vendedor\"]], how=\"left\", on = \"STORE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colunas de métricas interessantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - ROTURA\n",
    "> - PRÉ_ROTURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir coluna de rotura (se stock menor ou igual a 0 e existe Linear)\n",
    "\n",
    "dfFinal[\"ROTURA\"] = np.where((dfFinal[\"STOCK\"] <= 0) & (dfFinal[\"PRES_STOCK\"] > 0), 1, 0)\n",
    "dfFinal[\"ROTURA_1_Dias_Antes\"] = np.where((dfFinal[\"STOCK_1_Dias_Antes\"] <= 0) & (dfFinal[\"PRES_STOCK_1_Dias_Antes\"] > 0), 1, 0)\n",
    "\n",
    "\n",
    "# Definir coluna de rotura (se stock menor ou igual a 0)\n",
    "\n",
    "dfFinal[\"PRE_ROTURA\"] = (dfFinal[\"STOCK\"] < dfFinal[\"PRES_STOCK\"]).astype(int)\n",
    "dfFinal[\"PRE_ROTURA_1_Dias_Antes\"] = (dfFinal[\"STOCK_1_Dias_Antes\"] < dfFinal[\"PRES_STOCK_1_Dias_Antes\"]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas 1, 4, 5 e 10 dias antes:\n",
    "\n",
    "- INSTRANSIT\n",
    "- EXPECTED\n",
    "- SELLOUT\n",
    "- CICLOS\n",
    "- Dias para Rotura\n",
    "- Adequação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantos dias antes:\n",
    "\n",
    "diasMet = [1, 4, 5, 10]\n",
    "\n",
    "# Função para colunas de dias anteriores\n",
    "\n",
    "def dias(df, dia, coluna):         #dia é quantos dias antes\n",
    "    a=int(dia)\n",
    "\n",
    "    valores = df.groupby(['DESC_ARTIGO', 'STORE'])[coluna].transform(lambda x: x.shift(a))\n",
    "    valores[:a] = np.nan\n",
    "    \n",
    "    df.loc[:,f'{coluna}_{a}_Dias_Antes'] = valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - STOCK\n",
    "> - SELLOUT\n",
    "> - INTRANSIT\n",
    "> - EXPECTED \n",
    "> - STK\n",
    "> - FORNECIMENTO\n",
    "> - CICLOS\n",
    "> - Adequação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"STK\"] = dfFinal[\"STOCK\"] + dfFinal[\"INTRANSIT\"] + dfFinal[\"EXPECTED\"]\n",
    "dfFinal[\"FORNECIMENTO\"] = dfFinal[\"INTRANSIT\"] + dfFinal[\"EXPECTED\"]\n",
    "dfFinal[\"CICLOS\"] = dfFinal[\"STOCK\"]/dfFinal[\"PRES_STOCK\"]\n",
    "dfFinal[\"Adequacao\"]= np.where(dfFinal[\"CICLOS\"] > 1.1, \"Stock Suficiente\", \n",
    "                      np.where((dfFinal[\"CICLOS\"] <= 1.1) & (dfFinal[\"INTRANSIT\"]+dfFinal[\"EXPECTED\"]+dfFinal[\"STOCK\"]>=dfFinal[\"PRES_STOCK\"]), \"Stock Insuf c Forn Adequado\", \n",
    "                      np.where((dfFinal[\"CICLOS\"] <= 1.1) & (dfFinal[\"INTRANSIT\"]+dfFinal[\"EXPECTED\"]+dfFinal[\"STOCK\"]<dfFinal[\"PRES_STOCK\"]), \"Stock Insuf c Forn Desadequado\", \n",
    "                      \"\")))\n",
    "\n",
    "for i in diasMet:   \n",
    "    dias(dfFinal, i, \"STOCK\")\n",
    "    dias(dfFinal, i, \"SELLOUT\")\n",
    "    dias(dfFinal, i, \"INTRANSIT\")\n",
    "    dias(dfFinal, i, \"EXPECTED\")\n",
    "    dias(dfFinal, i, \"STK\")\n",
    "    dias(dfFinal, i, \"FORNECIMENTO\")\n",
    "    dias(dfFinal, i, \"CICLOS\")\n",
    "    dias(dfFinal, i, \"Adequacao\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - MSA\n",
    ">- Balance: sellout / soma stock disponível mais transito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MSA do dia = média dos sellouts dos 10 dias anteriores ao dia em causa\n",
    "\n",
    "dfFinal[\"MSA10\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes'].transform(lambda x: x.rolling(window=10).mean())\n",
    "dfFinal[\"MSA10Dp\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes'].transform(lambda x: x.rolling(window=10).std())\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"MSA10\")\n",
    "    \n",
    "\n",
    "dfFinal[\"MSA20\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes'].transform(lambda x: x.rolling(window=20).mean())\n",
    "dfFinal[\"MSA20Dp\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes'].transform(lambda x: x.rolling(window=20).std())\n",
    "  \n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"MSA20\")\n",
    "\n",
    "\n",
    "# Balance do dia = razão entre o sellout médio e o stock para o dia actual\n",
    "dfFinal[\"Balance\"] =  dfFinal[\"MSA10\"] / dfFinal[\"STK\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    \n",
    "    \n",
    "    valores = i * dfFinal[\"Balance\"].shift(i)\n",
    "    valores[:i] = np.nan\n",
    "    \n",
    "    dfFinal.loc[:,'%s_%s_Dias_Antes' % (\"Balance\", i)] = valores\n",
    "    \n",
    "dfFinal.loc[dfFinal.STK == 0, \"Balance\"] = 2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colunas de métricas 30, 60, 120 e 180 dias antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "diasMetHist = [30, 60, 120, 180]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- Balance raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Balance_Raw\"] =  dfFinal[\"SELLOUT\"] / dfFinal[\"STK\"]\n",
    "\n",
    "dfFinal[\"Balance_Raw_Count1\"] = np.where(dfFinal[\"Balance_Raw\"] < 0.5, 1, 0)\n",
    "\n",
    "dfFinal[\"Balance_Raw_Count2\"] = np.where(dfFinal[\"Balance_Raw\"] < 0.8, 1, 0)\n",
    "\n",
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Balance_Raw_Count1_{i}\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Balance_Raw_Count1'].transform(lambda x: x.rolling(window=i, min_periods=1).mean())\n",
    "    dfFinal[f\"Percentagem_Balance_Raw_Count2_{i}\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Balance_Raw_Count2'].transform(lambda x: x.rolling(window=i, min_periods=1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Efeito fim de semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfFinal['SELLOUT_fds'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([4,5,6])][\"SELLOUT\"].copy()\n",
    "#dfFinal['SELLOUT_semana'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([0,1,2,3])][\"SELLOUT\"].copy()\n",
    "dfFinal['SELLOUT_fds_1_Dias_Antes'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([5,6,0])][\"SELLOUT_1_Dias_Antes\"].copy()\n",
    "dfFinal['SELLOUT_semana_1_Dias_Antes'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([1,2,3,4])][\"SELLOUT_1_Dias_Antes\"].copy()\n",
    "\n",
    "dfFinal['SELLOUT_fds_Medio'] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())\n",
    "dfFinal['SELLOUT_semana_Medio'] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())\n",
    "\n",
    "\n",
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Efeito_Fds_{i}\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "                                               .transform(lambda x: x.rolling(window=i, min_periods=1).mean())/\n",
    "                                              (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "                                               .transform(lambda x: x.rolling(window=i, min_periods=1).mean())))-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Volatilidade\n",
    "> - Rotura \n",
    "> - Supply\n",
    "> - Percentagem de dias em Stock Borderline\n",
    "> - Percentagem de dias de Linear Incompleto\n",
    "> - Percentagem de dias sem vendas\n",
    "> - Tempo indisponível\n",
    "> - Vendas perdidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sempre que é pedido abastecimento, fazer com que seja 1\n",
    "dfFinal[\"New_Supply\"] = np.where((dfFinal[\"EXPECTED_1_Dias_Antes\"]==0) & (dfFinal[\"EXPECTED\"]>0), 1, 0)\n",
    "dfFinal[\"Percentagem_Stock_Borderline_1_Dias_Antes\"] = np.where(dfFinal[\"STOCK_1_Dias_Antes\"]<0.2*dfFinal[\"PRES_STOCK_1_Dias_Antes\"], 1, 0)\n",
    "dfFinal[\"Percentagem_Linear_Incompleto_1_Dias_Antes\"] = np.where(dfFinal[\"STOCK_1_Dias_Antes\"]<dfFinal[\"PRES_STOCK_1_Dias_Antes\"], 1, 0)\n",
    "dfFinal[\"Sem_Vendas_1_Dias_Antes\"] = np.where(dfFinal[\"SELLOUT_1_Dias_Antes\"] == 0, 1, 0)\n",
    "dfFinal[\"Dias_Indisponivel_1_Dias_Antes\"] = np.where(dfFinal[\"ROTURA_1_Dias_Antes\"]==1, 1, 0)\n",
    "\n",
    "dfFinal['ROTURA_fds_1_Dias_Antes'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([5,6,0])][\"ROTURA_1_Dias_Antes\"].copy()\n",
    "dfFinal['ROTURA_semana_1_Dias_Antes'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([1,2,3,4])][\"ROTURA_1_Dias_Antes\"].copy()\n",
    "\n",
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Volatilidade_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes']\\\n",
    "                                                .transform(lambda x: x.rolling(window=i, min_periods=1).std()) /\n",
    "                                                dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes']\\\n",
    "                                                .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "    \n",
    "    dfFinal[f\"Percentagem_Roturas_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_1_Dias_Antes']\\\n",
    "                                           .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "    \n",
    "    dfFinal[f\"Percentagem_Roturas_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_1_Dias_Antes']\\\n",
    "                                           .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "    \n",
    "    dfFinal[f\"Percentagem_Supply_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['New_Supply']\\\n",
    "                                          .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "\n",
    "    dfFinal[f\"Percentagem_Dias_Stock_Borderline_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Percentagem_Stock_Borderline_1_Dias_Antes']\\\n",
    "                                                         .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "\n",
    "    dfFinal[f\"Percentagem_Dias_Linear_Incompleto_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Percentagem_Linear_Incompleto_1_Dias_Antes']\\\n",
    "                                                          .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "    \n",
    "    dfFinal[f\"Percentagem_Dias_Sem_Vendas_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Sem_Vendas_1_Dias_Antes']\\\n",
    "                                                   .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "    \n",
    "    dfFinal[f\"Percentagem_Dias_Indisponivel_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Dias_Indisponivel_1_Dias_Antes']\\\n",
    "                                                     .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "\n",
    "    dfFinal[f\"Vendas_Perdidas_em_{i}_Dias\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_fds_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).sum())\\\n",
    "                                                  * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).mean())) \\\n",
    "                                                  + \n",
    "                                               (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_semana_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).sum()) \\\n",
    "                                                  * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).mean())))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Tempo médio inter-supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"InterSupply\"] = np.where(dfFinal[\"EXPECTED\"]==0, 1, 0)\n",
    "\n",
    "groups = (dfFinal['InterSupply'] != dfFinal['InterSupply'].shift()).cumsum()\n",
    "result = dfFinal.groupby(groups).agg({'DATA': 'first', 'DESC_ARTIGO': 'first', 'STORE': 'first', 'InterSupply': 'sum'}).reset_index(drop=True)\n",
    "result = result[result['InterSupply'] > 0]\n",
    "\n",
    "dfFinal = dfFinal.drop(columns=['InterSupply'])\n",
    "\n",
    "dfFinal = pd.merge(dfFinal, result, how=\"left\", on=[\"DATA\",\"DESC_ARTIGO\", \"STORE\"])\n",
    "\n",
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_InterSupplyMed_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['InterSupply'].transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=green> Função Contagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# Define a function to calculate weekday and weekend counts\n",
    "def contagem5dias(date):\n",
    "    weekday_count = 0\n",
    "    weekend_count = 0\n",
    "    \n",
    "    for _ in range(5):\n",
    "        if date.weekday() < 4:  # Monday to Thursday\n",
    "            weekday_count += 1\n",
    "        else:  # Friday to Sunday\n",
    "            weekend_count += 1\n",
    "        \n",
    "        date += timedelta(days=1)\n",
    "    \n",
    "    return pd.Series({\"CONTAGEM_SEMANA\": weekday_count, \"CONTAGEM_FIMSEMANA\": weekend_count})\n",
    "\n",
    "\n",
    "# Define a function to calculate weekday and weekend counts\n",
    "def contagem3dias(date):\n",
    "    weekday_count = 0\n",
    "    weekend_count = 0\n",
    "    \n",
    "    for _ in range(3):\n",
    "        if date.weekday() < 4:  # Monday to Thursday\n",
    "            weekday_count += 1\n",
    "        else:  # Friday to Sunday\n",
    "            weekend_count += 1\n",
    "        \n",
    "        date += timedelta(days=1)\n",
    "    \n",
    "    return pd.Series({\"CONTAGEM_SEMANA3\": weekday_count, \"CONTAGEM_FIMSEMANA3\": weekend_count})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Smart 3 dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7.91 s\n",
      "Wall time: 7.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "dfFinal[[\"CONTAGEM_SEMANA3\", \"CONTAGEM_FIMSEMANA3\"]] = dfFinal[\"DATA\"].apply(contagem3dias)\n",
    "dfFinal['CONTAGEM_FIMSEMANA3'] = dfFinal['CONTAGEM_FIMSEMANA3'].shift(-1)\n",
    "dfFinal['CONTAGEM_SEMANA3'] = dfFinal['CONTAGEM_SEMANA3'].shift(-1)\n",
    "\n",
    "dfFinal[\"Balance_Smart3\"] = ((\n",
    "    (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_FIMSEMANA3'])\n",
    "    +\n",
    "    (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_SEMANA3']))\n",
    "     / dfFinal[\"STK\"])\n",
    "\n",
    "dfFinal[\"Balance_Smart3\"] = np.where(dfFinal[\"STK\"]<=0, -1, dfFinal[\"Balance_Smart3\"])\n",
    "dfFinal[\"Balance_Smart_3_Dias_Antes\"] = dfFinal[\"Balance_Smart3\"].shift(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Smart 5 dias antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8.19 s\n",
      "Wall time: 8.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "dfFinal[[\"CONTAGEM_SEMANA\", \"CONTAGEM_FIMSEMANA\"]] = dfFinal[\"DATA\"].apply(contagem5dias)\n",
    "dfFinal['CONTAGEM_FIMSEMANA'] = dfFinal['CONTAGEM_FIMSEMANA'].shift(-1)\n",
    "dfFinal['CONTAGEM_SEMANA'] = dfFinal['CONTAGEM_SEMANA'].shift(-1)\n",
    "\n",
    "\n",
    "dfFinal[\"Balance_Smart\"] = ((\n",
    "    (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_FIMSEMANA'])\n",
    "    +\n",
    "    (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_SEMANA']))\n",
    "     / dfFinal[\"STK\"])\n",
    "\n",
    "dfFinal[\"Balance_Smart\"] = np.where(dfFinal[\"STK\"]<=0, -1, dfFinal[\"Balance_Smart\"])\n",
    "dfFinal[\"Balance_Smart_5_Dias_Antes\"] = dfFinal[\"Balance_Smart\"].shift(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Dias para rotura de Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal = dfFinal.copy()\n",
    "# Dias para a rotura mas com o Sellout médio (móvel) dos últimos 10 dias \n",
    "dfFinal[\"Dias_para_Rotura_Stock\"] = dfFinal[\"STK_1_Dias_Antes\"] / (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_FIMSEMANA'])+(dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_SEMANA'])\n",
    "\n",
    "dfFinal[\"Dias_para_Rotura_Stock_5_Dias_Antes\"] = dfFinal[\"Dias_para_Rotura_Stock\"].shift(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Dias para rotura de Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a métrica: Preslinear / med(Sellouts 10 dias)\n",
    "dfFinal['Dias_Duracao_Linear'] = dfFinal[\"PRES_STOCK\"] / (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_FIMSEMANA'])+(dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_SEMANA'])\n",
    "\n",
    "dfFinal[\"Dias_Duracao_Linear_5_Dias_Antes\"] = dfFinal[\"Dias_Duracao_Linear\"].shift(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Desempenho\n",
    "> - Volatilidade de Sellout\n",
    "> - Sensibilidade\n",
    "> - PS Classificação\n",
    "> - Risco de Rotura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Desempenho_de_Vendas_60\"] = np.where((dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>=0) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]<=0.151), \"Vendas com desempenho satisfatório\",\n",
    "                                     np.where((dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>0.151) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]<=0.317), \"Vendas com desempenho mediano\",\n",
    "                                     np.where((dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>0.317) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]<=0.433), \"Vendas com desempenho insatisfatório\",\n",
    "                                              \"Vendas com desempenho muito insatisfatório\")))\n",
    "\n",
    "\n",
    "                                     #np.where((dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>0.433) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]<=1), \n",
    "\n",
    "dfFinal[\"Volatilidade_SELLOUT\"] = np.where(dfFinal[\"Percentagem_Volatilidade_60\"] > 1.095, \" e com alta volatilidade de sellout.\",\n",
    "                                  np.where(dfFinal[\"Percentagem_Volatilidade_60\"] > 0.91 , \" e com média volatilidade de sellout.\",\n",
    "                                  np.where(dfFinal[\"Percentagem_Volatilidade_60\"] > 0.76 , \" e com baixa volatilidade de sellout.\",\n",
    "                                                                                           \" e com muito baixa volatilidade de sellout.\")))\n",
    "\n",
    "\n",
    "dfFinal[\"Sensibilidade_Rotura\"] = np.where(dfFinal[\"Percentagem_Roturas_60\"]>0.33, \" Produto com muito elevada propensão para rotura\",\n",
    "                                 np.where(dfFinal[\"Percentagem_Roturas_60\"]>0.166666, \" Produto com elevada propensão para rotura\",\n",
    "                                 np.where(dfFinal[\"Percentagem_Roturas_60\"]>0.017, \" Produto com moderada propensão para rotura\",\n",
    "                                 np.where(dfFinal[\"Percentagem_Roturas_60\"]>0, \" Produto com baixa propensão para rotura\",\n",
    "                                 \" Produto com muito baixa ou nula propensão para rotura\"))))\n",
    "\n",
    "dfFinal[\"Order_Sensibilidade_Rotura\"] = np.where(dfFinal[\"Percentagem_Roturas_60\"]>0.33, 5,\n",
    "                                 np.where(dfFinal[\"Percentagem_Roturas_60\"]>0.166666, 4,\n",
    "                                 np.where(dfFinal[\"Percentagem_Roturas_60\"]>0.017, 3,\n",
    "                                 np.where(dfFinal[\"Percentagem_Roturas_60\"]>0, 2,\n",
    "                                 1))))\n",
    "\n",
    "dfFinal[\"PS_Classificacao_60\"] = np.where((dfFinal[\"Percentagem_Dias_Linear_Incompleto_60\"] > 0.51) & (dfFinal[\"Percentagem_Balance_Raw_Count1_60\"]==1) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>0.29), \" e com PS excessivo.\",\n",
    "                              np.where((dfFinal[\"Percentagem_Dias_Linear_Incompleto_60\"] > 0.31) & (dfFinal[\"Percentagem_Balance_Raw_Count1_60\"]==1) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>0.29), \" e com PS moderadamente excessivo.\",\n",
    "                              np.where((dfFinal[\"Percentagem_Dias_Linear_Incompleto_60\"] < 0.07) & (dfFinal[\"Percentagem_Balance_Raw_Count1_60\"]<0.9) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]<0.07), \" e com PS escasso.\", \n",
    "                                                                                                                                                                                                            \" e com PS equilibrado.\")))\n",
    "\n",
    "dfFinal[\"RISCO\"] = np.where((dfFinal.Balance_Smart > 2) & (dfFinal.CICLOS_5_Dias_Antes < 0.2) & (dfFinal.Percentagem_Roturas_120 > 5), 1,\n",
    "                   np.where((dfFinal.Balance_Smart > 1) & (dfFinal.Balance_Smart < 2) & (dfFinal.CICLOS_5_Dias_Antes < 0.6) & (dfFinal.Percentagem_Roturas_120 < 3), 2, 3))\n",
    "\n",
    "dfFinal[\"RISCO_ROTURA\"] = np.where((dfFinal.Balance_Smart >= 12.5) | (dfFinal.Balance_Smart < 0), \" O produto apresenta hoje muito elevada probabilidade de rotura a 5 dias caso não haja fornecimento.\", \n",
    "                          np.where((dfFinal.Balance_Smart >= 1.1) & (dfFinal.Balance_Smart < 12.5), \" O produto apresenta hoje elevada probabilidade de rotura a 5 dias caso não haja fornecimento.\",\n",
    "                          np.where((dfFinal.Balance_Smart >= 0.833) & (dfFinal.Balance_Smart < 1.1), \" O produto apresenta hoje média probabilidade de rotura a 5 dias caso não haja fornecimento.\",\n",
    "                          np.where((dfFinal.Balance_Smart >= 0.087) & (dfFinal.Balance_Smart < 0.833), \" O produto apresenta hoje baixa probabilidade de rotura a 5 dias caso não haja fornecimento.\", \n",
    "                                                                                                         \" O produto apresenta hoje muito baixa ou nula probabilidade de rotura a 5 dias caso não haja fornecimento.\"))))         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Conclusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Conclusao1\"] = dfFinal[\"Desempenho_de_Vendas_60\"] + dfFinal[\"Volatilidade_SELLOUT\"] \n",
    "dfFinal[\"Conclusao2\"] = dfFinal[\"Sensibilidade_Rotura\"] + dfFinal[\"PS_Classificacao_60\"] \n",
    "dfFinal[\"Conclusao3\"] = dfFinal[\"RISCO_ROTURA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escrever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dias certos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"ROTURA\"] = np.where(dfFinal[\"ROTURA\"]==1, \"NÃO\", \"SIM\")\n",
    "# Ficheiro Dia\n",
    "dfEscreverDia = dfFinal[dfFinal.DATA == dfFinal.DATA.unique()[-2]].copy()\n",
    "\n",
    "# Ficheiro Mês\n",
    "dfEscreverMes = dfFinal[dfFinal.DATA.between(dfFinal.DATA.unique()[-31],dfFinal.DATA.unique()[-2])].copy()\n",
    "\n",
    "# Ficheiro 180 dias\n",
    "dfEscrever180 = dfFinal[dfFinal.DATA.between(dfFinal.DATA.unique()[-124],dfFinal.DATA.unique()[-2])].copy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "escrever_csv(dfEscreverDia, \"DataBaseDeltaDia\")\n",
    "escrever_csv(dfEscreverMes, \"DataBaseDeltaMes\")\n",
    "escrever_csv(dfEscrever180, \"DataBaseDelta180Dias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ninjas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorias possíveis\n",
    "mapping = {1: \"Presente com Stock\",\n",
    "           2: \"Ausente com Stock\",\n",
    "           3: \"Presente sem Stock\",\n",
    "           4: \"Ausente sem Stock\",\n",
    "           5: \"Presente sem Registo\",\n",
    "           6: \"Ausente sem Registo\"}\n",
    "\n",
    "# Definir coluna de sinal\n",
    "dfFinal[\"Sinal\"] = np.where((dfFinal[\"STOCK\"] > 0) & (dfFinal[\"NinjaInfo\"] == 1), 1,\n",
    "                     np.where((dfFinal[\"STOCK\"] > 0) & (dfFinal[\"NinjaInfo\"] == 0), 2,\n",
    "                     np.where((dfFinal[\"STOCK\"] <= 0) & (dfFinal[\"NinjaInfo\"] == 1), 3,\n",
    "                     np.where((dfFinal[\"STOCK\"] <= 0) & (dfFinal[\"NinjaInfo\"] == 0), 4,\n",
    "                     np.where((dfFinal[\"STOCK\"].isna()) & (dfFinal[\"NinjaInfo\"] == 1), 5,\n",
    "                     np.where((dfFinal[\"STOCK\"].isna()) & (dfFinal[\"NinjaInfo\"] == 0), 6,\n",
    "                     np.nan))))))\n",
    "\n",
    "# Substituir números pelas expressões escolhidas\n",
    "dfFinal[\"Sinal\"] = dfFinal[\"Sinal\"].map(mapping)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dfNinjas.Sinal.unique()\n",
    "\n",
    "dfNinjas[\"Audit\"] = np.where(dfNinjas.Sinal =='Presente com Stock', \"Produto Presente no Linear e com Stock em Loja\",\n",
    "                    np.where(dfNinjas.Sinal =='Ausente com Stock', \"Produto Ausente no Linear mas com Stock em Loja\",\n",
    "                    np.where(dfNinjas.Sinal =='Presente sem Stock', \"Produto Presente no Linear mas sem Stock em Loja\",\n",
    "                    np.where(dfNinjas.Sinal =='Ausente sem Stock', \"Produto Ausente no Linear e sem Stock em Loja\",         \n",
    "                    \"Sem Registo de Auditoria Prévio\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tempo anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year and month from the 'date' column\n",
    "dfFinal['Ano'] = dfFinal['DATA'].dt.year\n",
    "dfFinal['Ano_Anterior'] = dfFinal['Ano'] + 1\n",
    "dfFinal['Mes'] = dfFinal['DATA'].dt.month\n",
    "\n",
    "# Mês Actual\n",
    "media_mes_actual = dfFinal.groupby(['Ano', 'Mes'])['SELLOUT'].mean().reset_index()\n",
    "media_mes_actual.rename(columns={'SELLOUT': 'Media_Sellout_Mensal'}, inplace=True)\n",
    "\n",
    "# Mês Homólogo\n",
    "media_mes_homologo = dfFinal.groupby(['Ano_Anterior', 'Mes'])['SELLOUT'].mean().reset_index()\n",
    "media_mes_homologo.rename(columns={'SELLOUT': 'Media_Sellout_Mensal_Homologo'}, inplace=True)\n",
    "\n",
    "#drop\n",
    "\n",
    "\n",
    "# Merge the monthly mean back into the original DataFrame\n",
    "dfFinal = dfFinal.merge(media_mes_actual, on=['Ano', 'Mes'], how=\"left\")\n",
    "dfFinal = dfFinal.merge(media_mes_homologo, left_on=['Ano', 'Mes'], right_on=['Ano_Anterior', 'Mes'], how=\"left\")\n",
    "\n",
    "dfFinal = dfFinal.drop(columns = [\"Ano_Anterior_x\", \"Ano_Anterior_y\"])\n",
    "\n",
    "# Calculate the monthly mean for the previous month\n",
    "media_mes_anterior = dfFinal.groupby(['Ano', 'Mes'])['SELLOUT'].mean().shift(1).reset_index()\n",
    "media_mes_anterior.rename(columns={'SELLOUT': 'Media_Sellout_Mensal_Mes_Anterior'}, inplace=True)\n",
    "\n",
    "dfFinal = dfFinal.merge(media_mes_anterior, on=['Ano', 'Mes'], how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clickhouse"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "client.command('DROP TABLE IF EXISTS BaseDeltaMes')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "client.command(\"CREATE TABLE Delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ficheiro Dia\n",
    "dfEscreverDia = dfFinal[dfFinal.DATA == dfFinal.DATA.unique()[-2]].copy()\n",
    "\n",
    "# Ficheiro Mês\n",
    "dfEscreverMes = dfFinal[dfFinal.DATA.between(dfFinal.DATA.unique()[-31],dfFinal.DATA.unique()[-2])].copy()\n",
    "\n",
    "# Ficheiro 120 dias\n",
    "dfEscrever120 = dfFinal[dfFinal.DATA.between(dfFinal.DATA.unique()[-121],dfFinal.DATA.unique()[-2])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clickhouse_connect\n",
    "from clickhouse_driver import Client\n",
    "from unidecode import unidecode\n",
    "\n",
    "client = clickhouse_connect.get_client(host='ch.brandsandninjas.com', \n",
    "                                       port=443, \n",
    "                                       username='chninja', \n",
    "                                       password='ku43ueqnB5Q0AYb2C4FsJRTc7qX',\n",
    "                                       database = 'Delta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estabelecer a base a ser lida\n",
    "\n",
    "for qualbase in range(1,4):\n",
    "\n",
    "    if qualbase == 1:\n",
    "        baseCH = dfEscreverDia.copy()\n",
    "        tabela = \"Delta_Dia\" # BaseGoChillDia\n",
    "\n",
    "    elif qualbase == 2:\n",
    "        baseCH = dfEscreverMes.copy()\n",
    "        baseCH.NinjaInfo = baseCH.NinjaInfo.fillna(-1)\n",
    "\n",
    "        tabela = \"Delta_Mes\" # BaseGoChillMes\n",
    "\n",
    "    elif qualbase == 3:\n",
    "        baseCH = dfEscrever120.copy()\n",
    "        tabela = \"Delta_120dias\" # BaseDelta120\n",
    "\n",
    "    elif qualbase == 4:\n",
    "        baseCH = dfNinjas.copy()\n",
    "        tabela = \"Delta_Audit\" # BaseDeltaNinja\n",
    "\n",
    "    ## Algumas alterações\n",
    "    baseCH['DATA']= pd.to_datetime(baseCH['DATA'], format='%Y-%m-%d')  # Passar a Data para datetime\n",
    "\n",
    "    baseCH.columns = [unidecode(col) for col in baseCH.columns]        # Tirar acentos e afins dos nomes das colunas porque \n",
    "                                                                       # o Clickhouse não gosta\n",
    "\n",
    "\n",
    "    ## Listas para definir os tipos de dados de cada coluna a inserit\n",
    "    data = [\"DATA\"]\n",
    "    texto = [col for col in baseCH.columns if baseCH[col].dtype == 'object']\n",
    "    inteiros = [col for col in baseCH.columns if baseCH[col].dtype == 'int64' or baseCH[col].dtype == 'int32']\n",
    "    floats = [col for col in baseCH.columns if baseCH[col].dtype == 'float64']\n",
    "\n",
    "\n",
    "    ## Mudar inteiros para floats porque senão não pode haver missing values\n",
    "    for col_name in inteiros:\n",
    "        baseCH[col_name] = baseCH[col_name].astype(float)\n",
    "\n",
    "    ## Missing values em strings também estragam tudo\n",
    "    baseCH[texto] = baseCH[texto].fillna(\"-\")\n",
    "    baseCH[texto] = baseCH[texto].astype(str)\n",
    "\n",
    "    #Função que vai fazer a schema\n",
    "    def schema(lista, tipo):\n",
    "        result_list = [f\"{element} {tipo}\" for element in lista]\n",
    "        return result_list\n",
    "\n",
    "    # Schema a ser feito\n",
    "    data1 = schema(data, \"Date\")\n",
    "    texto1 = schema(texto, \"String\")\n",
    "    inteiros1 = schema(inteiros, \"Float64\")\n",
    "    floats1 = schema(floats, \"Float64\")\n",
    "    total = tuple(data1 + texto1 + inteiros1 + floats1)\n",
    "    schema = ', '.join([column.replace(\"'\", \"\") for column in total])\n",
    "\n",
    "    # Split the input string by commas\n",
    "    parts = schema.split(', ')\n",
    "    # Process each part and wrap the first word in double quotes\n",
    "    output_parts = []\n",
    "    for part in parts:\n",
    "        words = part.split()\n",
    "        if words:\n",
    "            first_word = words[0]\n",
    "            remaining_words = ' '.join(words[1:])\n",
    "            output_part = f'\"{first_word}\" {remaining_words}'\n",
    "            output_parts.append(output_part)\n",
    "    # Join the modified parts back into a string\n",
    "    schema = ', '.join(output_parts)\n",
    "\n",
    "    # Eliminar tabela que possa existir no CH com o mesmo nome\n",
    "    client.command(f'DROP TABLE IF EXISTS {tabela}')\n",
    "\n",
    "    # Criar tabela no CH\n",
    "    client.command(f'''\n",
    "        CREATE TABLE IF NOT EXISTS {tabela} (\n",
    "            {schema}\n",
    "            ) ENGINE = MergeTree\n",
    "            ORDER BY (DATA)\n",
    "    ''')\n",
    "\n",
    "\n",
    "    # Exportar os dados para o clickhouse\n",
    "    client.insert_df(tabela, baseCH, column_names=baseCH.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análises"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Teste\n",
    "colunas = dfFinal.filter(like='Percentagem_Supply_').columns.tolist()\n",
    "\n",
    "dfFinal[dfFinal.STORE==2][[\"DATA\", \"DESC_ARTIGO\",\"STORE\",\"New_Supply\"]+colunas[0:1]].head(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Estudos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(2022)\n",
    "for i in range (1,13):\n",
    "    \n",
    "    print(f\"Mês {i}: \",dfFinal[(dfFinal.ROTURA==\"SIM\") & (dfFinal.DATA.dt.year==2022) & (dfFinal.DATA.dt.month==i)].shape[0])\n",
    "print(2023)  \n",
    "for i in range (1,13):\n",
    "    print(f\"Mês {i}: \",dfFinal[(dfFinal.ROTURA==\"SIM\") & (dfFinal.DATA.dt.year==2023) & (dfFinal.DATA.dt.month==i)].shape[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "baseCH[(baseCH.STORE_NAME==\"CNT BRAGA N. ARCADA\") & (baseCH.DESC_ARTIGO==\"DOUBLE ESPRESSO GO CHILL DELTA 230ML\")][[\"DATA\", \"STORE_NAME\", \"Balance\", \"SELLOUT\", \"STK\", \"STOCK\", \"ROTURA\", \"NinjaInfo\"]].head(20)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "colunas = dfEscrever180.columns.tolist()[0:18]\n",
    "#colunas = ['DATA','EAN','DESC_ARTIGO','STORE',...]\n",
    "#colunas"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Definir base que queremos estudar\n",
    "\n",
    "baseFiltrada = dfEscreverDia.copy()\n",
    "\n",
    "# Correr\n",
    "\n",
    "from ipywidgets import interact, widgets\n",
    "@interact\n",
    "def filtrar_produto(\n",
    "    produto=widgets.Dropdown(options=list(baseFiltrada.DESC_ARTIGO.unique())),\n",
    "    loja=widgets.Dropdown(options=list(baseFiltrada.STORE_NAME.unique())),\n",
    "    rotura=widgets.SelectionSlider(\n",
    "        options=[\"NÃO\", \"SIM\"],\n",
    "        value=\"NÃO\",  # Set an initial value to \"NO\"\n",
    "        description=\"Rotura\"\n",
    "    )\n",
    "):\n",
    "    \n",
    "    filtered_df = baseFiltrada[\n",
    "        (baseFiltrada.DESC_ARTIGO == produto) &\n",
    "        (baseFiltrada.STORE_NAME == loja) &\n",
    "        (baseFiltrada.ROTURA == rotura)\n",
    "    ].head(7)\n",
    "    \n",
    "    return filtered_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
