{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumo do código\n",
    "\n",
    "### <u>Código que gera os ficheiros para estudo do comportamento da Delta</u>\n",
    "---\n",
    "O objectivo é receber dados da Delta e devolver um conjunto de métricas para prever roturas. Devolve um ficheiro que pode entrar no código 1 para juntar aos dados dos ninjas.\n",
    "\n",
    "---\n",
    "- Inputs\n",
    "\n",
    "> __Dados completos da Delta em pastas de ficheiros__ (de azul a verde)\n",
    "> - Stocks e trânsito, Sellout do dia anterior\n",
    "\n",
    "                    ou\n",
    "\n",
    "> __Ficheiro já completo__ (de vermelho a verde)\n",
    "> - Stocks e trânsito, Sellout do dia anterior\n",
    "\n",
    "- Outputs\n",
    "\n",
    "> __Ficheiro com produtos em causa__ em formato Long\n",
    "\n",
    "> __Métricas novas:__\n",
    "> - Roturas de Stock e Pré-rotura\n",
    "> - Sinal\n",
    "> - Ciclos e Adequação de Stock\n",
    "> - MSA (média de sellouts 10 dias antes)\n",
    "> - STK (Stock disponível + trânsito)\n",
    "> - (Novo) Balanço médio, mediano, liberal e conservador \n",
    "> - (Novo) Dias para a rotura de stock e de prateleira\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 13 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import clickhouse_connect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:Blue\">Juntar Ficheiros</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importar do Clickhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clickhouse_connect\n",
    "client = clickhouse_connect.get_client(host='ch.brandsandninjas.com', \n",
    "                                       port=443, \n",
    "                                       username='chninja', \n",
    "                                       password='ku43ueqnB5Q0AYb2C4FsJRTc7qX',\n",
    "                                       database = \"Delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ler o ficheiro\n",
    "\n",
    "dfClick = client.query_df('SELECT * FROM BaseDelta180')\n",
    "\n",
    "dfClick = dfClick[dfClick.DATA != dfClick.DATA.unique()[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importar ficheiros novos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNovo = pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Diário\\\\dia_actual.xlsb\") #xlsx\n",
    "\n",
    "\n",
    "dfNovo = dfNovo[['DATA', 'EAN', 'DESC_ARTIGO', 'STORE', \"STORE_NAME\", \n",
    "                         \"SOH\", \"INTRANSIT\", \"EXPECTED\", \"PRES_STOCK\", \"VND (D-1)\"]]\n",
    "\n",
    "# Renomear colunas e criar as do dia\n",
    "\n",
    "dfNovo = dfNovo.rename(columns={\"VND (D-1)\": \"SELLOUT_1_Dias_Antes\", \n",
    "                                \"SOH\": \"STOCK_1_Dias_Antes\",\n",
    "                                \"INTRANSIT\": \"INTRANSIT_1_Dias_Antes\", \n",
    "                                \"EXPECTED\": \"EXPECTED_1_Dias_Antes\", \n",
    "                                \"PRES_STOCK\": \"PRES_STOCK_1_Dias_Antes\"})\n",
    "\n",
    "dfNovo[\"SELLOUT_1_Dias_Antes\"] = np.where(dfNovo[\"SELLOUT_1_Dias_Antes\"]<0, 0, dfNovo[\"SELLOUT_1_Dias_Antes\"])\n",
    "dfNovo['SELLOUT'] = dfNovo.groupby([\"STORE\",\"EAN\"])['SELLOUT_1_Dias_Antes'].shift(-1)\n",
    "dfNovo['STOCK'] = dfNovo.groupby([\"STORE\",\"EAN\"])['STOCK_1_Dias_Antes'].shift(-1)\n",
    "dfNovo['INTRANSIT'] = dfNovo.groupby([\"STORE\",\"EAN\"])['INTRANSIT_1_Dias_Antes'].shift(-1)\n",
    "dfNovo['EXPECTED'] = dfNovo.groupby([\"STORE\",\"EAN\"])['EXPECTED_1_Dias_Antes'].shift(-1)\n",
    "dfNovo['PRES_STOCK'] = dfNovo.groupby([\"STORE\",\"EAN\"])['PRES_STOCK_1_Dias_Antes'].shift(-1)\n",
    "\n",
    "#DATETIME\n",
    "# se xlsx\n",
    "#dfNovo['DATA'] = pd.to_datetime(dfNovo['DATA'], format='%d-%m-%Y') \n",
    "\n",
    "# se xlsb\n",
    "dfNovo['DATA'] = pd.to_datetime(dfNovo['DATA'], unit='d', origin=datetime.datetime(1899, 12, 30)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clickhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ler o ficheiro\n",
    "\n",
    "dfNovo = client.query_df('SELECT * FROM BaseDeltaSonae')\n",
    "\n",
    "dfNovo = dfNovo[['DATA', 'EAN', 'DESC_ARTIGO', 'STORE', \"STORE_NAME\", \n",
    "                         \"SOH\", \"INTRANSIT\", \"EXPECTED\", \"PRES_STOCK\", \"VND (D-1)\"]]\n",
    "\n",
    "# Renomear colunas e criar as do dia\n",
    "\n",
    "dfNovo = dfNovo.rename(columns={\"VND (D-1)\": \"SELLOUT_1_Dias_Antes\", \n",
    "                                \"SOH\": \"STOCK_1_Dias_Antes\",\n",
    "                                \"INTRANSIT\": \"INTRANSIT_1_Dias_Antes\", \n",
    "                                \"EXPECTED\": \"EXPECTED_1_Dias_Antes\", \n",
    "                                \"PRES_STOCK\": \"PRES_STOCK_1_Dias_Antes\"})\n",
    "\n",
    "dfNovo[\"SELLOUT_1_Dias_Antes\"] = np.where(dfNovo[\"SELLOUT_1_Dias_Antes\"]<0, 0, dfNovo[\"SELLOUT_1_Dias_Antes\"])\n",
    "dfNovo['SELLOUT'] = dfNovo.groupby([\"STORE\",\"EAN\"])['SELLOUT_1_Dias_Antes'].shift(-1)\n",
    "dfNovo['STOCK'] = dfNovo.groupby([\"STORE\",\"EAN\"])['STOCK_1_Dias_Antes'].shift(-1)\n",
    "dfNovo['INTRANSIT'] = dfNovo.groupby([\"STORE\",\"EAN\"])['INTRANSIT_1_Dias_Antes'].shift(-1)\n",
    "dfNovo['EXPECTED'] = dfNovo.groupby([\"STORE\",\"EAN\"])['EXPECTED_1_Dias_Antes'].shift(-1)\n",
    "dfNovo['PRES_STOCK'] = dfNovo.groupby([\"STORE\",\"EAN\"])['PRES_STOCK_1_Dias_Antes'].shift(-1)\n",
    "\n",
    "#DATETIME\n",
    "# se xlsx\n",
    "#dfNovo['DATA'] = pd.to_datetime(dfNovo['DATA'], format='%d-%m-%Y') \n",
    "\n",
    "# se xlsb\n",
    "dfNovo['DATA'] = pd.to_datetime(dfNovo['DATA'], unit='d', origin=datetime.datetime(1899, 12, 30)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Produtos específicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Passar produtos e lojas para listas\n",
    "\n",
    "produtos = dfClick.DESC_ARTIGO.unique().tolist()\n",
    "lojas = dfClick.STORE.unique().tolist()\n",
    "\n",
    "# Alterar o dataframe para apenas incluir os produtos e lojas em causa\n",
    "\n",
    "dfNovo = dfNovo[(dfNovo[\"DESC_ARTIGO\"].isin(produtos)) & (dfNovo[\"STORE\"].isin(lojas))].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Juntar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDiario = pd.concat([dfClick, dfNovo], ignore_index=True, join='outer')\n",
    "\n",
    "dfFinal = dfDiario.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vendedores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfVendedor=pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Vendedor2.xlsx\", sheet_name = \"Lojas Sonae para o desafio\")\n",
    "dfVendedor = dfVendedor.rename(columns={\"Cód. Loja\":\"STORE\"})\n",
    "\n",
    "dfFinal = dfFinal.drop(columns=\"Vendedor\")\n",
    "\n",
    "# Criar coluna de reposição\n",
    "dfFinal = pd.merge(dfFinal, dfVendedor[[\"STORE\",\"Vendedor\"]], how=\"left\", on = \"STORE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=green>Ficheiro Lido<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colunas de métricas interessantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - ROTURA\n",
    "> - PRÉ_ROTURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir coluna de rotura (se stock menor ou igual a 0 e existe Linear)\n",
    "\n",
    "dfFinal[\"ROTURA\"] = np.where((dfFinal[\"STOCK\"] <= 0) & (dfFinal[\"PRES_STOCK\"] > 0), 1, 0)\n",
    "dfFinal[\"ROTURA_1_Dias_Antes\"] = np.where((dfFinal[\"STOCK_1_Dias_Antes\"] <= 0) & (dfFinal[\"PRES_STOCK_1_Dias_Antes\"] > 0), 1, 0)\n",
    "\n",
    "\n",
    "# Definir coluna de rotura (se stock menor ou igual a 0)\n",
    "\n",
    "dfFinal[\"PRE_ROTURA\"] = (dfFinal[\"STOCK\"] < dfFinal[\"PRES_STOCK\"]).astype(int)\n",
    "dfFinal[\"PRE_ROTURA_1_Dias_Antes\"] = (dfFinal[\"STOCK_1_Dias_Antes\"] < dfFinal[\"PRES_STOCK_1_Dias_Antes\"]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas 1, 4, 5 e 10 dias antes:\n",
    "\n",
    "- INSTRANSIT\n",
    "- EXPECTED\n",
    "- SELLOUT\n",
    "- CICLOS\n",
    "- Dias para Rotura\n",
    "- Adequação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantos dias antes:\n",
    "\n",
    "diasMet = [1, 4, 5, 10]\n",
    "\n",
    "# Função para colunas de dias anteriores\n",
    "\n",
    "def dias(df, dia, coluna):         #dia é quantos dias antes\n",
    "    a=int(dia)\n",
    "\n",
    "    valores = df.groupby(['DESC_ARTIGO', 'STORE'])[coluna].transform(lambda x: x.shift(a))\n",
    "    valores[:a] = np.nan\n",
    "    \n",
    "    df.loc[:,f'{coluna}_{a}_Dias_Antes'] = valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - STOCK\n",
    "> - SELLOUT\n",
    "> - INTRANSIT\n",
    "> - EXPECTED \n",
    "> - STK\n",
    "> - FORNECIMENTO\n",
    "> - CICLOS\n",
    "> - Adequação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"STK\"] = dfFinal[\"STOCK\"] + dfFinal[\"INTRANSIT\"] + dfFinal[\"EXPECTED\"]\n",
    "dfFinal[\"FORNECIMENTO\"] = dfFinal[\"INTRANSIT\"] + dfFinal[\"EXPECTED\"]\n",
    "dfFinal[\"CICLOS\"] = dfFinal[\"STOCK\"]/dfFinal[\"PRES_STOCK\"]\n",
    "dfFinal[\"Adequacao\"]= np.where(dfFinal[\"CICLOS\"] > 1.1, \"Stock Suficiente\", \n",
    "                      np.where((dfFinal[\"CICLOS\"] <= 1.1) & (dfFinal[\"INTRANSIT\"]+dfFinal[\"EXPECTED\"]+dfFinal[\"STOCK\"]>=dfFinal[\"PRES_STOCK\"]), \"Stock Insuf c Forn Adequado\", \n",
    "                      np.where((dfFinal[\"CICLOS\"] <= 1.1) & (dfFinal[\"INTRANSIT\"]+dfFinal[\"EXPECTED\"]+dfFinal[\"STOCK\"]<dfFinal[\"PRES_STOCK\"]), \"Stock Insuf c Forn Desadequado\", \n",
    "                      \"\")))\n",
    "\n",
    "for i in diasMet:   \n",
    "    dias(dfFinal, i, \"STOCK\")\n",
    "    dias(dfFinal, i, \"SELLOUT\")\n",
    "    dias(dfFinal, i, \"INTRANSIT\")\n",
    "    dias(dfFinal, i, \"EXPECTED\")\n",
    "    dias(dfFinal, i, \"STK\")\n",
    "    dias(dfFinal, i, \"FORNECIMENTO\")\n",
    "    dias(dfFinal, i, \"CICLOS\")\n",
    "    dias(dfFinal, i, \"Adequacao\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - MSA\n",
    "> - Balance: sellout / soma stock disponível mais transito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSA do dia = média dos sellouts dos 10 dias anteriores ao dia em causa\n",
    "\n",
    "dfFinal[\"MSA10\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes'].transform(lambda x: x.rolling(window=10).mean())\n",
    "dfFinal[\"MSA10Dp\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes'].transform(lambda x: x.rolling(window=10).std())\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"MSA10\")\n",
    "    \n",
    "\n",
    "dfFinal[\"MSA20\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes'].transform(lambda x: x.rolling(window=20).mean())\n",
    "dfFinal[\"MSA20Dp\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes'].transform(lambda x: x.rolling(window=20).std())\n",
    "  \n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"MSA20\")\n",
    "\n",
    "\n",
    "# Balance do dia = razão entre o sellout médio e o stock para o dia actual\n",
    "dfFinal[\"Balance\"] =  dfFinal[\"MSA10\"] / dfFinal[\"STK\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    \n",
    "    \n",
    "    valores = i * dfFinal[\"Balance\"].shift(i)\n",
    "    valores[:i] = np.nan\n",
    "    \n",
    "    dfFinal.loc[:,'%s_%s_Dias_Antes' % (\"Balance\", i)] = valores\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colunas de métricas 30, 60, 120 e 180 dias antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "diasMetHist = [30, 60, 120, 180]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- Balance raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Balance_Raw\"] =  dfFinal[\"SELLOUT\"] / dfFinal[\"STK\"]\n",
    "\n",
    "dfFinal[\"Balance_Raw_Count1\"] = np.where(dfFinal[\"Balance_Raw\"] < 0.5, 1, 0)\n",
    "\n",
    "dfFinal[\"Balance_Raw_Count2\"] = np.where(dfFinal[\"Balance_Raw\"] < 0.8, 1, 0)\n",
    "\n",
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Balance_Raw_Count1_{i}\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Balance_Raw_Count1'].transform(lambda x: x.rolling(window=i, min_periods=1).mean())\n",
    "    dfFinal[f\"Percentagem_Balance_Raw_Count2_{i}\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Balance_Raw_Count2'].transform(lambda x: x.rolling(window=i, min_periods=1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Efeito fim de semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfFinal['SELLOUT_fds'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([4,5,6])][\"SELLOUT\"].copy()\n",
    "#dfFinal['SELLOUT_semana'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([0,1,2,3])][\"SELLOUT\"].copy()\n",
    "dfFinal['SELLOUT_fds_1_Dias_Antes'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([5,6,0])][\"SELLOUT_1_Dias_Antes\"].copy()\n",
    "dfFinal['SELLOUT_semana_1_Dias_Antes'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([1,2,3,4])][\"SELLOUT_1_Dias_Antes\"].copy()\n",
    "\n",
    "dfFinal['SELLOUT_fds_Medio'] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())\n",
    "dfFinal['SELLOUT_semana_Medio'] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())\n",
    "\n",
    "\n",
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Efeito_Fds_{i}\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "                                               .transform(lambda x: x.rolling(window=i, min_periods=1).mean())/\n",
    "                                              (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "                                               .transform(lambda x: x.rolling(window=i, min_periods=1).mean())))-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Volatilidade\n",
    "> - Rotura \n",
    "> - Supply\n",
    "> - Percentagem de dias em Stock Borderline\n",
    "> - Percentagem de dias de Linear Incompleto\n",
    "> - Percentagem de dias sem vendas\n",
    "> - Tempo indisponível\n",
    "> - Vendas perdidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sempre que é pedido abastecimento, fazer com que seja 1\n",
    "dfFinal[\"New_Supply\"] = np.where((dfFinal[\"EXPECTED_1_Dias_Antes\"]==0) & (dfFinal[\"EXPECTED\"]>0), 1, 0)\n",
    "dfFinal[\"Percentagem_Stock_Borderline_1_Dias_Antes\"] = np.where(dfFinal[\"STOCK_1_Dias_Antes\"]<0.2*dfFinal[\"PRES_STOCK_1_Dias_Antes\"], 1, 0)\n",
    "dfFinal[\"Percentagem_Linear_Incompleto_1_Dias_Antes\"] = np.where(dfFinal[\"STOCK_1_Dias_Antes\"]<dfFinal[\"PRES_STOCK_1_Dias_Antes\"], 1, 0)\n",
    "dfFinal[\"Sem_Vendas_1_Dias_Antes\"] = np.where(dfFinal[\"SELLOUT_1_Dias_Antes\"] == 0, 1, 0)\n",
    "dfFinal[\"Dias_Indisponivel_1_Dias_Antes\"] = np.where(dfFinal[\"ROTURA_1_Dias_Antes\"]==1, 1, 0)\n",
    "\n",
    "dfFinal['ROTURA_fds_1_Dias_Antes'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([5,6,0])][\"ROTURA_1_Dias_Antes\"].copy()\n",
    "dfFinal['ROTURA_semana_1_Dias_Antes'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([1,2,3,4])][\"ROTURA_1_Dias_Antes\"].copy()\n",
    "\n",
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Volatilidade_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes']\\\n",
    "                                                .transform(lambda x: x.rolling(window=i, min_periods=1).std()) /\n",
    "                                                dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes']\\\n",
    "                                                .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "    \n",
    "    dfFinal[f\"Percentagem_Roturas_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_1_Dias_Antes']\\\n",
    "                                           .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "    \n",
    "    dfFinal[f\"Percentagem_Roturas_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_1_Dias_Antes']\\\n",
    "                                           .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "    \n",
    "    dfFinal[f\"Percentagem_Supply_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['New_Supply']\\\n",
    "                                          .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "\n",
    "    dfFinal[f\"Percentagem_Dias_Stock_Borderline_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Percentagem_Stock_Borderline_1_Dias_Antes']\\\n",
    "                                                         .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "\n",
    "    dfFinal[f\"Percentagem_Dias_Linear_Incompleto_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Percentagem_Linear_Incompleto_1_Dias_Antes']\\\n",
    "                                                          .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "    \n",
    "    dfFinal[f\"Percentagem_Dias_Sem_Vendas_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Sem_Vendas_1_Dias_Antes']\\\n",
    "                                                   .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "    \n",
    "    dfFinal[f\"Percentagem_Dias_Indisponivel_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Dias_Indisponivel_1_Dias_Antes']\\\n",
    "                                                     .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "\n",
    "    dfFinal[f\"Vendas_Perdidas_em_{i}_Dias\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_fds_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).sum())\\\n",
    "                                                  * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).mean())) \\\n",
    "                                                  + \n",
    "                                               (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_semana_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).sum()) \\\n",
    "                                                  * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).mean())))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Tempo médio inter-supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"InterSupply\"] = np.where(dfFinal[\"EXPECTED\"]==0, 1, 0)\n",
    "\n",
    "groups = (dfFinal['InterSupply'] != dfFinal['InterSupply'].shift()).cumsum()\n",
    "result = dfFinal.groupby(groups).agg({'DATA': 'first', 'DESC_ARTIGO': 'first', 'STORE': 'first', 'InterSupply': 'sum'}).reset_index(drop=True)\n",
    "result = result[result['InterSupply'] > 0]\n",
    "\n",
    "dfFinal = dfFinal.drop(columns=['InterSupply'])\n",
    "\n",
    "dfFinal = pd.merge(dfFinal, result, how=\"left\", on=[\"DATA\",\"DESC_ARTIGO\", \"STORE\"])\n",
    "\n",
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_InterSupplyMed_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['InterSupply'].transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=green> Função Contagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# Define a function to calculate weekday and weekend counts\n",
    "def contagem5dias(date):\n",
    "    weekday_count = 0\n",
    "    weekend_count = 0\n",
    "    \n",
    "    for _ in range(5):\n",
    "        if date.weekday() < 4:  # Monday to Thursday\n",
    "            weekday_count += 1\n",
    "        else:  # Friday to Sunday\n",
    "            weekend_count += 1\n",
    "        \n",
    "        date += timedelta(days=1)\n",
    "    \n",
    "    return pd.Series({\"CONTAGEM_SEMANA\": weekday_count, \"CONTAGEM_FIMSEMANA\": weekend_count})\n",
    "\n",
    "\n",
    "# Define a function to calculate weekday and weekend counts\n",
    "def contagem3dias(date):\n",
    "    weekday_count = 0\n",
    "    weekend_count = 0\n",
    "    \n",
    "    for _ in range(3):\n",
    "        if date.weekday() < 4:  # Monday to Thursday\n",
    "            weekday_count += 1\n",
    "        else:  # Friday to Sunday\n",
    "            weekend_count += 1\n",
    "        \n",
    "        date += timedelta(days=1)\n",
    "    \n",
    "    return pd.Series({\"CONTAGEM_SEMANA3\": weekday_count, \"CONTAGEM_FIMSEMANA3\": weekend_count})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Smart 3 dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "dfFinal[[\"CONTAGEM_SEMANA3\", \"CONTAGEM_FIMSEMANA3\"]] = dfFinal[\"DATA\"].apply(contagem3dias)\n",
    "dfFinal['CONTAGEM_FIMSEMANA3'] = dfFinal['CONTAGEM_FIMSEMANA3'].shift(-1)\n",
    "dfFinal['CONTAGEM_SEMANA3'] = dfFinal['CONTAGEM_SEMANA3'].shift(-1)\n",
    "\n",
    "dfFinal[\"Balance_Smart3\"] = ((\n",
    "    (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_FIMSEMANA3'])\n",
    "    +\n",
    "    (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_SEMANA3']))\n",
    "     / dfFinal[\"STK\"])\n",
    "\n",
    "dfFinal[\"Balance_Smart3\"] = np.where(dfFinal[\"STK\"]<=0, -1, dfFinal[\"Balance_Smart3\"])\n",
    "dfFinal[\"Balance_Smart_3_Dias_Antes\"] = dfFinal[\"Balance_Smart3\"].shift(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Smart 5 dias antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "dfFinal[[\"CONTAGEM_SEMANA\", \"CONTAGEM_FIMSEMANA\"]] = dfFinal[\"DATA\"].apply(contagem5dias)\n",
    "dfFinal['CONTAGEM_FIMSEMANA'] = dfFinal['CONTAGEM_FIMSEMANA'].shift(-1)\n",
    "dfFinal['CONTAGEM_SEMANA'] = dfFinal['CONTAGEM_SEMANA'].shift(-1)\n",
    "\n",
    "\n",
    "dfFinal[\"Balance_Smart\"] = ((\n",
    "    (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_FIMSEMANA'])\n",
    "    +\n",
    "    (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_SEMANA']))\n",
    "     / dfFinal[\"STK\"])\n",
    "\n",
    "dfFinal[\"Balance_Smart\"] = np.where(dfFinal[\"STK\"]<=0, -1, dfFinal[\"Balance_Smart\"])\n",
    "dfFinal[\"Balance_Smart_5_Dias_Antes\"] = dfFinal[\"Balance_Smart\"].shift(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Dias para rotura de Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal = dfFinal.copy()\n",
    "# Dias para a rotura mas com o Sellout médio (móvel) dos últimos 10 dias \n",
    "dfFinal[\"Dias_para_Rotura_Stock\"] = dfFinal[\"STK_1_Dias_Antes\"] / (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_FIMSEMANA'])+(dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_SEMANA'])\n",
    "\n",
    "dfFinal[\"Dias_para_Rotura_Stock_5_Dias_Antes\"] = dfFinal[\"Dias_para_Rotura_Stock\"].shift(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Dias para rotura de Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a métrica: Preslinear / med(Sellouts 10 dias)\n",
    "dfFinal['Dias_Duracao_Linear'] = dfFinal[\"PRES_STOCK\"] / (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_FIMSEMANA'])+(dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_SEMANA'])\n",
    "\n",
    "dfFinal[\"Dias_Duracao_Linear_5_Dias_Antes\"] = dfFinal[\"Dias_Duracao_Linear\"].shift(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Desempenho\n",
    "> - Volatilidade de Sellout\n",
    "> - Sensibilidade\n",
    "> - PS Classificação\n",
    "> - Risco de Rotura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Desempenho_de_Vendas_60\"] = np.where((dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>=0) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]<=0.151), \"Vendas com desempenho satisfatório\",\n",
    "                                     np.where((dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>0.151) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]<=0.317), \"Vendas com desempenho mediano\",\n",
    "                                     np.where((dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>0.317) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]<=0.433), \"Vendas com desempenho insatisfatório\",\n",
    "                                              \"Vendas com desempenho muito insatisfatório\")))\n",
    "\n",
    "\n",
    "                                     #np.where((dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>0.433) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]<=1), \n",
    "\n",
    "dfFinal[\"Volatilidade_SELLOUT\"] = np.where(dfFinal[\"Percentagem_Volatilidade_60\"] > 1.095, \" e com alta volatilidade de sellout.\",\n",
    "                                  np.where(dfFinal[\"Percentagem_Volatilidade_60\"] > 0.91 , \" e com média volatilidade de sellout.\",\n",
    "                                  np.where(dfFinal[\"Percentagem_Volatilidade_60\"] > 0.76 , \" e com baixa volatilidade de sellout.\",\n",
    "                                                                                           \" e com muito baixa volatilidade de sellout.\")))\n",
    "\n",
    "\n",
    "dfFinal[\"Sensibilidade_Rotura\"] = np.where(dfFinal[\"Percentagem_Roturas_60\"]>0.33, \" Produto com muito elevada propensão para rotura\",\n",
    "                                 np.where(dfFinal[\"Percentagem_Roturas_60\"]>0.166666, \" Produto com elevada propensão para rotura\",\n",
    "                                 np.where(dfFinal[\"Percentagem_Roturas_60\"]>0.017, \" Produto com moderada propensão para rotura\",\n",
    "                                 np.where(dfFinal[\"Percentagem_Roturas_60\"]>0, \" Produto com baixa propensão para rotura\",\n",
    "                                 \" Produto com muito baixa ou nula propensão para rotura\"))))\n",
    "\n",
    "dfFinal[\"PS_Classificacao_60\"] = np.where((dfFinal[\"Percentagem_Dias_Linear_Incompleto_60\"] > 0.51) & (dfFinal[\"Percentagem_Balance_Raw_Count1_60\"]==1) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>0.29), \" e com PS excessivo.\",\n",
    "                              np.where((dfFinal[\"Percentagem_Dias_Linear_Incompleto_60\"] > 0.31) & (dfFinal[\"Percentagem_Balance_Raw_Count1_60\"]==1) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>0.29), \" e com PS moderadamente excessivo.\",\n",
    "                              np.where((dfFinal[\"Percentagem_Dias_Linear_Incompleto_60\"] < 0.07) & (dfFinal[\"Percentagem_Balance_Raw_Count1_60\"]<0.9) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]<0.07), \" e com PS escasso.\", \n",
    "                                                                                                                                                                                                            \" e com PS equilibrado.\")))\n",
    "\n",
    "dfFinal[\"RISCO\"] = np.where((dfFinal.Balance_Smart > 2) & (dfFinal.CICLOS_5_Dias_Antes < 0.2) & (dfFinal.Percentagem_Roturas_120 > 5), 1,\n",
    "                   np.where((dfFinal.Balance_Smart > 1) & (dfFinal.Balance_Smart < 2) & (dfFinal.CICLOS_5_Dias_Antes < 0.6) & (dfFinal.Percentagem_Roturas_120 < 3), 2, 3))\n",
    "\n",
    "dfFinal[\"RISCO_ROTURA\"] = np.where((dfFinal.Balance_Smart >= 12.5) | (dfFinal.Balance_Smart < 0), \" O produto apresenta hoje muito elevada probabilidade de rotura a 5 dias caso não haja fornecimento.\", \n",
    "                          np.where((dfFinal.Balance_Smart >= 1.1) & (dfFinal.Balance_Smart < 12.5), \" O produto apresenta hoje elevada probabilidade de rotura a 5 dias caso não haja fornecimento.\",\n",
    "                          np.where((dfFinal.Balance_Smart >= 0.833) & (dfFinal.Balance_Smart < 1.1), \" O produto apresenta hoje média probabilidade de rotura a 5 dias caso não haja fornecimento.\",\n",
    "                          np.where((dfFinal.Balance_Smart >= 0.087) & (dfFinal.Balance_Smart < 0.833), \" O produto apresenta hoje baixa probabilidade de rotura a 5 dias caso não haja fornecimento.\", \n",
    "                                                                                                         \" O produto apresenta hoje muito baixa ou nula probabilidade de rotura a 5 dias caso não haja fornecimento.\"))))         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Conclusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Conclusao1\"] = dfFinal[\"Desempenho_de_Vendas_60\"] + dfFinal[\"Volatilidade_SELLOUT\"] \n",
    "dfFinal[\"Conclusao2\"] = dfFinal[\"Sensibilidade_Rotura\"] + dfFinal[\"PS_Classificacao_60\"] \n",
    "dfFinal[\"Conclusao3\"] = dfFinal[\"RISCO_ROTURA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>Escrever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dias certos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ficheiro 180 dias\n",
    "dfEscrever120 = dfFinal[dfFinal.DATA.between(dfFinal.DATA.unique()[-121],dfFinal.DATA.unique()[-2])].copy()\n",
    "\n",
    "len(dfFinal.DATA.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Passar para csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "escrever_csv(dfEscreverDia, \"DataBaseDeltaDia\")\n",
    "escrever_csv(dfEscreverMes, \"DataBaseDeltaMes\")\n",
    "escrever_csv(dfEscrever180, \"DataBaseDelta180Dias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clickhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clickhouse_connect\n",
    "from clickhouse_driver import Client\n",
    "from unidecode import unidecode\n",
    "\n",
    "client = clickhouse_connect.get_client(host='ch.brandsandninjas.com', \n",
    "                                       port=443, \n",
    "                                       username='chninja', \n",
    "                                       password='ku43ueqnB5Q0AYb2C4FsJRTc7qX')\n",
    "\n",
    "\n",
    "# Estabelecer a base a ser lida\n",
    "baseCH = dfEscrever120.copy()\n",
    "\n",
    "# Estabelecer a tabela a ser criada\n",
    "tabela = \"Delta_120dias\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<clickhouse_connect.driver.summary.QuerySummary at 0x1c91c51d180>"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "###\n",
    "baseCH['DATA']= pd.to_datetime(baseCH['DATA'], format='%Y-%m-%d')  # Passar para datetime\n",
    "new_columns = [unidecode(col) for col in baseCH.columns]           # Tirar acentos e afins\n",
    "baseCH.columns = new_columns                                       # Aplicar alterações da linha anterior\n",
    "###\n",
    "\n",
    "# Tipos de dados\n",
    "data = [\"DATA\"]\n",
    "texto = [col for col in baseCH.columns if baseCH[col].dtype == 'object']\n",
    "inteiros = [col for col in baseCH.columns if baseCH[col].dtype == 'int64' or baseCH[col].dtype == 'int32']\n",
    "floats = [col for col in baseCH.columns if baseCH[col].dtype == 'float64']\n",
    "\n",
    "\n",
    "# Só floats é que permitem missing values\n",
    "for col_name in inteiros:\n",
    "    baseCH[col_name] = baseCH[col_name].astype(float)\n",
    "# Missing values em strings estragam tudo\n",
    "baseCH[texto] = baseCH[texto].fillna(\"-\")\n",
    "\n",
    "\n",
    "def schema(lista, tipo):\n",
    "    result_list = [f\"{element} {tipo}\" for element in lista]\n",
    "    return result_list\n",
    "\n",
    "data1 = schema(data, \"Date\")\n",
    "texto1 = schema(texto, \"String\")\n",
    "inteiros1 = schema(inteiros, \"Float64\")\n",
    "floats1 = schema(floats, \"Float64\")\n",
    "total = tuple(data1 + texto1 + inteiros1 + floats1)\n",
    "\n",
    "schema = ', '.join([column.replace(\"'\", \"\") for column in total])\n",
    "\n",
    "# Split the input string by commas\n",
    "parts = schema.split(', ')\n",
    "# Process each part and wrap the first word in double quotes\n",
    "output_parts = []\n",
    "for part in parts:\n",
    "    words = part.split()\n",
    "    if words:\n",
    "        first_word = words[0]\n",
    "        remaining_words = ' '.join(words[1:])\n",
    "        output_part = f'\"{first_word}\" {remaining_words}'\n",
    "        output_parts.append(output_part)\n",
    "# Join the modified parts back into a string\n",
    "schema = ', '.join(output_parts)\n",
    "\n",
    "\n",
    "\n",
    "# Eliminar tabela no CH\n",
    "client.command(f'DROP TABLE IF EXISTS {tabela}')\n",
    "\n",
    "# Criar tabela no CH\n",
    "client.command(f'''\n",
    "    CREATE TABLE IF NOT EXISTS {tabela} (\n",
    "        {schema}\n",
    "        ) ENGINE = MergeTree\n",
    "        ORDER BY (DATA)\n",
    "''')\n",
    "\n",
    "client.insert_df(tabela, baseCH, column_names=baseCH.columns.tolist())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  \\"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    \\"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "      \\"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "      /"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    /"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  /"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
