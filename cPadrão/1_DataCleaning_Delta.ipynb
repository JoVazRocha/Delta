{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>DATA Cleaning</center>\n",
    "\n",
    "## <center><u>``Resumo do código``</u></center>\n",
    "\n",
    ">### Entra: 1Ninjas e 2Delta  \n",
    ">### Sai: 1Ninjas_Limpo e 2Delta_Limpo\n",
    "---\n",
    "O objectivo é receber dados dos Ninjas e da Delta e devolver ficheiros prontos para ser trabalhados. \n",
    "\n",
    "Devolve os ficheiros que entram nos códigos 1 e 2.\n",
    "\n",
    "---\n",
    "- Inputs\n",
    "\n",
    "> __Dados dos ninjas__ em formato Wide\n",
    "> - 1's e 0's consoante a presença e ausência do produto, Data e Loja\n",
    "\n",
    "> __Dados da Delta__ em formato Wide\n",
    "> - Stocks e trânsito, Sellout dia anterior\n",
    "\n",
    "- Outputs\n",
    "\n",
    "> **Dados dos Ninjas** limpos\n",
    "\n",
    "> **Dados da Delta** limpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "def escrever_excel(dfa, nome):\n",
    "    dfa.to_excel('D:\\\\B&N Dados\\\\Delta\\\\Padrão\\\\Padrão_06_2023\\\\%s.xlsx' %nome, index=False)\n",
    "    \n",
    "def escrever_txt(dfa, nome):\n",
    "    dfa.to_csv('D:\\\\B&N Dados\\\\Delta\\\\Padrão\\\\Padrão_06_2023\\\\%s.txt' %nome, sep='\\t', index=False, header=False)\n",
    "    \n",
    "def ler_json(ficheiro):\n",
    "    with open('D:\\\\B&N Dados\\\\Delta\\\\%s.json' %ficheiro, 'r') as file:\n",
    "        mapa = json.load(file)\n",
    "    return mapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Ler os dicionários previamente criados para poder usar os códigos de produto e de loja em vez dos nomes '''\n",
    "\n",
    "mapa_produtos = ler_json(\"dicionário_produtos\")\n",
    "mapa_lojas = ler_json(\"dicionário_lojas\")\n",
    "mapa_produtos2 = ler_json(\"dicionário_produtos_23\")\n",
    "\n",
    "mapa_lojas = {int(key): value for key, value in mapa_lojas.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ler e Mudar nomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # `Ninjas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Info Ninja\n",
    "dfNinjas1=pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Padrão\\\\Padrão_06_2023\\\\1_Ninjas1.xlsx\")\n",
    "dfNinjas2=pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Padrão\\\\Padrão_06_2023\\\\1_Ninjas2.xlsx\")\n",
    "dfNinjas3=pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Padrão\\\\Padrão_06_2023\\\\1_Ninjas3.xlsx\")\n",
    "dfNinjas4=pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Padrão\\\\Padrão_06_2023\\\\1_Ninjas4.xlsx\")\n",
    "\n",
    "dataframes=[dfNinjas1,dfNinjas2,dfNinjas3,dfNinjas4]\n",
    "dfNinjas=pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "dfNinjas = dfNinjas.rename(columns={' Data de Resposta': 'DATA', \"Código da loja\":\"STORE\", \"Nome da Loja\":\"Loja\"})\n",
    "\n",
    "# Evitar caracteres especiais quando há um espaço a mais\n",
    "dfNinjas.columns = dfNinjas.columns.str.replace('\\xa0', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Ler o ficheiro long com Stocks e Fornecimento\n",
    "\n",
    "directória = \"D:\\\\B&N Dados\\\\Delta\\\\Padrão\\\\Padrão_06_2023\\\\\"\n",
    "num_bases = 3\n",
    "\n",
    "prefixo = \"1_Ninjas\"\n",
    "extensão = \".xlsx\" #xlsb\n",
    "\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for i in range(1, num_bases + 1):\n",
    "    file_path = f\"{directória}{prefixo}{i}{extensão}\"\n",
    "    df = pd.read_excel(file_path)\n",
    "    dataframes.append(df)\n",
    "    \n",
    "dfNinjas = pd.concat(dataframes, ignore_index=True)\n",
    "dfNinjas = dfNinjas.rename(columns={' Data de Resposta': 'DATA', \"Código da loja\":\"STORE\", \"Nome da Loja\":\"Loja\"})\n",
    "\n",
    "#dfNinjas = dfNinjas.rename(columns=lambda x: mapa_produtos2.get(x, x))\n",
    "\n",
    "\"\"\"Datetime\"\"\"\n",
    "\n",
    "# se xlsx\n",
    "dfNinjas['DATA'] = pd.to_datetime(dfNinjas['DATA'], format='%d-%m-%Y') \n",
    "\n",
    "# se xlsb\n",
    "#dfNinjas['DATA'] = pd.to_datetime(dfNinjas['DATA'], unit='d', origin=datetime.datetime(1899, 12, 30)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lista de produtos e lista de lojas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produtos\n",
    "ficheiro_Produtos = dfNinjas.columns.tolist()\n",
    "df_produtos = pd.DataFrame(ficheiro_Produtos[3:], columns=[\"DESC_ARTIGO\"])\n",
    "#escrever_csv(ficheiroLojas, \"produtos\")\n",
    "\n",
    "# Lojas\n",
    "df_lojas = pd.DataFrame(dfNinjas[\"STORE\"].unique().tolist(), columns=[\"STORE\"])\n",
    "#escrever_csv(ficheiroLojas, \"lojas\")\n",
    "\n",
    "\n",
    "'''Colocar em listas para serem chamáveis'''\n",
    "\n",
    "lojas = df_lojas[\"STORE\"].tolist()\n",
    "produtos = df_produtos[\"DESC_ARTIGO\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #  `Delta`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Ler o ficheiro long com Stocks e Fornecimento\n",
    "#dfDelta1=pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Padrão\\\\Padrão_06_2023\\\\2_Delta1.xlsb\", engine='pyxlsb')\n",
    "#dfDelta2=pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Padrão\\\\Padrão_06_2023\\\\2_Delta2.xlsb\", engine='pyxlsb')\n",
    "#dfDelta3=pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Padrão\\\\Padrão_06_2023\\\\2_Delta3.xlsb\", engine='pyxlsb')\n",
    "#dfDelta4=pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Padrão\\\\Padrão_06_2023\\\\2_Delta4.xlsb\", engine='pyxlsb')\n",
    "\n",
    "#dataframes=[dfDelta1,dfDelta2,dfDelta3,dfDelta4]\n",
    "#dfDelta=pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Datetime\n",
    "#dfDelta['DATA'] = pd.to_datetime(dfDelta['DATA'], format='%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 16.3 s\n",
      "Wall time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Ler o ficheiro long com Stocks e Fornecimento\n",
    "\n",
    "directória = \"D:\\\\B&N Dados\\\\Delta\\\\Padrão\\\\Padrão_06_2023\\\\\"\n",
    "prefixo = \"2_Delta\"\n",
    "extensão = \".xlsb\"\n",
    "num_bases = 3\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for i in range(1, num_bases + 1):\n",
    "    file_path = f\"{directória}{prefixo}{i}{extensão}\"\n",
    "    df = pd.read_excel(file_path)\n",
    "    dataframes.append(df)\n",
    "    \n",
    "dfDelta=pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "\"\"\"Datetime\"\"\"\n",
    "\n",
    "# se xlsx\n",
    "#dfDelta['DATA'] = pd.to_datetime(dfDelta['DATA'], format='%d-%m-%Y') \n",
    "\n",
    "# se xlsb\n",
    "dfDelta['DATA'] = pd.to_datetime(dfDelta['DATA'], unit='d', origin=datetime.datetime(1899, 12, 30)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - **Definir os produtos e lojas em causa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estabelecer o Dataframe mais limitado\n",
    "dfDelta_Spec = dfDelta[dfDelta['STORE'].isin(lojas) & dfDelta['DESC_ARTIGO'].isin(produtos)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - **Limitar os dados apresentados e Renomear colunas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tirar apenas as colunas de interesse \n",
    "dfDelta_Limpo = dfDelta_Spec.loc[:, ['DATA', 'EAN', 'DESC_ARTIGO', 'STORE', \"STORE_NAME\", \n",
    "                         \"SOH\", \"INTRANSIT\", \"EXPECTED\", \"PRES_STOCK\", \"VND (D-1)\"]].copy()\n",
    "\n",
    "# Mudar nomes\n",
    "dfDelta_Limpo = dfDelta_Limpo.rename(columns={\"VND (D-1)\": \"SELLOUT_1_Dias_Antes\", \"SOH\": \"STOCK_1_Dias_Antes\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - **Criar colunas de Stock e Sellout para o próprio dia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizar para atingir os valores relevantes\n",
    "dfDelta_Limpo = dfDelta_Limpo.sort_values(by=[\"STORE\", \"DESC_ARTIGO\", \"DATA\"])\n",
    "\n",
    "#Agrupar por loja e produto para não haver valores errados \n",
    "dfDelta_Limpo[\"SELLOUT\"] = dfDelta_Limpo.groupby([\"DESC_ARTIGO\",\"STORE\"])[\"SELLOUT_1_Dias_Antes\"].shift(-1)\n",
    "dfDelta_Limpo[\"STOCK\"] = dfDelta_Limpo.groupby([\"DESC_ARTIGO\",\"STORE\"])[\"STOCK_1_Dias_Antes\"].shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - **Retirar os dias que não têm interesse (útltimo dia)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O dia 29 foi utilizado para conseguir dados do dia para stocks e sellouts mas não é dia de missão\n",
    "segunda = dfDelta_Limpo['DATA'].unique()\n",
    "dfDelta_Limpo = dfDelta_Limpo.loc[dfDelta_Limpo['DATA'] < segunda[-1]]  #'2023-05-29'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2023-06-17T00:00:00.000000000', '2023-06-18T00:00:00.000000000'],\n",
       "      dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfDelta_Limpo['DATA'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escrever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Organizar antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0: DATA',\n",
       " '1: EAN',\n",
       " '2: DESC_ARTIGO',\n",
       " '3: STORE',\n",
       " '4: STORE_NAME',\n",
       " '5: STOCK_1_Dias_Antes',\n",
       " '6: INTRANSIT',\n",
       " '7: EXPECTED',\n",
       " '8: PRES_STOCK',\n",
       " '9: SELLOUT_1_Dias_Antes',\n",
       " '10: SELLOUT',\n",
       " '11: STOCK']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_columns = dfDelta_Limpo.columns.tolist()\n",
    "indexed_columns = [f\"{index}: {column}\" for index, column in enumerate(df_columns)]\n",
    "indexed_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DATA',\n",
       " 'EAN',\n",
       " 'DESC_ARTIGO',\n",
       " 'STORE',\n",
       " 'STORE_NAME',\n",
       " 'STOCK',\n",
       " 'INTRANSIT',\n",
       " 'EXPECTED',\n",
       " 'PRES_STOCK',\n",
       " 'SELLOUT']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfDelta_Organizado = dfDelta_Limpo.iloc[:, np.r_[:5,11,6:9,10]]\n",
    "\n",
    "dfOrganizado.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Organizar antes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agora sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "escrever_excel(dfNinjas, \"1_Ninjas_Limpo\")\n",
    "escrever_excel(dfDelta_Organizado, \"2_Delta_Limpo\")\n",
    "\n",
    "escrever_txt(df_lojas, \"lojas\")\n",
    "escrever_txt(df_produtos, \"produtos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
