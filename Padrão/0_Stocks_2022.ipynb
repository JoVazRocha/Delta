{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Delta Dia Alvo Homólogo</center>\n",
    "\n",
    "## <center><u>``Resumo do código``</u></center>\n",
    "\n",
    ">### Entra: Stock_Delta_2022  \n",
    ">### Sai: 2_Delta_2022Id\n",
    "---\n",
    "O objectivo é receber dados dos ficheiros totais da Delta e devolver um ficheiro com os dados dos produtos e das lojas relevantes para o estudo da evolução do padrão de vendas (dias homólogos do ano anterior). \n",
    "\n",
    "Devolve um ficheiro que pode entrar no código 1 para juntar aos dados dos ninjas.\n",
    "\n",
    "---\n",
    "- Inputs\n",
    "\n",
    "> __Dados da Delta 2022__: Lojas e produtos todos\n",
    "> - Todas as métricas possíveis de retirar só dos dados Delta\n",
    "\n",
    "\n",
    "- Outputs\n",
    "\n",
    "> **2_Delta_2022Id**:\n",
    "> - Ficheiro com todas as métricas nas datas homólogas correspondentes aos dias em que ocorreram as missões\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Importar as bibliotecas necessárias e definir funções que serão necessárias'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def escrever_excel(dfa, nome):\n",
    "    dfa.to_excel(f'D:\\\\B&N Dados\\\\Delta\\\\Padrão\\\\Padrão_08_2023\\\\{nome}.xlsx' , index=False)\n",
    "    \n",
    "def escrever_csv(dfa, nome):\n",
    "    dfa.to_csv(f'D:\\\\B&N Dados\\\\Delta\\\\Padrão\\\\Padrão_08_2023\\\\{nome}.csv', index=False)\n",
    "    \n",
    "def escrever_json(dicionario, ficheiro):\n",
    "    with open(f'D:\\\\B&N Dados\\\\Delta\\\\{ficheiro}.json' , 'w') as file:\n",
    "        json.dump(dicionario, file)\n",
    "        \n",
    "# alteração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ler ficheiro com tudo e os específicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 17.7 s\n",
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfTudo=pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Stocks\\\\Stocks2022\\\\Stocks_Delta_2022_Limpo.csv')\n",
    "\n",
    "dfTudo['DATA']= pd.to_datetime(dfTudo['DATA'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criar dicionários para encontrar produtos e lojas a partir dos seus códigos identificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dicionário Produtos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "para_produtos = dfTudo.set_index(dfTudo.columns[1])[dfTudo.columns[2]].to_dict()\n",
    "para_produtos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dicionário Lojas"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "para_lojas = dfTudo.set_index(dfTudo.columns[3])[dfTudo.columns[4]].to_dict()\n",
    "para_lojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Escrever "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#escrever_json(para_produtos, \"dicionário_produtos\")\n",
    "#escrever_json(para_lojas, \"dicionário_lojas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ## Fazer subsets da Base total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Por loja e produto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler ficheiro para dataframe\n",
    "df_produtos = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Padrão\\\\Padrão_08_2023\\\\produtos.txt', header=None)\n",
    "df_lojas = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Padrão\\\\Padrão_08_2023\\\\lojas.txt', header=None)\n",
    "\n",
    "# Passar para uma lista\n",
    "produtos = df_produtos[0].tolist()\n",
    "lojas = df_lojas[0].tolist()\n",
    "\n",
    "dfFinal = dfTudo[dfTudo['STORE'].isin(lojas) & dfTudo['DESC_ARTIGO'].isin(produtos)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Datas homólogas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal=dfFinal.loc[(dfFinal['DATA'] >= '2022-08-19') & (dfFinal['DATA'] <= '2022-08-21')].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__<center>(Se forem dias específicos da semana)</center>__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dfFds = dfFinal[dfFinal['DATA'].dt.weekday.isin([4,5,6])].copy()         #Sexta, Sábado e Domingo\n",
    "dfSemana = dfJuntos[dfJuntos['DATA'].dt.weekday.isin([0,1,2,3])]    #Segunda a Quinta"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Dias em causa (1 fds depois da páscoa)\n",
    "dfFds=dfFds.loc[(dfFds['DATA'] >= '2023-04-14') & (dfFds['DATA'] <= '2023-05-07')].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Criar um **índice** para cada dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dfFinal.copy()\n",
    "\n",
    "# Extract the day and month components from the 'datetime' column\n",
    "df['day'] = pd.to_datetime(df['DATA']).dt.day\n",
    "df['month'] = pd.to_datetime(df['DATA']).dt.month\n",
    "\n",
    "# Create a new column combining day and month\n",
    "df['day_month'] = df['day'].astype(str) + '-' + df['month'].astype(str)\n",
    "\n",
    "# Assign unique IDs to each unique day-month combination\n",
    "df['id'], _ = pd.factorize(df['day_month'])\n",
    "\n",
    "df = df.drop(columns=['day', 'month', 'day_month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temos:\n",
    "- Uma base apenas com os fins de semana em causa com todas as métricas que estavam até agora mais a **Semana**, o **Dia** e o **Id** para poder ser mergido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escrever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "escrever_excel(df, \"2_Delta_2022Id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Média de Stock por loja e produto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1MedSto = dfFdsPiloto.groupby(['STORE_NAME', 'DESC_ARTIGO'])['SOH'].mean().reset_index()\n",
    "file1StdSto = dfFdsPiloto.groupby(['STORE_NAME', 'DESC_ARTIGO'])['SOH'].std().reset_index()\n",
    "\n",
    "stocks1 = pd.merge(file1MedSto, file1StdSto[['STORE_NAME', 'DESC_ARTIGO', 'SOH']], on=['STORE_NAME', 'DESC_ARTIGO'])\n",
    "stocks1 = stocks1.rename(columns={'SOH_x': 'Stock_médio_Fds', 'SOH_y': 'sdSto'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
