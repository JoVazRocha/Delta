{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumo do código\n",
    "\n",
    "### <u>Código que gera os ficheiros para estudo do comportamento da Delta</u>\n",
    "---\n",
    "O objectivo é receber dados da Delta e devolver um conjunto de métricas para prever roturas. Devolve um ficheiro que pode entrar no código 1 para juntar aos dados dos ninjas.\n",
    "\n",
    "---\n",
    "- Inputs\n",
    "\n",
    "> __Dados completos da Delta em pastas de ficheiros__ (de azul a verde)\n",
    "> - Stocks e trânsito, Sellout do dia anterior\n",
    "\n",
    "                    ou\n",
    "\n",
    "> __Ficheiro já completo__ (de vermelho a verde)\n",
    "> - Stocks e trânsito, Sellout do dia anterior\n",
    "\n",
    "- Outputs\n",
    "\n",
    "> __Ficheiro com produtos em causa__ em formato Long\n",
    "\n",
    "> __Métricas novas:__\n",
    "> - Roturas de Stock e Pré-rotura\n",
    "> - Sinal\n",
    "> - Ciclos e Adequação de Stock\n",
    "> - MSA (média de sellouts 10 dias antes)\n",
    "> - STK (Stock disponível + trânsito)\n",
    "> - (Novo) Balanço médio, mediano, liberal e conservador \n",
    "> - (Novo) Dias para a rotura de stock e de prateleira\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 219 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "\n",
    "def escrever_csv(dfa, nome): \n",
    "    dfa.to_csv(f'D:\\\\B&N Dados\\\\Delta\\\\Stocks\\\\StocksTotal\\\\{nome}.csv', index=False)\n",
    "\n",
    "def escrever_txt(dfa, nome): \n",
    "    dfa.to_csv(f'D:\\\\B&N Dados\\\\Delta\\\\Stocks\\\\StocksTotal\\\\{nome}.txt', index=False, header=False)\n",
    "\n",
    "def escrever_excel(dfa, nome):\n",
    "    dfa.to_excel(f'D:\\\\B&N Dados\\\\Delta\\\\Stocks\\\\StocksTotal\\\\{nome}.xlsx' , index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:red\"><u>Ler Ficheiro Completo</u> </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 18.9 s\n",
      "Wall time: 24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Ler os ficheiros\n",
    "df_2022 = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Stocks\\\\Stocks2022\\\\Stocks_Delta_2022_Limpo.csv')\n",
    "df_2023 = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Stocks\\\\Stocks2023\\\\Stocks_Delta_2023_Limpo.csv')\n",
    "\n",
    "# Juntar as bases\n",
    "\n",
    "\n",
    "#df_Fusão = df_2023.copy()\n",
    "df_Fusão = pd.concat([df_2022, df_2023], ignore_index=True)\n",
    "df_Fusão['DATA']= pd.to_datetime(df_Fusão['DATA'], format='%Y-%m-%d')\n",
    "\n",
    "\n",
    "\n",
    "# # Ficheiro de previsão\n",
    "# df_Prophet = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Forecast\\\\Prophet.csv')\n",
    "# df_Prophet['DATA']= pd.to_datetime(df_Prophet['DATA'], format='%Y-%m-%d')\n",
    "\n",
    "# df_XGBoost = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Forecast\\\\XGBoost.csv')\n",
    "# df_XGBoost['DATA']= pd.to_datetime(df_XGBoost['DATA'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red>Opcional:</font> Definir produtos em causa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Produtos específicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clickhouse_connect\n",
    "client = clickhouse_connect.get_client(host='ch.brandsandninjas.com', \n",
    "                                       port=443, \n",
    "                                       username='chninja', \n",
    "                                       password='ku43ueqnB5Q0AYb2C4FsJRTc7qX',\n",
    "                                       database = \"Delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ler o ficheiro\n",
    "\n",
    "dfClick = client.query_df('SELECT * FROM GoChill4SemFotos2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "produtos = dfClick.DESC_ARTIGO.unique()\n",
    "lojas = dfClick.STORE_NAME.unique()\n",
    "codlojas = dfClick.STORE.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal = df_Fusão[(df_Fusão[\"DESC_ARTIGO\"].isin(produtos)) & (df_Fusão[\"STORE\"].isin(codlojas))].copy()\n",
    "dfFinal = pd.merge(dfFinal, dfClick[[\"STORE\",\"DATA\",\"DESC_ARTIGO\",\"NinjaInfo\", \"Order_FDS\"]], how=\"left\", on = [\"STORE\",\"DATA\",\"DESC_ARTIGO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DATA', 'EAN', 'DESC_ARTIGO', 'STORE', 'STORE_NAME', 'INTRANSIT',\n",
       "       'EXPECTED', 'PRES_STOCK', 'STOCK', 'STOCK_1_Dias_Antes', 'SELLOUT',\n",
       "       'SELLOUT_1_Dias_Antes', 'NinjaInfo', 'Order_FDS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFinal.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%%time\n",
    "# Ler ficheiro dos produtos e lojas para dataframe\n",
    "df_produtos = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Piloto\\\\produtos.txt', header=None)\n",
    "df_lojas = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Piloto\\\\lojas.txt', header=None)\n",
    "\n",
    "# Passar para uma lista\n",
    "produtos = df_produtos[0].tolist()\n",
    "lojas = df_lojas[0].tolist()\n",
    "produtos+=[\"CAFÉ DELTA Q MYTHIQ 10CAP\", \"CAFÉ DELTA Q MYTHIQ XL 40CAP\", \"CAFÉ DELTA Q QALIDUS 10CAP\", \"CAFÉ DELTA Q QALIDUS 40CAP\",\n",
    "                'CAFÉ DELTA Q QHARACTER 10CAP','CAFÉ DELTA Q QHARACTER 40CAP','CAFÉ DELTA Q DEQAFEINATUS 10CAP','CAFÉ DELTA Q DEQAFEINATUS XL 40CAP',\n",
    "               'CAFÉ DELTA MOAGEM UNIVERSAL ANGOLA 220G','CAFÉ DELTA MOAGEM UNIVERSAL BRASIL 220G']\n",
    "# Alterar o dataframe para apenas incluir os produtos e lojas em causa\n",
    "dfFinal = df_Fusão[(df_Fusão[\"DESC_ARTIGO\"].isin(produtos)) & (df_Fusão[\"STORE_NAME\"].isin(lojas))].copy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df2 = pd.read_excel('D:\\\\B&N Dados\\\\Delta\\\\\\Book3.xlsx')\n",
    "\n",
    "\n",
    "num_repeats = len(dfFinal) // len(df2) + 1\n",
    "\n",
    "repeated_values = np.tile(df2['FOTO'], num_repeats)[:len(dfFinal)]\n",
    "\n",
    "dfFinal[\"FOTO\"] = repeated_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>Fim</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal['INTRANSIT'] = dfFinal.groupby([\"STORE\",\"EAN\"])['INTRANSIT_1_Dias_Antes'].shift(-1)\n",
    "dfFinal['EXPECTED'] = dfFinal.groupby([\"STORE\",\"EAN\"])['EXPECTED_1_Dias_Antes'].shift(-1)\n",
    "dfFinal['PRES_STOCK'] = dfFinal.groupby([\"STORE\",\"EAN\"])['PRES_STOCK_1_Dias_Antes'].shift(-1)\n",
    "dfFinal[\"SELLOUT\"] = np.where(dfFinal[\"SELLOUT\"]<0, 0, dfFinal[\"SELLOUT\"])\n",
    "dfFinal[\"SELLOUT_1_Dias_Antes\"] = np.where(dfFinal[\"SELLOUT_1_Dias_Antes\"]<0, 0, dfFinal[\"SELLOUT_1_Dias_Antes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fundir o Ficheiro da Delta com a previsão"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "# Prophet\n",
    "dfFinal = pd.merge(dfFinal, df_Prophet[['DATA', 'STORE', 'DESC_ARTIGO', 'Prophet']], how=\"left\", on=['DATA', 'STORE', 'DESC_ARTIGO',] )\n",
    "# XGBoost\n",
    "dfFinal = pd.merge(dfFinal, df_XGBoost[['DATA', 'STORE', 'DESC_ARTIGO', 'XGBoost']], how=\"left\", on=['DATA', 'STORE', 'DESC_ARTIGO',] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vendedores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfVendedor=pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Vendedor2.xlsx\", sheet_name = \"Lojas Sonae para o desafio\")\n",
    "dfVendedor = dfVendedor.rename(columns={\"Cód. Loja\":\"STORE\"})\n",
    "\n",
    "# Criar coluna de reposição\n",
    "dfFinal = pd.merge(dfFinal, dfVendedor[[\"STORE\",\"Vendedor\"]], how=\"left\", on = \"STORE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=green>Ficheiro Lido<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colunas de métricas interessantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - ROTURA\n",
    "> - PRÉ_ROTURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PRES_STOCK_1_Dias_Antes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'PRES_STOCK_1_Dias_Antes'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Definir coluna de rotura (se stock menor ou igual a 0 e existe Linear)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m dfFinal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROTURA\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere((dfFinal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTOCK\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (dfFinal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRES_STOCK\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m dfFinal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROTURA_1_Dias_Antes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere((dfFinal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTOCK_1_Dias_Antes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (\u001b[43mdfFinal\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPRES_STOCK_1_Dias_Antes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Definir coluna de rotura (se stock menor ou igual a 0)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m dfFinal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRE_ROTURA\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (dfFinal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTOCK\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m dfFinal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRES_STOCK\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'PRES_STOCK_1_Dias_Antes'"
     ]
    }
   ],
   "source": [
    "# Definir coluna de rotura (se stock menor ou igual a 0 e existe Linear)\n",
    "\n",
    "dfFinal[\"ROTURA\"] = np.where((dfFinal[\"STOCK\"] <= 0) & (dfFinal[\"PRES_STOCK\"] > 0), 1, 0)\n",
    "dfFinal[\"ROTURA_1_Dias_Antes\"] = np.where((dfFinal[\"STOCK_1_Dias_Antes\"] <= 0) & (dfFinal[\"PRES_STOCK_1_Dias_Antes\"] > 0), 1, 0)\n",
    "\n",
    "\n",
    "# Definir coluna de rotura (se stock menor ou igual a 0)\n",
    "\n",
    "dfFinal[\"PRE_ROTURA\"] = (dfFinal[\"STOCK\"] < dfFinal[\"PRES_STOCK\"]).astype(int)\n",
    "dfFinal[\"PRE_ROTURA_1_Dias_Antes\"] = (dfFinal[\"STOCK_1_Dias_Antes\"] < dfFinal[\"PRES_STOCK_1_Dias_Antes\"]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas 1, 4, 5 e 10 dias antes:\n",
    "\n",
    "- INSTRANSIT\n",
    "- EXPECTED\n",
    "- SELLOUT\n",
    "- CICLOS\n",
    "- Dias para Rotura\n",
    "- Adequação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantos dias antes:\n",
    "\n",
    "diasMet = [1, 4, 5, 10]\n",
    "\n",
    "# Função para colunas de dias anteriores\n",
    "\n",
    "def dias(df, dia, coluna):         #dia é quantos dias antes\n",
    "    a=int(dia)\n",
    "\n",
    "    valores = df.groupby(['DESC_ARTIGO', 'STORE'])[coluna].transform(lambda x: x.shift(a))\n",
    "    valores[:a] = np.nan\n",
    "    \n",
    "    df.loc[:,f'{coluna}_{a}_Dias_Antes'] = valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - STOCK\n",
    "> - SELLOUT\n",
    "> - INTRANSIT\n",
    "> - EXPECTED \n",
    "> - STK\n",
    "> - FORNECIMENTO\n",
    "> - CICLOS\n",
    "> - Adequação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"STK\"] = dfFinal[\"STOCK\"] + dfFinal[\"INTRANSIT\"] + dfFinal[\"EXPECTED\"]\n",
    "dfFinal[\"FORNECIMENTO\"] = dfFinal[\"INTRANSIT\"] + dfFinal[\"EXPECTED\"]\n",
    "dfFinal[\"CICLOS\"] = dfFinal[\"STOCK\"]/dfFinal[\"PRES_STOCK\"]\n",
    "dfFinal[\"Adequacao\"]= np.where(dfFinal[\"CICLOS\"] > 1.1, \"Stock Suficiente\", \n",
    "                      np.where((dfFinal[\"CICLOS\"] <= 1.1) & (dfFinal[\"INTRANSIT\"]+dfFinal[\"EXPECTED\"]+dfFinal[\"STOCK\"]>=dfFinal[\"PRES_STOCK\"]), \"Stock Insuf c Forn Adequado\", \n",
    "                      np.where((dfFinal[\"CICLOS\"] <= 1.1) & (dfFinal[\"INTRANSIT\"]+dfFinal[\"EXPECTED\"]+dfFinal[\"STOCK\"]<dfFinal[\"PRES_STOCK\"]), \"Stock Insuf c Forn Desadequado\", \n",
    "                      \"\")))\n",
    "\n",
    "for i in diasMet:   \n",
    "    dias(dfFinal, i, \"STOCK\")\n",
    "    dias(dfFinal, i, \"SELLOUT\")\n",
    "    dias(dfFinal, i, \"INTRANSIT\")\n",
    "    dias(dfFinal, i, \"EXPECTED\")\n",
    "    dias(dfFinal, i, \"STK\")\n",
    "    dias(dfFinal, i, \"FORNECIMENTO\")\n",
    "    dias(dfFinal, i, \"CICLOS\")\n",
    "    dias(dfFinal, i, \"Adequacao\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - MSA\n",
    ">- Balance: sellout / soma stock disponível mais transito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSA do dia = média dos sellouts dos 10 dias anteriores ao dia em causa\n",
    "\n",
    "dfFinal[\"MSA10\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes'].transform(lambda x: x.rolling(window=10).mean())\n",
    "dfFinal[\"MSA10Dp\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes'].transform(lambda x: x.rolling(window=10).std())\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"MSA10\")\n",
    "    \n",
    "\n",
    "dfFinal[\"MSA20\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes'].transform(lambda x: x.rolling(window=20).mean())\n",
    "dfFinal[\"MSA20Dp\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes'].transform(lambda x: x.rolling(window=20).std())\n",
    "  \n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"MSA20\")\n",
    "\n",
    "\n",
    "# Balance do dia = razão entre o sellout médio e o stock para o dia actual\n",
    "dfFinal[\"Balance\"] =  dfFinal[\"MSA10\"] / dfFinal[\"STK\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    \n",
    "    \n",
    "    valores = i * dfFinal[\"Balance\"].shift(i)\n",
    "    valores[:i] = np.nan\n",
    "    \n",
    "    dfFinal.loc[:,'%s_%s_Dias_Antes' % (\"Balance\", i)] = valores\n",
    "    \n",
    "dfFinal.loc[dfFinal.STK == 0, \"Balance\"] = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> > - Ordenar"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "previsões = 2\n",
    "dfOrg = dfFinal.iloc[:, np.r_[:9, 10, 12, 13, 12+previsões, 13+previsões, 9, \n",
    "                                (23+previsões):(32+previsões), 11, (14+previsões):(23+previsões)]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[f\"{index}: {column}\" for index, column in enumerate(dfOrg.columns.tolist())]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dfFinal = dfFinal.iloc[:, np.r_[:9, 10, 12, 13, 12+previsões, 13+previsões, 9, \n",
    "                                (23+previsões):(32+previsões), 11, (14+previsões):(23+previsões)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colunas de métricas 30, 60, 120 e 180 dias antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "diasMetHist = [30, 60, 120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- Balance raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Balance_Raw\"] =  dfFinal[\"SELLOUT\"] / dfFinal[\"STK\"]\n",
    "\n",
    "dfFinal[\"Balance_Raw_Count1\"] = np.where(dfFinal[\"Balance_Raw\"] < 0.5, 1, 0)\n",
    "\n",
    "dfFinal[\"Balance_Raw_Count2\"] = np.where(dfFinal[\"Balance_Raw\"] < 0.8, 1, 0)\n",
    "\n",
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Balance_Raw_Count1_{i}\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Balance_Raw_Count1'].transform(lambda x: x.rolling(window=i, min_periods=1).mean())\n",
    "    dfFinal[f\"Percentagem_Balance_Raw_Count2_{i}\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Balance_Raw_Count2'].transform(lambda x: x.rolling(window=i, min_periods=1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Efeito fim de semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfFinal['SELLOUT_fds'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([4,5,6])][\"SELLOUT\"].copy()\n",
    "#dfFinal['SELLOUT_semana'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([0,1,2,3])][\"SELLOUT\"].copy()\n",
    "dfFinal['SELLOUT_fds_1_Dias_Antes'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([5,6,0])][\"SELLOUT_1_Dias_Antes\"].copy()\n",
    "dfFinal['SELLOUT_semana_1_Dias_Antes'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([1,2,3,4])][\"SELLOUT_1_Dias_Antes\"].copy()\n",
    "\n",
    "dfFinal['SELLOUT_fds_Medio'] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())\n",
    "dfFinal['SELLOUT_semana_Medio'] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())\n",
    "\n",
    "\n",
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Efeito_Fds_{i}\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "                                               .transform(lambda x: x.rolling(window=i, min_periods=1).mean())/\n",
    "                                              (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "                                               .transform(lambda x: x.rolling(window=i, min_periods=1).mean())))-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Volatilidade\n",
    "> - Rotura \n",
    "> - Supply\n",
    "> - Percentagem de dias em Stock Borderline\n",
    "> - Percentagem de dias de Linear Incompleto\n",
    "> - Percentagem de dias sem vendas\n",
    "> - Tempo indisponível\n",
    "> - Vendas perdidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PRES_STOCK_1_Dias_Antes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'PRES_STOCK_1_Dias_Antes'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Sempre que é pedido abastecimento, fazer com que seja 1\u001b[39;00m\n\u001b[0;32m      2\u001b[0m dfFinal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew_Supply\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere((dfFinal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEXPECTED_1_Dias_Antes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (dfFinal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEXPECTED\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m dfFinal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPercentagem_Stock_Borderline_1_Dias_Antes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(dfFinal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTOCK_1_Dias_Antes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m0.2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mdfFinal\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPRES_STOCK_1_Dias_Antes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m dfFinal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPercentagem_Linear_Incompleto_1_Dias_Antes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(dfFinal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTOCK_1_Dias_Antes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m<\u001b[39mdfFinal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRES_STOCK_1_Dias_Antes\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      5\u001b[0m dfFinal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSem_Vendas_1_Dias_Antes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(dfFinal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELLOUT_1_Dias_Antes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'PRES_STOCK_1_Dias_Antes'"
     ]
    }
   ],
   "source": [
    "# Sempre que é pedido abastecimento, fazer com que seja 1\n",
    "dfFinal[\"New_Supply\"] = np.where((dfFinal[\"EXPECTED_1_Dias_Antes\"]==0) & (dfFinal[\"EXPECTED\"]>0), 1, 0)\n",
    "dfFinal[\"Percentagem_Stock_Borderline_1_Dias_Antes\"] = np.where(dfFinal[\"STOCK_1_Dias_Antes\"]<0.2*dfFinal[\"PRES_STOCK_1_Dias_Antes\"], 1, 0)\n",
    "dfFinal[\"Percentagem_Linear_Incompleto_1_Dias_Antes\"] = np.where(dfFinal[\"STOCK_1_Dias_Antes\"]<dfFinal[\"PRES_STOCK_1_Dias_Antes\"], 1, 0)\n",
    "dfFinal[\"Sem_Vendas_1_Dias_Antes\"] = np.where(dfFinal[\"SELLOUT_1_Dias_Antes\"] == 0, 1, 0)\n",
    "dfFinal[\"Dias_Indisponivel_1_Dias_Antes\"] = np.where(dfFinal[\"ROTURA_1_Dias_Antes\"]==1, 1, 0)\n",
    "\n",
    "dfFinal['ROTURA_fds_1_Dias_Antes'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([5,6,0])][\"ROTURA_1_Dias_Antes\"].copy()\n",
    "dfFinal['ROTURA_semana_1_Dias_Antes'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([1,2,3,4])][\"ROTURA_1_Dias_Antes\"].copy()\n",
    "\n",
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Volatilidade_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes']\\\n",
    "                                                .transform(lambda x: x.rolling(window=i, min_periods=1).std()) /\n",
    "                                                dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes']\\\n",
    "                                                .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "    \n",
    "    dfFinal[f\"Percentagem_Roturas_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_1_Dias_Antes']\\\n",
    "                                           .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "    \n",
    "    dfFinal[f\"Percentagem_Roturas_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_1_Dias_Antes']\\\n",
    "                                           .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "    \n",
    "    dfFinal[f\"Percentagem_Supply_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['New_Supply']\\\n",
    "                                          .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "\n",
    "    dfFinal[f\"Percentagem_Dias_Stock_Borderline_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Percentagem_Stock_Borderline_1_Dias_Antes']\\\n",
    "                                                         .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "\n",
    "    dfFinal[f\"Percentagem_Dias_Linear_Incompleto_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Percentagem_Linear_Incompleto_1_Dias_Antes']\\\n",
    "                                                          .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "    \n",
    "    dfFinal[f\"Percentagem_Dias_Sem_Vendas_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Sem_Vendas_1_Dias_Antes']\\\n",
    "                                                   .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "    \n",
    "    dfFinal[f\"Percentagem_Dias_Indisponivel_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Dias_Indisponivel_1_Dias_Antes']\\\n",
    "                                                     .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "\n",
    "    dfFinal[f\"Vendas_Perdidas_em_{i}_Dias\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_fds_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).sum())\\\n",
    "                                                  * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).median())) \\\n",
    "                                                  + \n",
    "                                               (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_semana_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).sum()) \\\n",
    "                                                  * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).median())))\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Teste\n",
    "colunas = dfFinal.filter(like='Percentagem_Supply_').columns.tolist()\n",
    "\n",
    "dfFinal[dfFinal.STORE==2][[\"DATA\", \"DESC_ARTIGO\",\"STORE\",\"New_Supply\"]+colunas[0:1]].head(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Tempo médio inter-supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"InterSupply\"] = np.where(dfFinal[\"EXPECTED\"]==0, 1, 0)\n",
    "\n",
    "groups = (dfFinal['InterSupply'] != dfFinal['InterSupply'].shift()).cumsum()\n",
    "result = dfFinal.groupby(groups).agg({'DATA': 'first', 'DESC_ARTIGO': 'first', 'STORE': 'first', 'InterSupply': 'sum'}).reset_index(drop=True)\n",
    "result = result[result['InterSupply'] > 0]\n",
    "\n",
    "dfFinal = dfFinal.drop(columns=['InterSupply'])\n",
    "\n",
    "dfFinal = pd.merge(dfFinal, result, how=\"left\", on=[\"DATA\",\"DESC_ARTIGO\", \"STORE\"])\n",
    "\n",
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_InterSupplyMed_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['InterSupply'].transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=green> Função Contagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# Define a function to calculate weekday and weekend counts\n",
    "def contagem5dias(date):\n",
    "    weekday_count = 0\n",
    "    weekend_count = 0\n",
    "    \n",
    "    for _ in range(5):\n",
    "        if date.weekday() < 4:  # Monday to Thursday\n",
    "            weekday_count += 1\n",
    "        else:  # Friday to Sunday\n",
    "            weekend_count += 1\n",
    "        \n",
    "        date += timedelta(days=1)\n",
    "    \n",
    "    return pd.Series({\"CONTAGEM_SEMANA\": weekday_count, \"CONTAGEM_FIMSEMANA\": weekend_count})\n",
    "\n",
    "\n",
    "# Define a function to calculate weekday and weekend counts\n",
    "def contagem3dias(date):\n",
    "    weekday_count = 0\n",
    "    weekend_count = 0\n",
    "    \n",
    "    for _ in range(3):\n",
    "        if date.weekday() < 4:  # Monday to Thursday\n",
    "            weekday_count += 1\n",
    "        else:  # Friday to Sunday\n",
    "            weekend_count += 1\n",
    "        \n",
    "        date += timedelta(days=1)\n",
    "    \n",
    "    return pd.Series({\"CONTAGEM_SEMANA3\": weekday_count, \"CONTAGEM_FIMSEMANA3\": weekend_count})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Smart 3 dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.34 s\n",
      "Wall time: 2.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "dfFinal[[\"CONTAGEM_SEMANA3\", \"CONTAGEM_FIMSEMANA3\"]] = dfFinal[\"DATA\"].apply(contagem3dias)\n",
    "dfFinal['CONTAGEM_FIMSEMANA3'] = dfFinal['CONTAGEM_FIMSEMANA3'].shift(-1)\n",
    "dfFinal['CONTAGEM_SEMANA3'] = dfFinal['CONTAGEM_SEMANA3'].shift(-1)\n",
    "\n",
    "dfFinal[\"Balance_Smart3\"] = ((\n",
    "    (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_FIMSEMANA3'])\n",
    "    +\n",
    "    (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_SEMANA3']))\n",
    "     / dfFinal[\"STK\"])\n",
    "\n",
    "dfFinal[\"Balance_Smart3\"] = np.where(dfFinal[\"STK\"]<=0, -1, dfFinal[\"Balance_Smart3\"])\n",
    "dfFinal[\"Balance_Smart_3_Dias_Antes\"] = dfFinal[\"Balance_Smart3\"].shift(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Smart 5 dias antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.36 s\n",
      "Wall time: 2.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "dfFinal[[\"CONTAGEM_SEMANA\", \"CONTAGEM_FIMSEMANA\"]] = dfFinal[\"DATA\"].apply(contagem5dias)\n",
    "dfFinal['CONTAGEM_FIMSEMANA'] = dfFinal['CONTAGEM_FIMSEMANA'].shift(-1)\n",
    "dfFinal['CONTAGEM_SEMANA'] = dfFinal['CONTAGEM_SEMANA'].shift(-1)\n",
    "\n",
    "\n",
    "dfFinal[\"Balance_Smart\"] = ((\n",
    "    (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_FIMSEMANA'])\n",
    "    +\n",
    "    (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_SEMANA']))\n",
    "     / dfFinal[\"STK\"])\n",
    "\n",
    "dfFinal[\"Balance_Smart\"] = np.where(dfFinal[\"STK\"]<=0, -1, dfFinal[\"Balance_Smart\"])\n",
    "dfFinal[\"Balance_Smart_5_Dias_Antes\"] = dfFinal[\"Balance_Smart\"].shift(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Dias para rotura de Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal = dfFinal.copy()\n",
    "# Dias para a rotura mas com o Sellout médio (móvel) dos últimos 10 dias \n",
    "dfFinal[\"Dias_para_Rotura_Stock\"] = dfFinal[\"STK_1_Dias_Antes\"] / (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_FIMSEMANA'])+(dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_SEMANA'])\n",
    "\n",
    "dfFinal[\"Dias_para_Rotura_Stock_5_Dias_Antes\"] = dfFinal[\"Dias_para_Rotura_Stock\"].shift(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Dias para rotura de Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a métrica: Preslinear / med(Sellouts 10 dias)\n",
    "dfFinal['Dias_Duracao_Linear'] = dfFinal[\"PRES_STOCK\"] / (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_FIMSEMANA'])+(dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_SEMANA'])\n",
    "\n",
    "dfFinal[\"Dias_Duracao_Linear_5_Dias_Antes\"] = dfFinal[\"Dias_Duracao_Linear\"].shift(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Desempenho\n",
    "> - Volatilidade de Sellout\n",
    "> - Sensibilidade\n",
    "> - PS Classificação\n",
    "> - Risco de Rotura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Desempenho_de_Vendas_60\"] = np.where((dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>=0) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]<=0.151), \"Vendas com desempenho satisfatório\",\n",
    "                                     np.where((dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>0.151) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]<=0.317), \"Vendas com desempenho mediano\",\n",
    "                                     np.where((dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>0.317) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]<=0.433), \"Vendas com desempenho insatisfatório\",\n",
    "                                              \"Vendas com desempenho muito insatisfatório\")))\n",
    "\n",
    "\n",
    "                                     #np.where((dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>0.433) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]<=1), \n",
    "\n",
    "dfFinal[\"Volatilidade_SELLOUT\"] = np.where(dfFinal[\"Percentagem_Volatilidade_60\"] > 1.095, \" e com alta volatilidade de sellout.\",\n",
    "                                  np.where(dfFinal[\"Percentagem_Volatilidade_60\"] > 0.91 , \" e com média volatilidade de sellout.\",\n",
    "                                  np.where(dfFinal[\"Percentagem_Volatilidade_60\"] > 0.76 , \" e com baixa volatilidade de sellout.\",\n",
    "                                                                                           \" e com muito baixa volatilidade de sellout.\")))\n",
    "\n",
    "\n",
    "dfFinal[\"Sensibilidade_Rotura\"] = np.where(dfFinal[\"Percentagem_Roturas_60\"]>0.33, \" Produto com muito elevada propensão para rotura\",\n",
    "                                 np.where(dfFinal[\"Percentagem_Roturas_60\"]>0.166666, \" Produto com elevada propensão para rotura\",\n",
    "                                 np.where(dfFinal[\"Percentagem_Roturas_60\"]>0.017, \" Produto com moderada propensão para rotura\",\n",
    "                                 np.where(dfFinal[\"Percentagem_Roturas_60\"]>0, \" Produto com baixa propensão para rotura\",\n",
    "                                 \" Produto com muito baixa ou nula propensão para rotura\"))))\n",
    "\n",
    "dfFinal[\"Order_Sensibilidade_Rotura\"] = np.where(dfFinal[\"Percentagem_Roturas_60\"]>0.33, 5,\n",
    "                                 np.where(dfFinal[\"Percentagem_Roturas_60\"]>0.166666, 4,\n",
    "                                 np.where(dfFinal[\"Percentagem_Roturas_60\"]>0.017, 3,\n",
    "                                 np.where(dfFinal[\"Percentagem_Roturas_60\"]>0, 2,\n",
    "                                 1))))\n",
    "\n",
    "dfFinal[\"PS_Classificacao_60\"] = np.where((dfFinal[\"Percentagem_Dias_Linear_Incompleto_60\"] > 0.51) & (dfFinal[\"Percentagem_Balance_Raw_Count1_60\"]==1) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>0.29), \" e com PS excessivo.\",\n",
    "                              np.where((dfFinal[\"Percentagem_Dias_Linear_Incompleto_60\"] > 0.31) & (dfFinal[\"Percentagem_Balance_Raw_Count1_60\"]==1) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>0.29), \" e com PS moderadamente excessivo.\",\n",
    "                              np.where((dfFinal[\"Percentagem_Dias_Linear_Incompleto_60\"] < 0.07) & (dfFinal[\"Percentagem_Balance_Raw_Count1_60\"]<0.9) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]<0.07), \" e com PS escasso.\", \n",
    "                                                                                                                                                                                                            \" e com PS equilibrado.\")))\n",
    "\n",
    "dfFinal[\"RISCO\"] = np.where((dfFinal.Balance_Smart > 2) & (dfFinal.CICLOS_5_Dias_Antes < 0.2) & (dfFinal.Percentagem_Roturas_120 > 5), 1,\n",
    "                   np.where((dfFinal.Balance_Smart > 1) & (dfFinal.Balance_Smart < 2) & (dfFinal.CICLOS_5_Dias_Antes < 0.6) & (dfFinal.Percentagem_Roturas_120 < 3), 2, 3))\n",
    "\n",
    "dfFinal[\"RISCO_ROTURA\"] = np.where((dfFinal.Balance_Smart >= 12.5) | (dfFinal.Balance_Smart < 0), \" O produto apresenta hoje muito elevada probabilidade de rotura a 5 dias caso não haja fornecimento.\", \n",
    "                          np.where((dfFinal.Balance_Smart >= 1.1) & (dfFinal.Balance_Smart < 12.5), \" O produto apresenta hoje elevada probabilidade de rotura a 5 dias caso não haja fornecimento.\",\n",
    "                          np.where((dfFinal.Balance_Smart >= 0.833) & (dfFinal.Balance_Smart < 1.1), \" O produto apresenta hoje média probabilidade de rotura a 5 dias caso não haja fornecimento.\",\n",
    "                          np.where((dfFinal.Balance_Smart >= 0.087) & (dfFinal.Balance_Smart < 0.833), \" O produto apresenta hoje baixa probabilidade de rotura a 5 dias caso não haja fornecimento.\", \n",
    "                                                                                                         \" O produto apresenta hoje muito baixa ou nula probabilidade de rotura a 5 dias caso não haja fornecimento.\"))))         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Conclusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Conclusao1\"] = dfFinal[\"Desempenho_de_Vendas_60\"] + dfFinal[\"Volatilidade_SELLOUT\"] \n",
    "dfFinal[\"Conclusao2\"] = dfFinal[\"Sensibilidade_Rotura\"] + dfFinal[\"PS_Classificacao_60\"] \n",
    "dfFinal[\"Conclusao3\"] = dfFinal[\"RISCO_ROTURA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escrever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dias certos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2023-06-01 00:00:00'),\n",
       " Timestamp('2023-06-02 00:00:00'),\n",
       " Timestamp('2023-06-03 00:00:00'),\n",
       " Timestamp('2023-06-04 00:00:00'),\n",
       " Timestamp('2023-06-05 00:00:00'),\n",
       " Timestamp('2023-06-06 00:00:00'),\n",
       " Timestamp('2023-06-07 00:00:00'),\n",
       " Timestamp('2023-06-08 00:00:00'),\n",
       " Timestamp('2023-06-09 00:00:00'),\n",
       " Timestamp('2023-06-10 00:00:00'),\n",
       " Timestamp('2023-06-11 00:00:00'),\n",
       " Timestamp('2023-06-12 00:00:00'),\n",
       " Timestamp('2023-06-13 00:00:00'),\n",
       " Timestamp('2023-06-14 00:00:00'),\n",
       " Timestamp('2023-06-15 00:00:00'),\n",
       " Timestamp('2023-06-16 00:00:00'),\n",
       " Timestamp('2023-06-17 00:00:00'),\n",
       " Timestamp('2023-06-18 00:00:00'),\n",
       " Timestamp('2023-06-19 00:00:00'),\n",
       " Timestamp('2023-06-20 00:00:00'),\n",
       " Timestamp('2023-06-21 00:00:00'),\n",
       " Timestamp('2023-06-22 00:00:00'),\n",
       " Timestamp('2023-06-23 00:00:00'),\n",
       " Timestamp('2023-06-24 00:00:00'),\n",
       " Timestamp('2023-06-25 00:00:00'),\n",
       " Timestamp('2023-06-26 00:00:00'),\n",
       " Timestamp('2023-06-27 00:00:00'),\n",
       " Timestamp('2023-06-28 00:00:00'),\n",
       " Timestamp('2023-06-29 00:00:00'),\n",
       " Timestamp('2023-06-30 00:00:00'),\n",
       " Timestamp('2023-07-01 00:00:00'),\n",
       " Timestamp('2023-07-02 00:00:00'),\n",
       " Timestamp('2023-07-03 00:00:00'),\n",
       " Timestamp('2023-07-04 00:00:00'),\n",
       " Timestamp('2023-07-05 00:00:00'),\n",
       " Timestamp('2023-07-06 00:00:00'),\n",
       " Timestamp('2023-07-07 00:00:00'),\n",
       " Timestamp('2023-07-08 00:00:00'),\n",
       " Timestamp('2023-07-09 00:00:00'),\n",
       " Timestamp('2023-07-10 00:00:00'),\n",
       " Timestamp('2023-07-11 00:00:00'),\n",
       " Timestamp('2023-07-12 00:00:00'),\n",
       " Timestamp('2023-07-13 00:00:00'),\n",
       " Timestamp('2023-07-14 00:00:00'),\n",
       " Timestamp('2023-07-15 00:00:00'),\n",
       " Timestamp('2023-07-16 00:00:00'),\n",
       " Timestamp('2023-07-17 00:00:00'),\n",
       " Timestamp('2023-07-18 00:00:00'),\n",
       " Timestamp('2023-07-19 00:00:00'),\n",
       " Timestamp('2023-07-20 00:00:00'),\n",
       " Timestamp('2023-07-21 00:00:00'),\n",
       " Timestamp('2023-07-22 00:00:00'),\n",
       " Timestamp('2023-07-23 00:00:00'),\n",
       " Timestamp('2023-07-24 00:00:00'),\n",
       " Timestamp('2023-07-25 00:00:00'),\n",
       " Timestamp('2023-07-26 00:00:00'),\n",
       " Timestamp('2023-07-27 00:00:00'),\n",
       " Timestamp('2023-07-28 00:00:00'),\n",
       " Timestamp('2023-07-29 00:00:00'),\n",
       " Timestamp('2023-07-30 00:00:00'),\n",
       " Timestamp('2023-07-31 00:00:00'),\n",
       " Timestamp('2023-08-01 00:00:00'),\n",
       " Timestamp('2023-08-02 00:00:00'),\n",
       " Timestamp('2023-08-04 00:00:00'),\n",
       " Timestamp('2023-08-05 00:00:00'),\n",
       " Timestamp('2023-08-06 00:00:00'),\n",
       " Timestamp('2023-08-07 00:00:00'),\n",
       " Timestamp('2023-08-08 00:00:00'),\n",
       " Timestamp('2023-08-09 00:00:00'),\n",
       " Timestamp('2023-08-10 00:00:00'),\n",
       " Timestamp('2023-08-11 00:00:00'),\n",
       " Timestamp('2023-08-12 00:00:00'),\n",
       " Timestamp('2023-08-13 00:00:00'),\n",
       " Timestamp('2023-08-14 00:00:00'),\n",
       " Timestamp('2023-08-15 00:00:00'),\n",
       " Timestamp('2023-08-16 00:00:00'),\n",
       " Timestamp('2023-08-17 00:00:00'),\n",
       " Timestamp('2023-08-18 00:00:00'),\n",
       " Timestamp('2023-08-19 00:00:00'),\n",
       " Timestamp('2023-08-20 00:00:00'),\n",
       " Timestamp('2023-08-21 00:00:00'),\n",
       " Timestamp('2023-08-22 00:00:00'),\n",
       " Timestamp('2023-08-23 00:00:00'),\n",
       " Timestamp('2023-08-24 00:00:00'),\n",
       " Timestamp('2023-08-25 00:00:00'),\n",
       " Timestamp('2023-08-26 00:00:00'),\n",
       " Timestamp('2023-08-27 00:00:00'),\n",
       " Timestamp('2023-08-28 00:00:00'),\n",
       " Timestamp('2023-08-29 00:00:00'),\n",
       " Timestamp('2023-08-30 00:00:00'),\n",
       " Timestamp('2023-08-31 00:00:00'),\n",
       " Timestamp('2023-09-01 00:00:00'),\n",
       " Timestamp('2023-09-02 00:00:00'),\n",
       " Timestamp('2023-09-03 00:00:00'),\n",
       " Timestamp('2023-09-04 00:00:00'),\n",
       " Timestamp('2023-09-05 00:00:00'),\n",
       " Timestamp('2023-09-06 00:00:00'),\n",
       " Timestamp('2023-09-07 00:00:00'),\n",
       " Timestamp('2023-09-08 00:00:00'),\n",
       " Timestamp('2023-09-09 00:00:00'),\n",
       " Timestamp('2023-09-10 00:00:00'),\n",
       " Timestamp('2023-09-11 00:00:00'),\n",
       " Timestamp('2023-09-12 00:00:00'),\n",
       " Timestamp('2023-09-13 00:00:00'),\n",
       " Timestamp('2023-09-14 00:00:00'),\n",
       " Timestamp('2023-09-15 00:00:00'),\n",
       " Timestamp('2023-09-16 00:00:00'),\n",
       " Timestamp('2023-09-17 00:00:00'),\n",
       " Timestamp('2023-09-18 00:00:00'),\n",
       " Timestamp('2023-09-19 00:00:00'),\n",
       " Timestamp('2023-09-20 00:00:00'),\n",
       " Timestamp('2023-09-21 00:00:00'),\n",
       " Timestamp('2023-09-22 00:00:00'),\n",
       " Timestamp('2023-09-23 00:00:00'),\n",
       " Timestamp('2023-09-24 00:00:00'),\n",
       " Timestamp('2023-09-25 00:00:00'),\n",
       " Timestamp('2023-09-26 00:00:00'),\n",
       " Timestamp('2023-09-27 00:00:00'),\n",
       " Timestamp('2023-09-28 00:00:00'),\n",
       " Timestamp('2023-09-29 00:00:00'),\n",
       " Timestamp('2023-09-30 00:00:00'),\n",
       " Timestamp('2023-10-01 00:00:00'),\n",
       " Timestamp('2023-10-02 00:00:00'),\n",
       " Timestamp('2023-10-03 00:00:00'),\n",
       " Timestamp('2023-06-01 00:00:00'),\n",
       " Timestamp('2023-06-02 00:00:00'),\n",
       " Timestamp('2023-06-03 00:00:00'),\n",
       " Timestamp('2023-06-04 00:00:00'),\n",
       " Timestamp('2023-06-05 00:00:00'),\n",
       " Timestamp('2023-06-06 00:00:00'),\n",
       " Timestamp('2023-06-07 00:00:00'),\n",
       " Timestamp('2023-06-08 00:00:00'),\n",
       " Timestamp('2023-06-09 00:00:00'),\n",
       " Timestamp('2023-06-10 00:00:00'),\n",
       " Timestamp('2023-06-11 00:00:00'),\n",
       " Timestamp('2023-06-12 00:00:00'),\n",
       " Timestamp('2023-06-13 00:00:00'),\n",
       " Timestamp('2023-06-14 00:00:00'),\n",
       " Timestamp('2023-06-15 00:00:00'),\n",
       " Timestamp('2023-06-16 00:00:00'),\n",
       " Timestamp('2023-06-17 00:00:00'),\n",
       " Timestamp('2023-06-18 00:00:00'),\n",
       " Timestamp('2023-06-19 00:00:00'),\n",
       " Timestamp('2023-06-20 00:00:00'),\n",
       " Timestamp('2023-06-21 00:00:00'),\n",
       " Timestamp('2023-06-22 00:00:00'),\n",
       " Timestamp('2023-06-23 00:00:00'),\n",
       " Timestamp('2023-06-24 00:00:00'),\n",
       " Timestamp('2023-06-25 00:00:00'),\n",
       " Timestamp('2023-06-26 00:00:00'),\n",
       " Timestamp('2023-06-27 00:00:00'),\n",
       " Timestamp('2023-06-28 00:00:00'),\n",
       " Timestamp('2023-06-29 00:00:00'),\n",
       " Timestamp('2023-06-30 00:00:00'),\n",
       " Timestamp('2023-07-01 00:00:00'),\n",
       " Timestamp('2023-07-02 00:00:00'),\n",
       " Timestamp('2023-07-03 00:00:00'),\n",
       " Timestamp('2023-07-04 00:00:00'),\n",
       " Timestamp('2023-07-05 00:00:00'),\n",
       " Timestamp('2023-07-06 00:00:00'),\n",
       " Timestamp('2023-07-07 00:00:00'),\n",
       " Timestamp('2023-07-08 00:00:00'),\n",
       " Timestamp('2023-07-09 00:00:00'),\n",
       " Timestamp('2023-07-10 00:00:00'),\n",
       " Timestamp('2023-07-11 00:00:00'),\n",
       " Timestamp('2023-07-12 00:00:00'),\n",
       " Timestamp('2023-07-13 00:00:00'),\n",
       " Timestamp('2023-07-14 00:00:00'),\n",
       " Timestamp('2023-07-15 00:00:00'),\n",
       " Timestamp('2023-07-16 00:00:00'),\n",
       " Timestamp('2023-07-17 00:00:00'),\n",
       " Timestamp('2023-07-18 00:00:00'),\n",
       " Timestamp('2023-07-19 00:00:00'),\n",
       " Timestamp('2023-07-20 00:00:00'),\n",
       " Timestamp('2023-07-21 00:00:00'),\n",
       " Timestamp('2023-07-22 00:00:00'),\n",
       " Timestamp('2023-07-23 00:00:00'),\n",
       " Timestamp('2023-07-24 00:00:00'),\n",
       " Timestamp('2023-07-25 00:00:00'),\n",
       " Timestamp('2023-07-26 00:00:00'),\n",
       " Timestamp('2023-07-27 00:00:00'),\n",
       " Timestamp('2023-07-28 00:00:00'),\n",
       " Timestamp('2023-07-29 00:00:00'),\n",
       " Timestamp('2023-07-30 00:00:00'),\n",
       " Timestamp('2023-07-31 00:00:00'),\n",
       " Timestamp('2023-08-01 00:00:00'),\n",
       " Timestamp('2023-08-02 00:00:00'),\n",
       " Timestamp('2023-08-04 00:00:00'),\n",
       " Timestamp('2023-08-05 00:00:00'),\n",
       " Timestamp('2023-08-06 00:00:00'),\n",
       " Timestamp('2023-08-07 00:00:00'),\n",
       " Timestamp('2023-08-08 00:00:00'),\n",
       " Timestamp('2023-08-09 00:00:00'),\n",
       " Timestamp('2023-08-10 00:00:00'),\n",
       " Timestamp('2023-08-11 00:00:00'),\n",
       " Timestamp('2023-08-12 00:00:00'),\n",
       " Timestamp('2023-08-13 00:00:00'),\n",
       " Timestamp('2023-08-14 00:00:00'),\n",
       " Timestamp('2023-08-15 00:00:00'),\n",
       " Timestamp('2023-08-16 00:00:00'),\n",
       " Timestamp('2023-08-17 00:00:00'),\n",
       " Timestamp('2023-08-18 00:00:00'),\n",
       " Timestamp('2023-08-19 00:00:00'),\n",
       " Timestamp('2023-08-20 00:00:00'),\n",
       " Timestamp('2023-08-21 00:00:00'),\n",
       " Timestamp('2023-08-22 00:00:00'),\n",
       " Timestamp('2023-08-23 00:00:00'),\n",
       " Timestamp('2023-08-24 00:00:00'),\n",
       " Timestamp('2023-08-25 00:00:00'),\n",
       " Timestamp('2023-08-26 00:00:00'),\n",
       " Timestamp('2023-08-27 00:00:00'),\n",
       " Timestamp('2023-08-28 00:00:00'),\n",
       " Timestamp('2023-08-29 00:00:00'),\n",
       " Timestamp('2023-08-30 00:00:00'),\n",
       " Timestamp('2023-08-31 00:00:00'),\n",
       " Timestamp('2023-09-01 00:00:00'),\n",
       " Timestamp('2023-09-02 00:00:00'),\n",
       " Timestamp('2023-09-03 00:00:00'),\n",
       " Timestamp('2023-09-04 00:00:00'),\n",
       " Timestamp('2023-09-05 00:00:00'),\n",
       " Timestamp('2023-09-06 00:00:00'),\n",
       " Timestamp('2023-09-07 00:00:00'),\n",
       " Timestamp('2023-09-08 00:00:00'),\n",
       " Timestamp('2023-09-09 00:00:00'),\n",
       " Timestamp('2023-09-10 00:00:00'),\n",
       " Timestamp('2023-09-11 00:00:00'),\n",
       " Timestamp('2023-09-12 00:00:00'),\n",
       " Timestamp('2023-09-13 00:00:00'),\n",
       " Timestamp('2023-09-14 00:00:00'),\n",
       " Timestamp('2023-09-15 00:00:00'),\n",
       " Timestamp('2023-09-16 00:00:00'),\n",
       " Timestamp('2023-09-17 00:00:00'),\n",
       " Timestamp('2023-09-18 00:00:00'),\n",
       " Timestamp('2023-09-19 00:00:00'),\n",
       " Timestamp('2023-09-20 00:00:00'),\n",
       " Timestamp('2023-09-21 00:00:00'),\n",
       " Timestamp('2023-09-22 00:00:00'),\n",
       " Timestamp('2023-09-23 00:00:00'),\n",
       " Timestamp('2023-09-24 00:00:00'),\n",
       " Timestamp('2023-09-25 00:00:00'),\n",
       " Timestamp('2023-09-26 00:00:00'),\n",
       " Timestamp('2023-09-27 00:00:00'),\n",
       " Timestamp('2023-09-28 00:00:00'),\n",
       " Timestamp('2023-09-29 00:00:00'),\n",
       " Timestamp('2023-09-30 00:00:00'),\n",
       " Timestamp('2023-10-01 00:00:00'),\n",
       " Timestamp('2023-10-02 00:00:00'),\n",
       " Timestamp('2023-10-03 00:00:00'),\n",
       " Timestamp('2023-06-01 00:00:00'),\n",
       " Timestamp('2023-06-02 00:00:00'),\n",
       " Timestamp('2023-06-03 00:00:00'),\n",
       " Timestamp('2023-06-04 00:00:00'),\n",
       " Timestamp('2023-06-05 00:00:00'),\n",
       " Timestamp('2023-06-06 00:00:00'),\n",
       " Timestamp('2023-06-07 00:00:00'),\n",
       " Timestamp('2023-06-08 00:00:00'),\n",
       " Timestamp('2023-06-09 00:00:00'),\n",
       " Timestamp('2023-06-10 00:00:00'),\n",
       " Timestamp('2023-06-11 00:00:00'),\n",
       " Timestamp('2023-06-12 00:00:00'),\n",
       " Timestamp('2023-06-13 00:00:00'),\n",
       " Timestamp('2023-06-14 00:00:00'),\n",
       " Timestamp('2023-06-15 00:00:00'),\n",
       " Timestamp('2023-06-16 00:00:00'),\n",
       " Timestamp('2023-06-17 00:00:00'),\n",
       " Timestamp('2023-06-18 00:00:00'),\n",
       " Timestamp('2023-06-19 00:00:00'),\n",
       " Timestamp('2023-06-20 00:00:00'),\n",
       " Timestamp('2023-06-21 00:00:00'),\n",
       " Timestamp('2023-06-22 00:00:00'),\n",
       " Timestamp('2023-06-23 00:00:00'),\n",
       " Timestamp('2023-06-24 00:00:00'),\n",
       " Timestamp('2023-06-25 00:00:00'),\n",
       " Timestamp('2023-06-26 00:00:00'),\n",
       " Timestamp('2023-06-27 00:00:00'),\n",
       " Timestamp('2023-06-28 00:00:00'),\n",
       " Timestamp('2023-06-29 00:00:00'),\n",
       " Timestamp('2023-06-30 00:00:00'),\n",
       " Timestamp('2023-07-01 00:00:00'),\n",
       " Timestamp('2023-07-02 00:00:00'),\n",
       " Timestamp('2023-07-03 00:00:00'),\n",
       " Timestamp('2023-07-04 00:00:00'),\n",
       " Timestamp('2023-07-05 00:00:00'),\n",
       " Timestamp('2023-07-06 00:00:00'),\n",
       " Timestamp('2023-07-07 00:00:00'),\n",
       " Timestamp('2023-07-08 00:00:00'),\n",
       " Timestamp('2023-07-09 00:00:00'),\n",
       " Timestamp('2023-07-10 00:00:00'),\n",
       " Timestamp('2023-07-11 00:00:00'),\n",
       " Timestamp('2023-07-12 00:00:00'),\n",
       " Timestamp('2023-07-13 00:00:00'),\n",
       " Timestamp('2023-07-14 00:00:00'),\n",
       " Timestamp('2023-07-15 00:00:00'),\n",
       " Timestamp('2023-07-16 00:00:00'),\n",
       " Timestamp('2023-07-17 00:00:00'),\n",
       " Timestamp('2023-07-18 00:00:00'),\n",
       " Timestamp('2023-07-19 00:00:00'),\n",
       " Timestamp('2023-07-20 00:00:00'),\n",
       " Timestamp('2023-07-21 00:00:00'),\n",
       " Timestamp('2023-07-22 00:00:00'),\n",
       " Timestamp('2023-07-23 00:00:00'),\n",
       " Timestamp('2023-07-24 00:00:00'),\n",
       " Timestamp('2023-07-25 00:00:00'),\n",
       " Timestamp('2023-07-26 00:00:00'),\n",
       " Timestamp('2023-07-27 00:00:00'),\n",
       " Timestamp('2023-07-28 00:00:00'),\n",
       " Timestamp('2023-07-29 00:00:00'),\n",
       " Timestamp('2023-07-30 00:00:00'),\n",
       " Timestamp('2023-07-31 00:00:00'),\n",
       " Timestamp('2023-08-01 00:00:00'),\n",
       " Timestamp('2023-08-02 00:00:00'),\n",
       " Timestamp('2023-08-04 00:00:00'),\n",
       " Timestamp('2023-08-05 00:00:00'),\n",
       " Timestamp('2023-08-06 00:00:00'),\n",
       " Timestamp('2023-08-07 00:00:00'),\n",
       " Timestamp('2023-08-08 00:00:00'),\n",
       " Timestamp('2023-08-09 00:00:00'),\n",
       " Timestamp('2023-08-10 00:00:00'),\n",
       " Timestamp('2023-08-11 00:00:00'),\n",
       " Timestamp('2023-08-12 00:00:00'),\n",
       " Timestamp('2023-08-13 00:00:00'),\n",
       " Timestamp('2023-08-14 00:00:00'),\n",
       " Timestamp('2023-08-15 00:00:00'),\n",
       " Timestamp('2023-08-16 00:00:00'),\n",
       " Timestamp('2023-08-17 00:00:00'),\n",
       " Timestamp('2023-08-18 00:00:00'),\n",
       " Timestamp('2023-08-19 00:00:00'),\n",
       " Timestamp('2023-08-20 00:00:00'),\n",
       " Timestamp('2023-08-21 00:00:00'),\n",
       " Timestamp('2023-08-22 00:00:00'),\n",
       " Timestamp('2023-08-23 00:00:00'),\n",
       " Timestamp('2023-08-24 00:00:00'),\n",
       " Timestamp('2023-08-25 00:00:00'),\n",
       " Timestamp('2023-08-26 00:00:00'),\n",
       " Timestamp('2023-08-27 00:00:00'),\n",
       " Timestamp('2023-08-28 00:00:00'),\n",
       " Timestamp('2023-08-29 00:00:00'),\n",
       " Timestamp('2023-08-30 00:00:00'),\n",
       " Timestamp('2023-08-31 00:00:00'),\n",
       " Timestamp('2023-09-01 00:00:00'),\n",
       " Timestamp('2023-09-02 00:00:00'),\n",
       " Timestamp('2023-09-03 00:00:00'),\n",
       " Timestamp('2023-09-04 00:00:00'),\n",
       " Timestamp('2023-09-05 00:00:00'),\n",
       " Timestamp('2023-09-06 00:00:00'),\n",
       " Timestamp('2023-09-07 00:00:00'),\n",
       " Timestamp('2023-09-08 00:00:00'),\n",
       " Timestamp('2023-09-09 00:00:00'),\n",
       " Timestamp('2023-09-10 00:00:00'),\n",
       " Timestamp('2023-09-11 00:00:00'),\n",
       " Timestamp('2023-09-12 00:00:00'),\n",
       " Timestamp('2023-09-13 00:00:00'),\n",
       " Timestamp('2023-09-14 00:00:00'),\n",
       " Timestamp('2023-09-15 00:00:00'),\n",
       " Timestamp('2023-09-16 00:00:00'),\n",
       " Timestamp('2023-09-17 00:00:00'),\n",
       " Timestamp('2023-09-18 00:00:00'),\n",
       " Timestamp('2023-09-19 00:00:00'),\n",
       " Timestamp('2023-09-20 00:00:00'),\n",
       " Timestamp('2023-09-21 00:00:00'),\n",
       " Timestamp('2023-09-22 00:00:00'),\n",
       " Timestamp('2023-09-23 00:00:00'),\n",
       " Timestamp('2023-09-24 00:00:00'),\n",
       " Timestamp('2023-09-25 00:00:00'),\n",
       " Timestamp('2023-09-26 00:00:00'),\n",
       " Timestamp('2023-09-27 00:00:00'),\n",
       " Timestamp('2023-09-28 00:00:00'),\n",
       " Timestamp('2023-09-29 00:00:00'),\n",
       " Timestamp('2023-09-30 00:00:00'),\n",
       " Timestamp('2023-10-01 00:00:00'),\n",
       " Timestamp('2023-10-02 00:00:00'),\n",
       " Timestamp('2023-10-03 00:00:00'),\n",
       " Timestamp('2023-06-01 00:00:00'),\n",
       " Timestamp('2023-06-02 00:00:00'),\n",
       " Timestamp('2023-06-03 00:00:00'),\n",
       " Timestamp('2023-06-04 00:00:00'),\n",
       " Timestamp('2023-06-05 00:00:00'),\n",
       " Timestamp('2023-06-06 00:00:00'),\n",
       " Timestamp('2023-06-07 00:00:00'),\n",
       " Timestamp('2023-06-08 00:00:00'),\n",
       " Timestamp('2023-06-09 00:00:00'),\n",
       " Timestamp('2023-06-10 00:00:00'),\n",
       " Timestamp('2023-06-11 00:00:00'),\n",
       " Timestamp('2023-06-12 00:00:00'),\n",
       " Timestamp('2023-06-13 00:00:00'),\n",
       " Timestamp('2023-06-14 00:00:00'),\n",
       " Timestamp('2023-06-15 00:00:00'),\n",
       " Timestamp('2023-06-16 00:00:00'),\n",
       " Timestamp('2023-06-17 00:00:00'),\n",
       " Timestamp('2023-06-18 00:00:00'),\n",
       " Timestamp('2023-06-19 00:00:00'),\n",
       " Timestamp('2023-06-20 00:00:00'),\n",
       " Timestamp('2023-06-21 00:00:00'),\n",
       " Timestamp('2023-06-22 00:00:00'),\n",
       " Timestamp('2023-06-23 00:00:00'),\n",
       " Timestamp('2023-06-24 00:00:00'),\n",
       " Timestamp('2023-06-25 00:00:00'),\n",
       " Timestamp('2023-06-26 00:00:00'),\n",
       " Timestamp('2023-06-27 00:00:00'),\n",
       " Timestamp('2023-06-28 00:00:00'),\n",
       " Timestamp('2023-06-29 00:00:00'),\n",
       " Timestamp('2023-06-30 00:00:00'),\n",
       " Timestamp('2023-07-01 00:00:00'),\n",
       " Timestamp('2023-07-02 00:00:00'),\n",
       " Timestamp('2023-07-03 00:00:00'),\n",
       " Timestamp('2023-07-04 00:00:00'),\n",
       " Timestamp('2023-07-05 00:00:00'),\n",
       " Timestamp('2023-07-06 00:00:00'),\n",
       " Timestamp('2023-07-07 00:00:00'),\n",
       " Timestamp('2023-07-08 00:00:00'),\n",
       " Timestamp('2023-07-09 00:00:00'),\n",
       " Timestamp('2023-07-10 00:00:00'),\n",
       " Timestamp('2023-07-11 00:00:00'),\n",
       " Timestamp('2023-07-12 00:00:00'),\n",
       " Timestamp('2023-07-13 00:00:00'),\n",
       " Timestamp('2023-07-14 00:00:00'),\n",
       " Timestamp('2023-07-15 00:00:00'),\n",
       " Timestamp('2023-07-16 00:00:00'),\n",
       " Timestamp('2023-07-17 00:00:00'),\n",
       " Timestamp('2023-07-18 00:00:00'),\n",
       " Timestamp('2023-07-19 00:00:00'),\n",
       " Timestamp('2023-07-20 00:00:00'),\n",
       " Timestamp('2023-07-21 00:00:00'),\n",
       " Timestamp('2023-07-22 00:00:00'),\n",
       " Timestamp('2023-07-23 00:00:00'),\n",
       " Timestamp('2023-07-24 00:00:00'),\n",
       " Timestamp('2023-07-25 00:00:00'),\n",
       " Timestamp('2023-07-26 00:00:00'),\n",
       " Timestamp('2023-07-27 00:00:00'),\n",
       " Timestamp('2023-07-28 00:00:00'),\n",
       " Timestamp('2023-07-29 00:00:00'),\n",
       " Timestamp('2023-07-30 00:00:00'),\n",
       " Timestamp('2023-07-31 00:00:00'),\n",
       " Timestamp('2023-08-01 00:00:00'),\n",
       " Timestamp('2023-08-02 00:00:00'),\n",
       " Timestamp('2023-08-04 00:00:00'),\n",
       " Timestamp('2023-08-05 00:00:00'),\n",
       " Timestamp('2023-08-06 00:00:00'),\n",
       " Timestamp('2023-08-07 00:00:00'),\n",
       " Timestamp('2023-08-08 00:00:00'),\n",
       " Timestamp('2023-08-09 00:00:00'),\n",
       " Timestamp('2023-08-10 00:00:00'),\n",
       " Timestamp('2023-08-11 00:00:00'),\n",
       " Timestamp('2023-08-12 00:00:00'),\n",
       " Timestamp('2023-08-13 00:00:00'),\n",
       " Timestamp('2023-08-14 00:00:00'),\n",
       " Timestamp('2023-08-15 00:00:00'),\n",
       " Timestamp('2023-08-16 00:00:00'),\n",
       " Timestamp('2023-08-17 00:00:00'),\n",
       " Timestamp('2023-08-18 00:00:00'),\n",
       " Timestamp('2023-08-19 00:00:00'),\n",
       " Timestamp('2023-08-20 00:00:00'),\n",
       " Timestamp('2023-08-21 00:00:00'),\n",
       " Timestamp('2023-08-22 00:00:00'),\n",
       " Timestamp('2023-08-23 00:00:00'),\n",
       " Timestamp('2023-08-24 00:00:00'),\n",
       " Timestamp('2023-08-25 00:00:00'),\n",
       " Timestamp('2023-08-26 00:00:00'),\n",
       " Timestamp('2023-08-27 00:00:00'),\n",
       " Timestamp('2023-08-28 00:00:00'),\n",
       " Timestamp('2023-08-29 00:00:00'),\n",
       " Timestamp('2023-08-30 00:00:00'),\n",
       " Timestamp('2023-08-31 00:00:00'),\n",
       " Timestamp('2023-09-01 00:00:00'),\n",
       " Timestamp('2023-09-02 00:00:00'),\n",
       " Timestamp('2023-09-03 00:00:00'),\n",
       " Timestamp('2023-09-04 00:00:00'),\n",
       " Timestamp('2023-09-05 00:00:00'),\n",
       " Timestamp('2023-09-06 00:00:00'),\n",
       " Timestamp('2023-09-07 00:00:00'),\n",
       " Timestamp('2023-09-08 00:00:00'),\n",
       " Timestamp('2023-09-09 00:00:00'),\n",
       " Timestamp('2023-09-10 00:00:00'),\n",
       " Timestamp('2023-09-11 00:00:00'),\n",
       " Timestamp('2023-09-12 00:00:00'),\n",
       " Timestamp('2023-09-13 00:00:00'),\n",
       " Timestamp('2023-09-14 00:00:00'),\n",
       " Timestamp('2023-09-15 00:00:00'),\n",
       " Timestamp('2023-09-16 00:00:00'),\n",
       " Timestamp('2023-09-17 00:00:00'),\n",
       " Timestamp('2023-09-18 00:00:00'),\n",
       " Timestamp('2023-09-19 00:00:00'),\n",
       " Timestamp('2023-09-20 00:00:00'),\n",
       " Timestamp('2023-09-21 00:00:00'),\n",
       " Timestamp('2023-09-22 00:00:00'),\n",
       " Timestamp('2023-09-23 00:00:00'),\n",
       " Timestamp('2023-09-24 00:00:00'),\n",
       " Timestamp('2023-09-25 00:00:00'),\n",
       " Timestamp('2023-09-26 00:00:00'),\n",
       " Timestamp('2023-09-27 00:00:00'),\n",
       " Timestamp('2023-09-28 00:00:00'),\n",
       " Timestamp('2023-09-29 00:00:00'),\n",
       " Timestamp('2023-09-30 00:00:00'),\n",
       " Timestamp('2023-10-01 00:00:00'),\n",
       " Timestamp('2023-10-02 00:00:00'),\n",
       " Timestamp('2023-10-03 00:00:00'),\n",
       " Timestamp('2023-06-01 00:00:00'),\n",
       " Timestamp('2023-06-02 00:00:00'),\n",
       " Timestamp('2023-06-03 00:00:00'),\n",
       " Timestamp('2023-06-04 00:00:00'),\n",
       " Timestamp('2023-06-05 00:00:00'),\n",
       " Timestamp('2023-06-06 00:00:00'),\n",
       " Timestamp('2023-06-07 00:00:00'),\n",
       " Timestamp('2023-06-08 00:00:00'),\n",
       " Timestamp('2023-06-09 00:00:00'),\n",
       " Timestamp('2023-06-10 00:00:00'),\n",
       " Timestamp('2023-06-11 00:00:00'),\n",
       " Timestamp('2023-06-12 00:00:00'),\n",
       " Timestamp('2023-06-13 00:00:00'),\n",
       " Timestamp('2023-06-14 00:00:00'),\n",
       " Timestamp('2023-06-15 00:00:00'),\n",
       " Timestamp('2023-06-16 00:00:00'),\n",
       " Timestamp('2023-06-17 00:00:00'),\n",
       " Timestamp('2023-06-18 00:00:00'),\n",
       " Timestamp('2023-06-19 00:00:00'),\n",
       " Timestamp('2023-06-20 00:00:00'),\n",
       " Timestamp('2023-06-21 00:00:00'),\n",
       " Timestamp('2023-06-22 00:00:00'),\n",
       " Timestamp('2023-06-23 00:00:00'),\n",
       " Timestamp('2023-06-24 00:00:00'),\n",
       " Timestamp('2023-06-25 00:00:00'),\n",
       " Timestamp('2023-06-26 00:00:00'),\n",
       " Timestamp('2023-06-27 00:00:00'),\n",
       " Timestamp('2023-06-28 00:00:00'),\n",
       " Timestamp('2023-06-29 00:00:00'),\n",
       " Timestamp('2023-06-30 00:00:00'),\n",
       " Timestamp('2023-07-01 00:00:00'),\n",
       " Timestamp('2023-07-02 00:00:00'),\n",
       " Timestamp('2023-07-03 00:00:00'),\n",
       " Timestamp('2023-07-04 00:00:00'),\n",
       " Timestamp('2023-07-05 00:00:00'),\n",
       " Timestamp('2023-07-06 00:00:00'),\n",
       " Timestamp('2023-07-07 00:00:00'),\n",
       " Timestamp('2023-07-08 00:00:00'),\n",
       " Timestamp('2023-07-09 00:00:00'),\n",
       " Timestamp('2023-07-10 00:00:00'),\n",
       " Timestamp('2023-07-11 00:00:00'),\n",
       " Timestamp('2023-07-12 00:00:00'),\n",
       " Timestamp('2023-07-13 00:00:00'),\n",
       " Timestamp('2023-07-14 00:00:00'),\n",
       " Timestamp('2023-07-15 00:00:00'),\n",
       " Timestamp('2023-07-16 00:00:00'),\n",
       " Timestamp('2023-07-17 00:00:00'),\n",
       " Timestamp('2023-07-18 00:00:00'),\n",
       " Timestamp('2023-07-19 00:00:00'),\n",
       " Timestamp('2023-07-20 00:00:00'),\n",
       " Timestamp('2023-07-21 00:00:00'),\n",
       " Timestamp('2023-07-22 00:00:00'),\n",
       " Timestamp('2023-07-23 00:00:00'),\n",
       " Timestamp('2023-07-24 00:00:00'),\n",
       " Timestamp('2023-07-25 00:00:00'),\n",
       " Timestamp('2023-07-26 00:00:00'),\n",
       " Timestamp('2023-07-27 00:00:00'),\n",
       " Timestamp('2023-07-28 00:00:00'),\n",
       " Timestamp('2023-07-29 00:00:00'),\n",
       " Timestamp('2023-07-30 00:00:00'),\n",
       " Timestamp('2023-07-31 00:00:00'),\n",
       " Timestamp('2023-08-01 00:00:00'),\n",
       " Timestamp('2023-08-02 00:00:00'),\n",
       " Timestamp('2023-08-04 00:00:00'),\n",
       " Timestamp('2023-08-05 00:00:00'),\n",
       " Timestamp('2023-08-06 00:00:00'),\n",
       " Timestamp('2023-08-07 00:00:00'),\n",
       " Timestamp('2023-08-08 00:00:00'),\n",
       " Timestamp('2023-08-09 00:00:00'),\n",
       " Timestamp('2023-08-10 00:00:00'),\n",
       " Timestamp('2023-08-11 00:00:00'),\n",
       " Timestamp('2023-08-12 00:00:00'),\n",
       " Timestamp('2023-08-13 00:00:00'),\n",
       " Timestamp('2023-08-14 00:00:00'),\n",
       " Timestamp('2023-08-15 00:00:00'),\n",
       " Timestamp('2023-08-16 00:00:00'),\n",
       " Timestamp('2023-08-17 00:00:00'),\n",
       " Timestamp('2023-08-18 00:00:00'),\n",
       " Timestamp('2023-08-19 00:00:00'),\n",
       " Timestamp('2023-08-20 00:00:00'),\n",
       " Timestamp('2023-08-21 00:00:00'),\n",
       " Timestamp('2023-08-22 00:00:00'),\n",
       " Timestamp('2023-08-23 00:00:00'),\n",
       " Timestamp('2023-08-24 00:00:00'),\n",
       " Timestamp('2023-08-25 00:00:00'),\n",
       " Timestamp('2023-08-26 00:00:00'),\n",
       " Timestamp('2023-08-27 00:00:00'),\n",
       " Timestamp('2023-08-28 00:00:00'),\n",
       " Timestamp('2023-08-29 00:00:00'),\n",
       " Timestamp('2023-08-30 00:00:00'),\n",
       " Timestamp('2023-08-31 00:00:00'),\n",
       " Timestamp('2023-09-01 00:00:00'),\n",
       " Timestamp('2023-09-02 00:00:00'),\n",
       " Timestamp('2023-09-03 00:00:00'),\n",
       " Timestamp('2023-09-04 00:00:00'),\n",
       " Timestamp('2023-09-05 00:00:00'),\n",
       " Timestamp('2023-09-06 00:00:00'),\n",
       " Timestamp('2023-09-07 00:00:00'),\n",
       " Timestamp('2023-09-08 00:00:00'),\n",
       " Timestamp('2023-09-09 00:00:00'),\n",
       " Timestamp('2023-09-10 00:00:00'),\n",
       " Timestamp('2023-09-11 00:00:00'),\n",
       " Timestamp('2023-09-12 00:00:00'),\n",
       " Timestamp('2023-09-13 00:00:00'),\n",
       " Timestamp('2023-09-14 00:00:00'),\n",
       " Timestamp('2023-09-15 00:00:00'),\n",
       " Timestamp('2023-09-16 00:00:00'),\n",
       " Timestamp('2023-09-17 00:00:00'),\n",
       " Timestamp('2023-09-18 00:00:00'),\n",
       " Timestamp('2023-09-19 00:00:00'),\n",
       " Timestamp('2023-09-20 00:00:00'),\n",
       " Timestamp('2023-09-21 00:00:00'),\n",
       " Timestamp('2023-09-22 00:00:00'),\n",
       " Timestamp('2023-09-23 00:00:00'),\n",
       " Timestamp('2023-09-24 00:00:00'),\n",
       " Timestamp('2023-09-25 00:00:00'),\n",
       " Timestamp('2023-09-26 00:00:00'),\n",
       " Timestamp('2023-09-27 00:00:00'),\n",
       " Timestamp('2023-09-28 00:00:00'),\n",
       " Timestamp('2023-09-29 00:00:00'),\n",
       " Timestamp('2023-09-30 00:00:00'),\n",
       " Timestamp('2023-10-01 00:00:00'),\n",
       " Timestamp('2023-10-02 00:00:00'),\n",
       " Timestamp('2023-10-03 00:00:00'),\n",
       " Timestamp('2023-06-01 00:00:00'),\n",
       " Timestamp('2023-06-02 00:00:00'),\n",
       " Timestamp('2023-06-03 00:00:00'),\n",
       " Timestamp('2023-06-04 00:00:00'),\n",
       " Timestamp('2023-06-05 00:00:00'),\n",
       " Timestamp('2023-06-06 00:00:00'),\n",
       " Timestamp('2023-06-07 00:00:00'),\n",
       " Timestamp('2023-06-08 00:00:00'),\n",
       " Timestamp('2023-06-09 00:00:00'),\n",
       " Timestamp('2023-06-10 00:00:00'),\n",
       " Timestamp('2023-06-11 00:00:00'),\n",
       " Timestamp('2023-06-12 00:00:00'),\n",
       " Timestamp('2023-06-13 00:00:00'),\n",
       " Timestamp('2023-06-14 00:00:00'),\n",
       " Timestamp('2023-06-15 00:00:00'),\n",
       " Timestamp('2023-06-16 00:00:00'),\n",
       " Timestamp('2023-06-17 00:00:00'),\n",
       " Timestamp('2023-06-18 00:00:00'),\n",
       " Timestamp('2023-06-19 00:00:00'),\n",
       " Timestamp('2023-06-20 00:00:00'),\n",
       " Timestamp('2023-06-21 00:00:00'),\n",
       " Timestamp('2023-06-22 00:00:00'),\n",
       " Timestamp('2023-06-23 00:00:00'),\n",
       " Timestamp('2023-06-24 00:00:00'),\n",
       " Timestamp('2023-06-25 00:00:00'),\n",
       " Timestamp('2023-06-26 00:00:00'),\n",
       " Timestamp('2023-06-27 00:00:00'),\n",
       " Timestamp('2023-06-28 00:00:00'),\n",
       " Timestamp('2023-06-29 00:00:00'),\n",
       " Timestamp('2023-06-30 00:00:00'),\n",
       " Timestamp('2023-07-01 00:00:00'),\n",
       " Timestamp('2023-07-02 00:00:00'),\n",
       " Timestamp('2023-07-03 00:00:00'),\n",
       " Timestamp('2023-07-04 00:00:00'),\n",
       " Timestamp('2023-07-05 00:00:00'),\n",
       " Timestamp('2023-07-06 00:00:00'),\n",
       " Timestamp('2023-07-07 00:00:00'),\n",
       " Timestamp('2023-07-08 00:00:00'),\n",
       " Timestamp('2023-07-09 00:00:00'),\n",
       " Timestamp('2023-07-10 00:00:00'),\n",
       " Timestamp('2023-07-11 00:00:00'),\n",
       " Timestamp('2023-07-12 00:00:00'),\n",
       " Timestamp('2023-07-13 00:00:00'),\n",
       " Timestamp('2023-07-14 00:00:00'),\n",
       " Timestamp('2023-07-15 00:00:00'),\n",
       " Timestamp('2023-07-16 00:00:00'),\n",
       " Timestamp('2023-07-17 00:00:00'),\n",
       " Timestamp('2023-07-18 00:00:00'),\n",
       " Timestamp('2023-07-19 00:00:00'),\n",
       " Timestamp('2023-07-20 00:00:00'),\n",
       " Timestamp('2023-07-21 00:00:00'),\n",
       " Timestamp('2023-07-22 00:00:00'),\n",
       " Timestamp('2023-07-23 00:00:00'),\n",
       " Timestamp('2023-07-24 00:00:00'),\n",
       " Timestamp('2023-07-25 00:00:00'),\n",
       " Timestamp('2023-07-26 00:00:00'),\n",
       " Timestamp('2023-07-27 00:00:00'),\n",
       " Timestamp('2023-07-28 00:00:00'),\n",
       " Timestamp('2023-07-29 00:00:00'),\n",
       " Timestamp('2023-07-30 00:00:00'),\n",
       " Timestamp('2023-07-31 00:00:00'),\n",
       " Timestamp('2023-08-01 00:00:00'),\n",
       " Timestamp('2023-08-02 00:00:00'),\n",
       " Timestamp('2023-08-04 00:00:00'),\n",
       " Timestamp('2023-08-05 00:00:00'),\n",
       " Timestamp('2023-08-06 00:00:00'),\n",
       " Timestamp('2023-08-07 00:00:00'),\n",
       " Timestamp('2023-08-08 00:00:00'),\n",
       " Timestamp('2023-08-09 00:00:00'),\n",
       " Timestamp('2023-08-10 00:00:00'),\n",
       " Timestamp('2023-08-11 00:00:00'),\n",
       " Timestamp('2023-08-12 00:00:00'),\n",
       " Timestamp('2023-08-13 00:00:00'),\n",
       " Timestamp('2023-08-14 00:00:00'),\n",
       " Timestamp('2023-08-15 00:00:00'),\n",
       " Timestamp('2023-08-16 00:00:00'),\n",
       " Timestamp('2023-08-17 00:00:00'),\n",
       " Timestamp('2023-08-18 00:00:00'),\n",
       " Timestamp('2023-08-19 00:00:00'),\n",
       " Timestamp('2023-08-20 00:00:00'),\n",
       " Timestamp('2023-08-21 00:00:00'),\n",
       " Timestamp('2023-08-22 00:00:00'),\n",
       " Timestamp('2023-08-23 00:00:00'),\n",
       " Timestamp('2023-08-24 00:00:00'),\n",
       " Timestamp('2023-08-25 00:00:00'),\n",
       " Timestamp('2023-08-26 00:00:00'),\n",
       " Timestamp('2023-08-27 00:00:00'),\n",
       " Timestamp('2023-08-28 00:00:00'),\n",
       " Timestamp('2023-08-29 00:00:00'),\n",
       " Timestamp('2023-08-30 00:00:00'),\n",
       " Timestamp('2023-08-31 00:00:00'),\n",
       " Timestamp('2023-09-01 00:00:00'),\n",
       " Timestamp('2023-09-02 00:00:00'),\n",
       " Timestamp('2023-09-03 00:00:00'),\n",
       " Timestamp('2023-09-04 00:00:00'),\n",
       " Timestamp('2023-09-05 00:00:00'),\n",
       " Timestamp('2023-09-06 00:00:00'),\n",
       " Timestamp('2023-09-07 00:00:00'),\n",
       " Timestamp('2023-09-08 00:00:00'),\n",
       " Timestamp('2023-09-09 00:00:00'),\n",
       " Timestamp('2023-09-10 00:00:00'),\n",
       " Timestamp('2023-09-11 00:00:00'),\n",
       " Timestamp('2023-09-12 00:00:00'),\n",
       " Timestamp('2023-09-13 00:00:00'),\n",
       " Timestamp('2023-09-14 00:00:00'),\n",
       " Timestamp('2023-09-15 00:00:00'),\n",
       " Timestamp('2023-09-16 00:00:00'),\n",
       " Timestamp('2023-09-17 00:00:00'),\n",
       " Timestamp('2023-09-18 00:00:00'),\n",
       " Timestamp('2023-09-19 00:00:00'),\n",
       " Timestamp('2023-09-20 00:00:00'),\n",
       " Timestamp('2023-09-21 00:00:00'),\n",
       " Timestamp('2023-09-22 00:00:00'),\n",
       " Timestamp('2023-09-23 00:00:00'),\n",
       " Timestamp('2023-09-24 00:00:00'),\n",
       " Timestamp('2023-09-25 00:00:00'),\n",
       " Timestamp('2023-09-26 00:00:00'),\n",
       " Timestamp('2023-09-27 00:00:00'),\n",
       " Timestamp('2023-09-28 00:00:00'),\n",
       " Timestamp('2023-09-29 00:00:00'),\n",
       " Timestamp('2023-09-30 00:00:00'),\n",
       " Timestamp('2023-10-01 00:00:00'),\n",
       " Timestamp('2023-10-02 00:00:00'),\n",
       " Timestamp('2023-10-03 00:00:00'),\n",
       " Timestamp('2023-06-01 00:00:00'),\n",
       " Timestamp('2023-06-02 00:00:00'),\n",
       " Timestamp('2023-06-03 00:00:00'),\n",
       " Timestamp('2023-06-04 00:00:00'),\n",
       " Timestamp('2023-06-05 00:00:00'),\n",
       " Timestamp('2023-06-06 00:00:00'),\n",
       " Timestamp('2023-06-07 00:00:00'),\n",
       " Timestamp('2023-06-08 00:00:00'),\n",
       " Timestamp('2023-06-09 00:00:00'),\n",
       " Timestamp('2023-06-10 00:00:00'),\n",
       " Timestamp('2023-06-11 00:00:00'),\n",
       " Timestamp('2023-06-12 00:00:00'),\n",
       " Timestamp('2023-06-13 00:00:00'),\n",
       " Timestamp('2023-06-14 00:00:00'),\n",
       " Timestamp('2023-06-15 00:00:00'),\n",
       " Timestamp('2023-06-16 00:00:00'),\n",
       " Timestamp('2023-06-17 00:00:00'),\n",
       " Timestamp('2023-06-18 00:00:00'),\n",
       " Timestamp('2023-06-19 00:00:00'),\n",
       " Timestamp('2023-06-20 00:00:00'),\n",
       " Timestamp('2023-06-21 00:00:00'),\n",
       " Timestamp('2023-06-22 00:00:00'),\n",
       " Timestamp('2023-06-23 00:00:00'),\n",
       " Timestamp('2023-06-24 00:00:00'),\n",
       " Timestamp('2023-06-25 00:00:00'),\n",
       " Timestamp('2023-06-26 00:00:00'),\n",
       " Timestamp('2023-06-27 00:00:00'),\n",
       " Timestamp('2023-06-28 00:00:00'),\n",
       " Timestamp('2023-06-29 00:00:00'),\n",
       " Timestamp('2023-06-30 00:00:00'),\n",
       " Timestamp('2023-07-01 00:00:00'),\n",
       " Timestamp('2023-07-02 00:00:00'),\n",
       " Timestamp('2023-07-03 00:00:00'),\n",
       " Timestamp('2023-07-04 00:00:00'),\n",
       " Timestamp('2023-07-05 00:00:00'),\n",
       " Timestamp('2023-07-06 00:00:00'),\n",
       " Timestamp('2023-07-07 00:00:00'),\n",
       " Timestamp('2023-07-08 00:00:00'),\n",
       " Timestamp('2023-07-09 00:00:00'),\n",
       " Timestamp('2023-07-10 00:00:00'),\n",
       " Timestamp('2023-07-11 00:00:00'),\n",
       " Timestamp('2023-07-12 00:00:00'),\n",
       " Timestamp('2023-07-13 00:00:00'),\n",
       " Timestamp('2023-07-14 00:00:00'),\n",
       " Timestamp('2023-07-15 00:00:00'),\n",
       " Timestamp('2023-07-16 00:00:00'),\n",
       " Timestamp('2023-07-17 00:00:00'),\n",
       " Timestamp('2023-07-18 00:00:00'),\n",
       " Timestamp('2023-07-19 00:00:00'),\n",
       " Timestamp('2023-07-20 00:00:00'),\n",
       " Timestamp('2023-07-21 00:00:00'),\n",
       " Timestamp('2023-07-22 00:00:00'),\n",
       " Timestamp('2023-07-23 00:00:00'),\n",
       " Timestamp('2023-07-24 00:00:00'),\n",
       " Timestamp('2023-07-25 00:00:00'),\n",
       " Timestamp('2023-07-26 00:00:00'),\n",
       " Timestamp('2023-07-27 00:00:00'),\n",
       " Timestamp('2023-07-28 00:00:00'),\n",
       " Timestamp('2023-07-29 00:00:00'),\n",
       " Timestamp('2023-07-30 00:00:00'),\n",
       " Timestamp('2023-07-31 00:00:00'),\n",
       " Timestamp('2023-08-01 00:00:00'),\n",
       " Timestamp('2023-08-02 00:00:00'),\n",
       " Timestamp('2023-08-04 00:00:00'),\n",
       " Timestamp('2023-08-05 00:00:00'),\n",
       " Timestamp('2023-08-06 00:00:00'),\n",
       " Timestamp('2023-08-07 00:00:00'),\n",
       " Timestamp('2023-08-08 00:00:00'),\n",
       " Timestamp('2023-08-09 00:00:00'),\n",
       " Timestamp('2023-08-10 00:00:00'),\n",
       " Timestamp('2023-08-11 00:00:00'),\n",
       " Timestamp('2023-08-12 00:00:00'),\n",
       " Timestamp('2023-08-13 00:00:00'),\n",
       " Timestamp('2023-08-14 00:00:00'),\n",
       " Timestamp('2023-08-15 00:00:00'),\n",
       " Timestamp('2023-08-16 00:00:00'),\n",
       " Timestamp('2023-08-17 00:00:00'),\n",
       " Timestamp('2023-08-18 00:00:00'),\n",
       " Timestamp('2023-08-19 00:00:00'),\n",
       " Timestamp('2023-08-20 00:00:00'),\n",
       " Timestamp('2023-08-21 00:00:00'),\n",
       " Timestamp('2023-08-22 00:00:00'),\n",
       " Timestamp('2023-08-23 00:00:00'),\n",
       " Timestamp('2023-08-24 00:00:00'),\n",
       " Timestamp('2023-08-25 00:00:00'),\n",
       " Timestamp('2023-08-26 00:00:00'),\n",
       " Timestamp('2023-08-27 00:00:00'),\n",
       " Timestamp('2023-08-28 00:00:00'),\n",
       " Timestamp('2023-08-29 00:00:00'),\n",
       " Timestamp('2023-08-30 00:00:00'),\n",
       " Timestamp('2023-08-31 00:00:00'),\n",
       " Timestamp('2023-09-01 00:00:00'),\n",
       " Timestamp('2023-09-02 00:00:00'),\n",
       " Timestamp('2023-09-03 00:00:00'),\n",
       " Timestamp('2023-09-04 00:00:00'),\n",
       " Timestamp('2023-09-05 00:00:00'),\n",
       " Timestamp('2023-09-06 00:00:00'),\n",
       " Timestamp('2023-09-07 00:00:00'),\n",
       " Timestamp('2023-09-08 00:00:00'),\n",
       " Timestamp('2023-09-09 00:00:00'),\n",
       " Timestamp('2023-09-10 00:00:00'),\n",
       " Timestamp('2023-09-11 00:00:00'),\n",
       " Timestamp('2023-09-12 00:00:00'),\n",
       " Timestamp('2023-09-13 00:00:00'),\n",
       " Timestamp('2023-09-14 00:00:00'),\n",
       " Timestamp('2023-09-15 00:00:00'),\n",
       " Timestamp('2023-09-16 00:00:00'),\n",
       " Timestamp('2023-09-17 00:00:00'),\n",
       " Timestamp('2023-09-18 00:00:00'),\n",
       " Timestamp('2023-09-19 00:00:00'),\n",
       " Timestamp('2023-09-20 00:00:00'),\n",
       " Timestamp('2023-09-21 00:00:00'),\n",
       " Timestamp('2023-09-22 00:00:00'),\n",
       " Timestamp('2023-09-23 00:00:00'),\n",
       " Timestamp('2023-09-24 00:00:00'),\n",
       " Timestamp('2023-09-25 00:00:00'),\n",
       " Timestamp('2023-09-26 00:00:00'),\n",
       " Timestamp('2023-09-27 00:00:00'),\n",
       " Timestamp('2023-09-28 00:00:00'),\n",
       " Timestamp('2023-09-29 00:00:00'),\n",
       " Timestamp('2023-09-30 00:00:00'),\n",
       " Timestamp('2023-10-01 00:00:00'),\n",
       " Timestamp('2023-10-02 00:00:00'),\n",
       " Timestamp('2023-10-03 00:00:00'),\n",
       " Timestamp('2023-06-01 00:00:00'),\n",
       " Timestamp('2023-06-02 00:00:00'),\n",
       " Timestamp('2023-06-03 00:00:00'),\n",
       " Timestamp('2023-06-04 00:00:00'),\n",
       " Timestamp('2023-06-05 00:00:00'),\n",
       " Timestamp('2023-06-06 00:00:00'),\n",
       " Timestamp('2023-06-07 00:00:00'),\n",
       " Timestamp('2023-06-08 00:00:00'),\n",
       " Timestamp('2023-06-09 00:00:00'),\n",
       " Timestamp('2023-06-10 00:00:00'),\n",
       " Timestamp('2023-06-11 00:00:00'),\n",
       " Timestamp('2023-06-12 00:00:00'),\n",
       " Timestamp('2023-06-13 00:00:00'),\n",
       " Timestamp('2023-06-14 00:00:00'),\n",
       " Timestamp('2023-06-15 00:00:00'),\n",
       " Timestamp('2023-06-16 00:00:00'),\n",
       " Timestamp('2023-06-17 00:00:00'),\n",
       " Timestamp('2023-06-18 00:00:00'),\n",
       " Timestamp('2023-06-19 00:00:00'),\n",
       " Timestamp('2023-06-20 00:00:00'),\n",
       " Timestamp('2023-06-21 00:00:00'),\n",
       " Timestamp('2023-06-22 00:00:00'),\n",
       " Timestamp('2023-06-23 00:00:00'),\n",
       " Timestamp('2023-06-24 00:00:00'),\n",
       " Timestamp('2023-06-25 00:00:00'),\n",
       " Timestamp('2023-06-26 00:00:00'),\n",
       " Timestamp('2023-06-27 00:00:00'),\n",
       " Timestamp('2023-06-28 00:00:00'),\n",
       " Timestamp('2023-06-29 00:00:00'),\n",
       " Timestamp('2023-06-30 00:00:00'),\n",
       " Timestamp('2023-07-01 00:00:00'),\n",
       " Timestamp('2023-07-02 00:00:00'),\n",
       " Timestamp('2023-07-03 00:00:00'),\n",
       " Timestamp('2023-07-04 00:00:00'),\n",
       " Timestamp('2023-07-05 00:00:00'),\n",
       " Timestamp('2023-07-06 00:00:00'),\n",
       " Timestamp('2023-07-07 00:00:00'),\n",
       " Timestamp('2023-07-08 00:00:00'),\n",
       " Timestamp('2023-07-09 00:00:00'),\n",
       " Timestamp('2023-07-10 00:00:00'),\n",
       " Timestamp('2023-07-11 00:00:00'),\n",
       " Timestamp('2023-07-12 00:00:00'),\n",
       " Timestamp('2023-07-13 00:00:00'),\n",
       " Timestamp('2023-07-14 00:00:00'),\n",
       " Timestamp('2023-07-15 00:00:00'),\n",
       " Timestamp('2023-07-16 00:00:00'),\n",
       " Timestamp('2023-07-17 00:00:00'),\n",
       " Timestamp('2023-07-18 00:00:00'),\n",
       " Timestamp('2023-07-19 00:00:00'),\n",
       " Timestamp('2023-07-20 00:00:00'),\n",
       " Timestamp('2023-07-21 00:00:00'),\n",
       " Timestamp('2023-07-22 00:00:00'),\n",
       " Timestamp('2023-07-23 00:00:00'),\n",
       " Timestamp('2023-07-24 00:00:00'),\n",
       " Timestamp('2023-07-25 00:00:00'),\n",
       " Timestamp('2023-07-26 00:00:00'),\n",
       " Timestamp('2023-07-27 00:00:00'),\n",
       " Timestamp('2023-07-28 00:00:00'),\n",
       " Timestamp('2023-07-29 00:00:00'),\n",
       " Timestamp('2023-07-30 00:00:00'),\n",
       " Timestamp('2023-07-31 00:00:00'),\n",
       " Timestamp('2023-08-01 00:00:00'),\n",
       " Timestamp('2023-08-02 00:00:00'),\n",
       " Timestamp('2023-08-04 00:00:00'),\n",
       " Timestamp('2023-08-05 00:00:00'),\n",
       " Timestamp('2023-08-06 00:00:00'),\n",
       " Timestamp('2023-08-07 00:00:00'),\n",
       " Timestamp('2023-08-08 00:00:00'),\n",
       " Timestamp('2023-08-09 00:00:00'),\n",
       " Timestamp('2023-08-10 00:00:00'),\n",
       " Timestamp('2023-08-11 00:00:00'),\n",
       " Timestamp('2023-08-12 00:00:00'),\n",
       " Timestamp('2023-08-13 00:00:00'),\n",
       " Timestamp('2023-08-14 00:00:00'),\n",
       " Timestamp('2023-08-15 00:00:00'),\n",
       " Timestamp('2023-08-16 00:00:00'),\n",
       " Timestamp('2023-08-17 00:00:00'),\n",
       " Timestamp('2023-08-18 00:00:00'),\n",
       " Timestamp('2023-08-19 00:00:00'),\n",
       " Timestamp('2023-08-20 00:00:00'),\n",
       " Timestamp('2023-08-21 00:00:00'),\n",
       " Timestamp('2023-08-22 00:00:00'),\n",
       " Timestamp('2023-08-23 00:00:00'),\n",
       " Timestamp('2023-08-24 00:00:00'),\n",
       " Timestamp('2023-08-25 00:00:00'),\n",
       " Timestamp('2023-08-26 00:00:00'),\n",
       " Timestamp('2023-08-27 00:00:00'),\n",
       " Timestamp('2023-08-28 00:00:00'),\n",
       " Timestamp('2023-08-29 00:00:00'),\n",
       " Timestamp('2023-08-30 00:00:00'),\n",
       " Timestamp('2023-08-31 00:00:00'),\n",
       " Timestamp('2023-09-01 00:00:00'),\n",
       " Timestamp('2023-09-02 00:00:00'),\n",
       " Timestamp('2023-09-03 00:00:00'),\n",
       " Timestamp('2023-09-04 00:00:00'),\n",
       " Timestamp('2023-09-05 00:00:00'),\n",
       " Timestamp('2023-09-06 00:00:00'),\n",
       " Timestamp('2023-09-07 00:00:00'),\n",
       " Timestamp('2023-09-08 00:00:00'),\n",
       " Timestamp('2023-09-09 00:00:00'),\n",
       " Timestamp('2023-09-10 00:00:00'),\n",
       " Timestamp('2023-09-11 00:00:00'),\n",
       " Timestamp('2023-09-12 00:00:00'),\n",
       " Timestamp('2023-09-13 00:00:00'),\n",
       " Timestamp('2023-09-14 00:00:00'),\n",
       " Timestamp('2023-09-15 00:00:00'),\n",
       " Timestamp('2023-09-16 00:00:00'),\n",
       " Timestamp('2023-09-17 00:00:00'),\n",
       " Timestamp('2023-09-18 00:00:00'),\n",
       " Timestamp('2023-09-19 00:00:00'),\n",
       " Timestamp('2023-09-20 00:00:00'),\n",
       " Timestamp('2023-09-21 00:00:00'),\n",
       " Timestamp('2023-09-22 00:00:00'),\n",
       " Timestamp('2023-09-23 00:00:00'),\n",
       " Timestamp('2023-09-24 00:00:00'),\n",
       " Timestamp('2023-09-25 00:00:00'),\n",
       " Timestamp('2023-09-26 00:00:00'),\n",
       " Timestamp('2023-09-27 00:00:00'),\n",
       " Timestamp('2023-09-28 00:00:00'),\n",
       " Timestamp('2023-09-29 00:00:00'),\n",
       " Timestamp('2023-09-30 00:00:00'),\n",
       " Timestamp('2023-10-01 00:00:00'),\n",
       " Timestamp('2023-10-02 00:00:00'),\n",
       " Timestamp('2023-10-03 00:00:00'),\n",
       " Timestamp('2023-06-01 00:00:00'),\n",
       " Timestamp('2023-06-02 00:00:00'),\n",
       " Timestamp('2023-06-03 00:00:00'),\n",
       " Timestamp('2023-06-04 00:00:00'),\n",
       " Timestamp('2023-06-05 00:00:00'),\n",
       " Timestamp('2023-06-06 00:00:00'),\n",
       " Timestamp('2023-06-07 00:00:00'),\n",
       " Timestamp('2023-06-08 00:00:00'),\n",
       " ...]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFinal.DATA.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"ROTURA\"] = np.where(dfFinal[\"ROTURA\"]==1, \"SIM\", \"NÃO\")\n",
    "# Ficheiro Dia\n",
    "dfEscreverDia = dfFinal[dfFinal.DATA == dfFinal.DATA.unique()[-2]].copy()\n",
    "\n",
    "# Ficheiro Mês\n",
    "dfEscreverMes = dfFinal[dfFinal.DATA.between(dfFinal.DATA.unique()[-31],dfFinal.DATA.unique()[-2])].copy()\n",
    "\n",
    "# Ficheiro 180 dias\n",
    "dfEscrever180 = dfFinal[dfFinal.DATA.between(dfFinal.DATA.unique()[-124],dfFinal.DATA.unique()[-2])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEscreverMachineLearning = dfFinal[[\"DATA\", \"STORE\", \"ROTURA\", \"CICLOS\", \"Balance_Smart\", \n",
    "                      \"Percentagem_Dias_Stock_Borderline_60\",\"Percentagem_Dias_Stock_Borderline_120\", \n",
    "                      \"Percentagem_Roturas_60\", \"Percentagem_Roturas_120\", \n",
    "                      \"Percentagem_Volatilidade_60\", \"Percentagem_Volatilidade_120\", \n",
    "                      \"Percentagem_Dias_Sem_Vendas_60\",\"Percentagem_Dias_Sem_Vendas_120\",\n",
    "                      \"Percentagem_Dias_Linear_Incompleto_60\", \"Percentagem_Dias_Linear_Incompleto_120\",\n",
    "                      \"Percentagem_Balance_Raw_Count1_60\", \"Percentagem_Balance_Raw_Count1_120\",\n",
    "                      \"Percentagem_Balance_Raw_Count2_60\", \"Percentagem_Balance_Raw_Count2_120\"]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "escrever_csv(dfEscreverDia, \"DataBaseDeltaDia\")\n",
    "escrever_csv(dfEscreverMes, \"DataBaseDeltaMes\")\n",
    "escrever_csv(dfEscrever180, \"DataBaseDelta180Dias\")\n",
    "escrever_csv(dfEscreverMachineLearning, \"DataBaseDeltaML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Estudos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(2022)\n",
    "for i in range (1,13):\n",
    "    \n",
    "    print(f\"Mês {i}: \",dfFinal[(dfFinal.ROTURA==\"SIM\") & (dfFinal.DATA.dt.year==2022) & (dfFinal.DATA.dt.month==i)].shape[0])\n",
    "print(2023)  \n",
    "for i in range (1,13):\n",
    "    print(f\"Mês {i}: \",dfFinal[(dfFinal.ROTURA==\"SIM\") & (dfFinal.DATA.dt.year==2023) & (dfFinal.DATA.dt.month==i)].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ninjas"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dfNinjas = dfClick.copy()\n",
    "\n",
    "dfNinjas = dfNinjas[[\"DATA\",\"STORE_NAME\",\"DESC_ARTIGO\",\"Sinal\"]][(dfNinjas[\"DESC_ARTIGO\"].isin(produtos)) & (dfNinjas[\"STORE_NAME\"].isin(lojas))].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal = pd.merge(dfFinal, dfClick[[\"STORE\",\"DATA\",\"DESC_ARTIGO\",\"NinjaInfo\", \"Order_FDS\"]], how=\"left\", on = [\"STORE\",\"DATA\",\"DESC_ARTIGO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorias possíveis\n",
    "mapping = {1: \"Presente com Stock\",\n",
    "           2: \"Ausente com Stock\",\n",
    "           3: \"Presente sem Stock\",\n",
    "           4: \"Ausente sem Stock\",\n",
    "           5: \"Presente sem Registo\",\n",
    "           6: \"Ausente sem Registo\"}\n",
    "\n",
    "# Definir coluna de sinal\n",
    "dfFinal[\"Sinal\"] = np.where((dfFinal[\"STOCK\"] > 0) & (dfFinal[\"NinjaInfo\"] == 1), 1,\n",
    "                     np.where((dfFinal[\"STOCK\"] > 0) & (dfFinal[\"NinjaInfo\"] == 0), 2,\n",
    "                     np.where((dfFinal[\"STOCK\"] <= 0) & (dfFinal[\"NinjaInfo\"] == 1), 3,\n",
    "                     np.where((dfFinal[\"STOCK\"] <= 0) & (dfFinal[\"NinjaInfo\"] == 0), 4,\n",
    "                     np.where((dfFinal[\"STOCK\"].isna()) & (dfFinal[\"NinjaInfo\"] == 1), 5,\n",
    "                     np.where((dfFinal[\"STOCK\"].isna()) & (dfFinal[\"NinjaInfo\"] == 0), 6,\n",
    "                     np.nan))))))\n",
    "\n",
    "# Substituir números pelas expressões escolhidas\n",
    "dfFinal[\"Sinal\"] = dfFinal[\"Sinal\"].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNinjas.Sinal.unique()\n",
    "\n",
    "dfNinjas[\"Audit\"] = np.where(dfNinjas.Sinal =='Presente com Stock', \"Produto Presente no Linear e com Stock em Loja\",\n",
    "                    np.where(dfNinjas.Sinal =='Ausente com Stock', \"Produto Ausente no Linear mas com Stock em Loja\",\n",
    "                    np.where(dfNinjas.Sinal =='Presente sem Stock', \"Produto Presente no Linear mas sem Stock em Loja\",\n",
    "                    np.where(dfNinjas.Sinal =='Ausente sem Stock', \"Produto Ausente no Linear e sem Stock em Loja\",         \n",
    "                    \"Sem Registo de Auditoria Prévio\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tempo anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year and month from the 'date' column\n",
    "dfFinal['Ano'] = dfFinal['DATA'].dt.year\n",
    "dfFinal['Ano_Anterior'] = dfFinal['Ano'] + 1\n",
    "dfFinal['Mes'] = dfFinal['DATA'].dt.month\n",
    "\n",
    "# Mês Actual\n",
    "media_mes_actual = dfFinal.groupby(['Ano', 'Mes'])['SELLOUT'].mean().reset_index()\n",
    "media_mes_actual.rename(columns={'SELLOUT': 'Media_Sellout_Mensal'}, inplace=True)\n",
    "\n",
    "# Mês Homólogo\n",
    "media_mes_homologo = dfFinal.groupby(['Ano_Anterior', 'Mes'])['SELLOUT'].mean().reset_index()\n",
    "media_mes_homologo.rename(columns={'SELLOUT': 'Media_Sellout_Mensal_Homologo'}, inplace=True)\n",
    "\n",
    "#drop\n",
    "\n",
    "\n",
    "# Merge the monthly mean back into the original DataFrame\n",
    "dfFinal = dfFinal.merge(media_mes_actual, on=['Ano', 'Mes'], how=\"left\")\n",
    "dfFinal = dfFinal.merge(media_mes_homologo, left_on=['Ano', 'Mes'], right_on=['Ano_Anterior', 'Mes'], how=\"left\")\n",
    "\n",
    "dfFinal = dfFinal.drop(columns = [\"Ano_Anterior_x\", \"Ano_Anterior_y\"])\n",
    "\n",
    "# Calculate the monthly mean for the previous month\n",
    "media_mes_anterior = dfFinal.groupby(['Ano', 'Mes'])['SELLOUT'].mean().shift(1).reset_index()\n",
    "media_mes_anterior.rename(columns={'SELLOUT': 'Media_Sellout_Mensal_Mes_Anterior'}, inplace=True)\n",
    "\n",
    "dfFinal = dfFinal.merge(media_mes_anterior, on=['Ano', 'Mes'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clickhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ficheiro Dia\n",
    "dfEscreverDia = dfFinal[dfFinal.DATA == dfFinal.DATA.unique()[-2]].copy()\n",
    "\n",
    "# Ficheiro Mês\n",
    "dfEscreverMes = dfFinal[dfFinal.DATA.between(dfFinal.DATA.unique()[-31],dfFinal.DATA.unique()[-2])].copy()\n",
    "\n",
    "# Ficheiro 180 dias\n",
    "dfEscrever180 = dfFinal[dfFinal.DATA.between(dfFinal.DATA.unique()[-124],dfFinal.DATA.unique()[-2])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clickhouse_connect\n",
    "from clickhouse_driver import Client\n",
    "from unidecode import unidecode\n",
    "\n",
    "client = clickhouse_connect.get_client(host='ch.brandsandninjas.com', \n",
    "                                       port=443, \n",
    "                                       username='chninja', \n",
    "                                       password='ku43ueqnB5Q0AYb2C4FsJRTc7qX',\n",
    "                                       database = 'Delta')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "client.command('DROP TABLE IF EXISTS BaseDeltaMes')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "client.command(\"CREATE TABLE Delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estabelecer a base a ser lida\n",
    "\n",
    "qualbase = 1\n",
    "\n",
    "if qualbase == 1:\n",
    "    baseCH = dfEscreverDia.copy()\n",
    "    tabela = \"BaseGoChillDia\"\n",
    "\n",
    "elif qualbase == 2:\n",
    "    baseCH = dfEscreverMes.copy()\n",
    "    tabela = \"BaseGoChillMes2\"\n",
    "\n",
    "elif qualbase == 3:\n",
    "    baseCH = dfEscrever180.copy()\n",
    "    tabela = \"BaseDelta180\"\n",
    "\n",
    "elif qualbase == 4:\n",
    "    baseCH = dfNinjas.copy()\n",
    "    tabela = \"BaseDeltaNinja\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<clickhouse_connect.driver.summary.QuerySummary at 0x20052816800>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Algumas alterações\n",
    "baseCH['DATA']= pd.to_datetime(baseCH['DATA'], format='%Y-%m-%d')  # Passar a Data para datetime\n",
    "\n",
    "baseCH.columns = [unidecode(col) for col in baseCH.columns]        # Tirar acentos e afins dos nomes das colunas porque \n",
    "                                                                   # o Clickhouse não gosta\n",
    "\n",
    "\n",
    "## Listas para definir os tipos de dados de cada coluna a inserit\n",
    "data = [\"DATA\"]\n",
    "texto = [col for col in baseCH.columns if baseCH[col].dtype == 'object']\n",
    "inteiros = [col for col in baseCH.columns if baseCH[col].dtype == 'int64' or baseCH[col].dtype == 'int32']\n",
    "floats = [col for col in baseCH.columns if baseCH[col].dtype == 'float64']\n",
    "\n",
    "\n",
    "## Mudar inteiros para floats porque senão não pode haver missing values\n",
    "for col_name in inteiros:\n",
    "    baseCH[col_name] = baseCH[col_name].astype(float)\n",
    "\n",
    "## Missing values em strings também estragam tudo\n",
    "baseCH[texto] = baseCH[texto].fillna(\"-\")\n",
    "baseCH[texto] = baseCH[texto].astype(str)\n",
    "\n",
    "#Função que vai fazer a schema\n",
    "def schema(lista, tipo):\n",
    "    result_list = [f\"{element} {tipo}\" for element in lista]\n",
    "    return result_list\n",
    "\n",
    "# Schema a ser feito\n",
    "data1 = schema(data, \"Date\")\n",
    "texto1 = schema(texto, \"String\")\n",
    "inteiros1 = schema(inteiros, \"Float64\")\n",
    "floats1 = schema(floats, \"Float64\")\n",
    "total = tuple(data1 + texto1 + inteiros1 + floats1)\n",
    "schema = ', '.join([column.replace(\"'\", \"\") for column in total])\n",
    "\n",
    "# Split the input string by commas\n",
    "parts = schema.split(', ')\n",
    "# Process each part and wrap the first word in double quotes\n",
    "output_parts = []\n",
    "for part in parts:\n",
    "    words = part.split()\n",
    "    if words:\n",
    "        first_word = words[0]\n",
    "        remaining_words = ' '.join(words[1:])\n",
    "        output_part = f'\"{first_word}\" {remaining_words}'\n",
    "        output_parts.append(output_part)\n",
    "# Join the modified parts back into a string\n",
    "schema = ', '.join(output_parts)\n",
    "\n",
    "# Eliminar tabela que possa existir no CH com o mesmo nome\n",
    "client.command(f'DROP TABLE IF EXISTS {tabela}')\n",
    "\n",
    "# Criar tabela no CH\n",
    "client.command(f'''\n",
    "    CREATE TABLE IF NOT EXISTS {tabela} (\n",
    "        {schema}\n",
    "        ) ENGINE = MergeTree\n",
    "        ORDER BY (DATA)\n",
    "''')\n",
    "\n",
    "\n",
    "# Exportar os dados para o clickhouse\n",
    "client.insert_df(tabela, baseCH, column_names=baseCH.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = dfEscrever180.columns.tolist()[0:18]\n",
    "#colunas = ['DATA','EAN','DESC_ARTIGO','STORE',...]\n",
    "#colunas"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Definir base que queremos estudar\n",
    "\n",
    "baseFiltrada = dfEscreverDia.copy()\n",
    "\n",
    "# Correr\n",
    "\n",
    "from ipywidgets import interact, widgets\n",
    "@interact\n",
    "def filtrar_produto(\n",
    "    produto=widgets.Dropdown(options=list(baseFiltrada.DESC_ARTIGO.unique())),\n",
    "    loja=widgets.Dropdown(options=list(baseFiltrada.STORE_NAME.unique())),\n",
    "    rotura=widgets.SelectionSlider(\n",
    "        options=[\"NÃO\", \"SIM\"],\n",
    "        value=\"NÃO\",  # Set an initial value to \"NO\"\n",
    "        description=\"Rotura\"\n",
    "    )\n",
    "):\n",
    "    \n",
    "    filtered_df = baseFiltrada[\n",
    "        (baseFiltrada.DESC_ARTIGO == produto) &\n",
    "        (baseFiltrada.STORE_NAME == loja) &\n",
    "        (baseFiltrada.ROTURA == rotura)\n",
    "    ].head(7)\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
