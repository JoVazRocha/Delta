{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumo do código Alteração\n",
    "\n",
    "### <u>Código que gera os ficheiros para estudo do comportamento da Delta</u>\n",
    "---\n",
    "O objectivo é receber dados da Delta e devolver um conjunto de métricas para prever roturas. Devolve um ficheiro que pode entrar no código 1 para juntar aos dados dos ninjas.\n",
    "\n",
    "---\n",
    "- Inputs\n",
    "\n",
    "> __Dados completos da Delta em pastas de ficheiros__ (de azul a verde)\n",
    "> - Stocks e trânsito, Sellout do dia anterior\n",
    "\n",
    "                    ou\n",
    "\n",
    "> __Ficheiro já completo__ (de vermelho a verde)\n",
    "> - Stocks e trânsito, Sellout do dia anterior\n",
    "\n",
    "- Outputs\n",
    "\n",
    "> __Ficheiro com produtos em causa__ em formato Long\n",
    "\n",
    "> __Métricas novas:__\n",
    "> - Roturas de Stock e Pré-rotura\n",
    "> - Sinal\n",
    "> - Ciclos e Adequação de Stock\n",
    "> - MSA (média de sellouts 10 dias antes)\n",
    "> - STK (Stock disponível + trânsito)\n",
    "> - (Novo) Balanço médio, mediano, liberal e conservador \n",
    "> - (Novo) Dias para a rotura de stock e de prateleira\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 300 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import clickhouse_connect\n",
    "from IPython.display import Audio\n",
    "\n",
    "def escrever_excel(dfa, nome):\n",
    "    dfa.to_excel(f'C:\\\\Users\\\\Chip7\\\\Desktop\\\\B&N\\\\Dados\\\\2.Delta\\\\Sonae\\\\Testes\\\\{nome}.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:Blue\">Alterar</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_actual = \"03-11\"           # Do tipo dd-mm\n",
    "base_Clickhouse_120 = \"P\"      # P ou I, quer dizer que o dia anterior é par ou ímpar\n",
    "base_Clickhouse_120_nova = \"I\" # A alternativa diferente à da variável anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:Blue\">Juntar Ficheiros</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importar do Clickhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clickhouse_connect\n",
    "client = clickhouse_connect.get_client(host='ch.brandsandninjas.com', \n",
    "                                       port=443, \n",
    "                                       username='chninja', \n",
    "                                       password='ku43ueqnB5Q0AYb2C4FsJRTc7qX',\n",
    "                                       database = \"Delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.1 s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Ler o ficheiro\n",
    "\n",
    "dfClick = client.query_df(f'SELECT * FROM Delta_dbd_120dias_{base_Clickhouse_120}')\n",
    "\n",
    "dfClick = dfClick.sort_values(by = \"DATA\")\n",
    "dfClick = dfClick[dfClick.DATA != dfClick.DATA.unique()[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importar ficheiros novos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfNovo = pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Diário\\\\31-10.xlsb\") #xlsx\n",
    "dfNovo = pd.read_excel(f\"C:\\\\Users\\\\Chip7\\\\Desktop\\\\B&N\\\\Dados\\\\2.Delta\\\\Sonae\\\\Diario\\\\{dia_actual}.xlsb\")\n",
    "\n",
    "dfNovo = dfNovo[['DATA', 'EAN', 'DESC_ARTIGO', 'STORE', \"STORE_NAME\", \n",
    "                 \"SOH\", \"INTRANSIT\", \"EXPECTED\", \"PRES_STOCK\", \"VND (D-1)\", \"FLUXO\"]]\n",
    "\n",
    "# Renomear colunas e criar as do dia\n",
    "\n",
    "dfNovo = dfNovo.rename(columns={\"VND (D-1)\": \"SELLOUT_1_Dias_Antes\", \n",
    "                                \"SOH\": \"STOCK_1_Dias_Antes\",\n",
    "                                \"INTRANSIT\": \"INTRANSIT_1_Dias_Antes\", \n",
    "                                \"EXPECTED\": \"EXPECTED_1_Dias_Antes\", \n",
    "                                \"PRES_STOCK\": \"PRES_STOCK_1_Dias_Antes\"})\n",
    "\n",
    "dfNovo[\"SELLOUT_1_Dias_Antes\"] = np.where(dfNovo[\"SELLOUT_1_Dias_Antes\"]<0, 0, dfNovo[\"SELLOUT_1_Dias_Antes\"])\n",
    "\n",
    "#DATETIME\n",
    "# se xlsx\n",
    "#dfNovo['DATA'] = pd.to_datetime(dfNovo['DATA'], format='%Y-%m-%d') \n",
    "\n",
    "# se xlsb\n",
    "dfNovo['DATA'] = pd.to_datetime(dfNovo['DATA'], unit='D', origin=datetime.datetime(1899, 12, 30)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Juntar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDiario = pd.concat([dfClick, dfNovo], ignore_index=True, join='outer')\n",
    "\n",
    "dfFinal = dfDiario.copy()\n",
    "dfFinal['DATA'] = pd.to_datetime(dfFinal['DATA'], format='%Y-%m-%d') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vendedores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfVendedor=pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Vendedor2.xlsx\", sheet_name = \"Lojas Sonae para o desafio\")\n",
    "dfVendedor=pd.read_excel(\"C:\\\\Users\\\\Chip7\\\\Desktop\\\\B&N\\\\Dados\\\\2.Delta\\\\Sonae\\\\Vendedor2.xlsx\", sheet_name = \"Lojas Sonae para o desafio\")\n",
    "\n",
    "dfVendedor = dfVendedor.rename(columns={\"Cód. Loja\":\"STORE\"})\n",
    "\n",
    "dfFinal = dfFinal.drop(columns=\"Vendedor\")\n",
    "\n",
    "# Criar coluna de reposição\n",
    "dfFinal = pd.merge(dfFinal, dfVendedor[[\"STORE\",\"Vendedor\"]], how=\"left\", on = \"STORE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal['SELLOUT'] = dfFinal.groupby([\"STORE\",\"EAN\"])['SELLOUT_1_Dias_Antes'].shift(-1)\n",
    "dfFinal['STOCK'] = dfFinal.groupby([\"STORE\",\"EAN\"])['STOCK_1_Dias_Antes'].shift(-1)\n",
    "dfFinal['INTRANSIT'] = dfFinal.groupby([\"STORE\",\"EAN\"])['INTRANSIT_1_Dias_Antes'].shift(-1)\n",
    "dfFinal['EXPECTED'] = dfFinal.groupby([\"STORE\",\"EAN\"])['EXPECTED_1_Dias_Antes'].shift(-1)\n",
    "dfFinal['PRES_STOCK'] = dfFinal.groupby([\"STORE\",\"EAN\"])['PRES_STOCK_1_Dias_Antes'].shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=green>Ficheiro Lido<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colunas de métricas interessantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - ROTURA\n",
    "> - PRÉ_ROTURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir coluna de rotura (se stock menor ou igual a 0 e existe Linear)\n",
    "\n",
    "dfFinal[\"ROTURA\"] = np.where((dfFinal[\"STOCK\"] <= 0) & (dfFinal[\"PRES_STOCK\"] > 0), 1, 0)\n",
    "dfFinal[\"ROTURA_1_Dias_Antes\"] = np.where((dfFinal[\"STOCK_1_Dias_Antes\"] <= 0) & (dfFinal[\"PRES_STOCK_1_Dias_Antes\"] > 0), 1, 0)\n",
    "\n",
    "\n",
    "# Definir coluna de rotura (se stock menor ou igual a 0)\n",
    "\n",
    "dfFinal[\"PRE_ROTURA\"] = (dfFinal[\"STOCK\"] < dfFinal[\"PRES_STOCK\"]).astype(int)\n",
    "dfFinal[\"PRE_ROTURA_1_Dias_Antes\"] = (dfFinal[\"STOCK_1_Dias_Antes\"] < dfFinal[\"PRES_STOCK_1_Dias_Antes\"]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas 1, 4, 5 e 10 dias antes:\n",
    "\n",
    "- INSTRANSIT\n",
    "- EXPECTED\n",
    "- SELLOUT\n",
    "- CICLOS\n",
    "- Dias para Rotura\n",
    "- Adequação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantos dias antes:\n",
    "\n",
    "diasMet = [4, 5, 10]\n",
    "\n",
    "# Função para colunas de dias anteriores\n",
    "\n",
    "def dias(df, dia, coluna):         #dia é quantos dias antes\n",
    "    a=int(dia)\n",
    "\n",
    "    valores = df.groupby(['DESC_ARTIGO', 'STORE'])[coluna].transform(lambda x: x.shift(a))\n",
    "    valores[:a] = np.nan\n",
    "    \n",
    "    df.loc[:,f'{coluna}_{a}_Dias_Antes'] = valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - STOCK\n",
    "> - SELLOUT\n",
    "> - INTRANSIT\n",
    "> - EXPECTED \n",
    "> - STK\n",
    "> - FORNECIMENTO\n",
    "> - CICLOS\n",
    "> - Adequação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 19.4 s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfFinal[\"STK\"] = dfFinal[\"STOCK\"] + dfFinal[\"INTRANSIT\"] + dfFinal[\"EXPECTED\"]\n",
    "dfFinal[\"STK_1_Dias_Antes\"] = dfFinal[\"STOCK_1_Dias_Antes\"] + dfFinal[\"INTRANSIT_1_Dias_Antes\"] + dfFinal[\"EXPECTED_1_Dias_Antes\"]\n",
    "\n",
    "dfFinal[\"FORNECIMENTO\"] = dfFinal[\"INTRANSIT\"] + dfFinal[\"EXPECTED\"]\n",
    "dfFinal[\"FORNECIMENTO_1_Dias_Antes\"] = dfFinal[\"INTRANSIT_1_Dias_Antes\"] + dfFinal[\"EXPECTED_1_Dias_Antes\"]\n",
    "\n",
    "dfFinal[\"CICLOS\"] = dfFinal[\"STOCK\"]/dfFinal[\"PRES_STOCK\"]\n",
    "dfFinal[\"CICLOS_1_Dias_Antes\"] = dfFinal[\"STOCK_1_Dias_Antes\"]/dfFinal[\"PRES_STOCK_1_Dias_Antes\"]\n",
    "dfFinal[\"CICLOS\"] = dfFinal[\"CICLOS\"].fillna(0)\n",
    "dfFinal.loc[np.isinf(dfFinal['CICLOS']), \"CICLOS\"] = 0\n",
    "\n",
    "dfFinal[\"Adequacao\"]= np.where(dfFinal[\"CICLOS\"] > 1.1, \"Stock Suficiente\", \n",
    "                      np.where((dfFinal[\"CICLOS\"] <= 1.1) & (dfFinal[\"INTRANSIT\"]+dfFinal[\"EXPECTED\"]+dfFinal[\"STOCK\"]>=dfFinal[\"PRES_STOCK\"]), \"Stock Insuf c Forn Adequado\", \n",
    "                      np.where((dfFinal[\"CICLOS\"] <= 1.1) & (dfFinal[\"INTRANSIT\"]+dfFinal[\"EXPECTED\"]+dfFinal[\"STOCK\"]<dfFinal[\"PRES_STOCK\"]), \"Stock Insuf c Forn Desadequado\", \n",
    "                      \"\")))\n",
    "dfFinal[\"Adequacao_1_Dias_Antes\"]= np.where(dfFinal[\"CICLOS_1_Dias_Antes\"] > 1.1, \"Stock Suficiente\", \n",
    "                      np.where((dfFinal[\"CICLOS_1_Dias_Antes\"] <= 1.1) & (dfFinal[\"INTRANSIT_1_Dias_Antes\"]+dfFinal[\"EXPECTED_1_Dias_Antes\"]+dfFinal[\"STOCK_1_Dias_Antes\"]>=dfFinal[\"PRES_STOCK_1_Dias_Antes\"]), \"Stock Insuf c Forn Adequado\", \n",
    "                      np.where((dfFinal[\"CICLOS_1_Dias_Antes\"] <= 1.1) & (dfFinal[\"INTRANSIT_1_Dias_Antes\"]+dfFinal[\"EXPECTED_1_Dias_Antes\"]+dfFinal[\"STOCK_1_Dias_Antes\"]<dfFinal[\"PRES_STOCK_1_Dias_Antes\"]), \"Stock Insuf c Forn Desadequado\", \n",
    "                      \"\")))\n",
    "\n",
    "\n",
    "for i in diasMet:   \n",
    "    dias(dfFinal, i, \"STOCK\")\n",
    "    dias(dfFinal, i, \"SELLOUT\")\n",
    "    dias(dfFinal, i, \"INTRANSIT\")\n",
    "    dias(dfFinal, i, \"EXPECTED\")\n",
    "    dias(dfFinal, i, \"STK\")\n",
    "    dias(dfFinal, i, \"FORNECIMENTO\")\n",
    "    dias(dfFinal, i, \"CICLOS\")\n",
    "    dias(dfFinal, i, \"Adequacao\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - MSA\n",
    "> - Balance: sellout / soma stock disponível mais transito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14.8 s\n",
      "Wall time: 34.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# MSA do dia = média dos sellouts dos 10 dias anteriores ao dia em causa\n",
    "\n",
    "dfFinal[\"MSA10\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes'].transform(lambda x: x.rolling(window=10).mean())\n",
    "dfFinal[\"MSA10Dp\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes'].transform(lambda x: x.rolling(window=10).std())\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"MSA10\")\n",
    "    \n",
    "\n",
    "dfFinal[\"MSA20\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes'].transform(lambda x: x.rolling(window=20).mean())\n",
    "dfFinal[\"MSA20Dp\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes'].transform(lambda x: x.rolling(window=20).std())\n",
    "  \n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"MSA20\")\n",
    "\n",
    "\n",
    "# Balance do dia = razão entre o sellout médio e o stock para o dia actual\n",
    "dfFinal[\"Balance\"] =  dfFinal[\"MSA10\"] / dfFinal[\"STK\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    \n",
    "    \n",
    "    valores = i * dfFinal[\"Balance\"].shift(i)\n",
    "    valores[:i] = np.nan\n",
    "    \n",
    "    dfFinal.loc[:,'%s_%s_Dias_Antes' % (\"Balance\", i)] = valores\n",
    "\n",
    "    \n",
    "\n",
    "dfFinal.loc[dfFinal.STK == 0, \"Balance\"] = 2\n",
    "dfFinal.Balance = dfFinal.Balance.fillna(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colunas de métricas 30, 60 e 120 dias antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "diasMetHist = [30, 60, 120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- Balance raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6.19 s\n",
      "Wall time: 24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfFinal[\"Balance_Raw\"] =  dfFinal[\"SELLOUT\"] / dfFinal[\"STK\"]\n",
    "dfFinal.loc[dfFinal.STK == 0, \"Balance_Raw\"] = 2\n",
    "\n",
    "dfFinal[\"Balance_Raw_Count1\"] = np.where(dfFinal[\"Balance_Raw\"] < 0.5, 1, 0)\n",
    "\n",
    "dfFinal[\"Balance_Raw_Count2\"] = np.where(dfFinal[\"Balance_Raw\"] < 0.8, 1, 0)\n",
    "\n",
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Balance_Raw_Count1_{i}\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Balance_Raw_Count1'].transform(lambda x: x.rolling(window=i, min_periods=1).mean())\n",
    "    dfFinal[f\"Percentagem_Balance_Raw_Count2_{i}\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Balance_Raw_Count2'].transform(lambda x: x.rolling(window=i, min_periods=1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Efeito fim de semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11 s\n",
      "Wall time: 35.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#dfFinal['SELLOUT_fds'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([4,5,6])][\"SELLOUT\"].copy()\n",
    "#dfFinal['SELLOUT_semana'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([0,1,2,3])][\"SELLOUT\"].copy()\n",
    "dfFinal['SELLOUT_fds_1_Dias_Antes'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([5,6,0])][\"SELLOUT_1_Dias_Antes\"].copy()\n",
    "dfFinal['SELLOUT_semana_1_Dias_Antes'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([1,2,3,4])][\"SELLOUT_1_Dias_Antes\"].copy()\n",
    "\n",
    "dfFinal['SELLOUT_fds_Medio'] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())\n",
    "dfFinal['SELLOUT_semana_Medio'] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())\n",
    "\n",
    "\n",
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Efeito_Fds_{i}\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "                                               .transform(lambda x: x.rolling(window=i, min_periods=1).mean())/\n",
    "                                              (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "                                               .transform(lambda x: x.rolling(window=i, min_periods=1).mean())))-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Volatilidade\n",
    "> - Rotura \n",
    "> - Supply\n",
    "> - Percentagem de dias em Stock Borderline\n",
    "> - Percentagem de dias de Linear Incompleto\n",
    "> - Percentagem de dias sem vendas\n",
    "> - Tempo indisponível\n",
    "> - Vendas perdidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 54.8 s\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfFinal=dfFinal.copy()\n",
    "# Sempre que é pedido abastecimento, fazer com que seja 1\n",
    "dfFinal[\"New_Supply\"] = np.where((dfFinal[\"EXPECTED_1_Dias_Antes\"]==0) & (dfFinal[\"EXPECTED\"]>0), 1, 0)\n",
    "dfFinal[\"Percentagem_Stock_Borderline_1_Dias_Antes\"] = np.where(dfFinal[\"STOCK_1_Dias_Antes\"]<0.2*dfFinal[\"PRES_STOCK_1_Dias_Antes\"], 1, 0)\n",
    "dfFinal[\"Percentagem_Linear_Incompleto_1_Dias_Antes\"] = np.where(dfFinal[\"STOCK_1_Dias_Antes\"]<dfFinal[\"PRES_STOCK_1_Dias_Antes\"], 1, 0)\n",
    "dfFinal[\"Sem_Vendas_1_Dias_Antes\"] = np.where(dfFinal[\"SELLOUT_1_Dias_Antes\"] == 0, 1, 0)\n",
    "dfFinal[\"Dias_Indisponivel_1_Dias_Antes\"] = np.where(dfFinal[\"ROTURA_1_Dias_Antes\"]==1, 1, 0)\n",
    "\n",
    "dfFinal['ROTURA_fds_1_Dias_Antes'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([5,6,0])][\"ROTURA_1_Dias_Antes\"].copy()\n",
    "dfFinal['ROTURA_semana_1_Dias_Antes'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([1,2,3,4])][\"ROTURA_1_Dias_Antes\"].copy()\n",
    "\n",
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Volatilidade_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes']\\\n",
    "                                                .transform(lambda x: x.rolling(window=i, min_periods=1).std()) /\n",
    "                                                dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes']\\\n",
    "                                                .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "    \n",
    "    dfFinal[f\"Percentagem_Roturas_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_1_Dias_Antes']\\\n",
    "                                           .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "    \n",
    "    dfFinal[f\"Percentagem_Roturas_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_1_Dias_Antes']\\\n",
    "                                           .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "    \n",
    "    dfFinal[f\"Percentagem_Supply_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['New_Supply']\\\n",
    "                                          .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "\n",
    "    dfFinal[f\"Percentagem_Dias_Stock_Borderline_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Percentagem_Stock_Borderline_1_Dias_Antes']\\\n",
    "                                                         .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "\n",
    "    dfFinal[f\"Percentagem_Dias_Linear_Incompleto_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Percentagem_Linear_Incompleto_1_Dias_Antes']\\\n",
    "                                                          .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "    \n",
    "    dfFinal[f\"Percentagem_Dias_Sem_Vendas_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Sem_Vendas_1_Dias_Antes']\\\n",
    "                                                   .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "    \n",
    "    dfFinal[f\"Percentagem_Dias_Indisponivel_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Dias_Indisponivel_1_Dias_Antes']\\\n",
    "                                                     .transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n",
    "\n",
    "    dfFinal[f\"Vendas_Perdidas_em_{i}_Dias\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_fds_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).sum())\\\n",
    "                                                  * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).mean())) \\\n",
    "                                                  + \n",
    "                                               (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_semana_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).sum()) \\\n",
    "                                                  * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).mean())))\n",
    "    \n",
    "dfFinal.Percentagem_Volatilidade_60 = dfFinal.Percentagem_Volatilidade_60.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Tempo médio inter-supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10.1 s\n",
      "Wall time: 25.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfFinal=dfFinal.copy()\n",
    "dfFinal[\"InterSupply\"] = np.where(dfFinal[\"EXPECTED\"]==0, 1, 0)\n",
    "\n",
    "groups = (dfFinal['InterSupply'] != dfFinal['InterSupply'].shift()).cumsum()\n",
    "result = dfFinal.groupby(groups).agg({'DATA': 'first', 'DESC_ARTIGO': 'first', 'STORE': 'first', 'InterSupply': 'sum'}).reset_index(drop=True)\n",
    "result = result[result['InterSupply'] > 0]\n",
    "\n",
    "dfFinal = dfFinal.drop(columns=['InterSupply'])\n",
    "\n",
    "dfFinal = pd.merge(dfFinal, result, how=\"left\", on=[\"DATA\",\"DESC_ARTIGO\", \"STORE\"])\n",
    "\n",
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_InterSupplyMed_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['InterSupply'].transform(lambda x: x.rolling(window=i, min_periods=1).mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=green> Função Contagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# Define a function to calculate weekday and weekend counts\n",
    "def contagem5dias(date):\n",
    "    weekday_count = 0\n",
    "    weekend_count = 0\n",
    "    \n",
    "    for _ in range(5):\n",
    "        if date.weekday() < 4:  # Monday to Thursday\n",
    "            weekday_count += 1\n",
    "        else:  # Friday to Sunday\n",
    "            weekend_count += 1\n",
    "        \n",
    "        date += timedelta(days=1)\n",
    "    \n",
    "    return pd.Series({\"CONTAGEM_SEMANA\": weekday_count, \"CONTAGEM_FIMSEMANA\": weekend_count})\n",
    "\n",
    "\n",
    "# Define a function to calculate weekday and weekend counts\n",
    "def contagem3dias(date):\n",
    "    weekday_count = 0\n",
    "    weekend_count = 0\n",
    "    \n",
    "    for _ in range(3):\n",
    "        if date.weekday() < 4:  # Monday to Thursday\n",
    "            weekday_count += 1\n",
    "        else:  # Friday to Sunday\n",
    "            weekend_count += 1\n",
    "        \n",
    "        date += timedelta(days=1)\n",
    "    \n",
    "    return pd.Series({\"CONTAGEM_SEMANA3\": weekday_count, \"CONTAGEM_FIMSEMANA3\": weekend_count})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Smart 3 dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 53s\n",
      "Wall time: 5min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "dfFinal[[\"CONTAGEM_SEMANA3\", \"CONTAGEM_FIMSEMANA3\"]] = dfFinal[\"DATA\"].apply(contagem3dias)\n",
    "dfFinal['CONTAGEM_FIMSEMANA3'] = dfFinal['CONTAGEM_FIMSEMANA3'].shift(-1)\n",
    "dfFinal['CONTAGEM_SEMANA3'] = dfFinal['CONTAGEM_SEMANA3'].shift(-1)\n",
    "\n",
    "dfFinal[\"Balance_Smart3\"] = ((\n",
    "    (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_FIMSEMANA3'])\n",
    "    +\n",
    "    (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_SEMANA3']))\n",
    "     / dfFinal[\"STK\"])\n",
    "\n",
    "dfFinal[\"Balance_Smart3\"] = np.where(dfFinal[\"STK\"]<=0, -1, dfFinal[\"Balance_Smart3\"])\n",
    "dfFinal[\"Balance_Smart_3_Dias_Antes\"] = dfFinal[\"Balance_Smart3\"].shift(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Smart 5 dias antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 53s\n",
      "Wall time: 5min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "dfFinal[[\"CONTAGEM_SEMANA\", \"CONTAGEM_FIMSEMANA\"]] = dfFinal[\"DATA\"].apply(contagem5dias)\n",
    "dfFinal['CONTAGEM_FIMSEMANA'] = dfFinal['CONTAGEM_FIMSEMANA'].shift(-1)\n",
    "dfFinal['CONTAGEM_SEMANA'] = dfFinal['CONTAGEM_SEMANA'].shift(-1)\n",
    "\n",
    "\n",
    "dfFinal[\"Balance_Smart\"] = ((\n",
    "    (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_FIMSEMANA'])\n",
    "    +\n",
    "    (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_SEMANA']))\n",
    "     / dfFinal[\"STK\"])\n",
    "\n",
    "dfFinal[\"Balance_Smart\"] = np.where(dfFinal[\"STK\"]<=0, -1, dfFinal[\"Balance_Smart\"])\n",
    "dfFinal[\"Balance_Smart_5_Dias_Antes\"] = dfFinal[\"Balance_Smart\"].shift(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Dias para rotura de Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal = dfFinal.copy()\n",
    "# Dias para a rotura mas com o Sellout médio (móvel) dos últimos 10 dias \n",
    "dfFinal[\"Dias_para_Rotura_Stock\"] = dfFinal[\"STK_1_Dias_Antes\"] / (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_FIMSEMANA'])+(dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_SEMANA'])\n",
    "\n",
    "dfFinal[\"Dias_para_Rotura_Stock_5_Dias_Antes\"] = dfFinal[\"Dias_para_Rotura_Stock\"].shift(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Dias para rotura de Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a métrica: Preslinear / med(Sellouts 10 dias)\n",
    "dfFinal['Dias_Duracao_Linear'] = dfFinal[\"PRES_STOCK\"] / (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_FIMSEMANA'])+(dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_SEMANA'])\n",
    "\n",
    "dfFinal[\"Dias_Duracao_Linear_5_Dias_Antes\"] = dfFinal[\"Dias_Duracao_Linear\"].shift(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Desempenho\n",
    "> - Volatilidade de Sellout\n",
    "> - Sensibilidade\n",
    "> - PS Classificação\n",
    "> - Risco de Rotura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.33 s\n",
      "Wall time: 5.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfFinal[\"Desempenho_de_Vendas_60\"] = np.where((dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>=0) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]<=0.151), \"Vendas com desempenho satisfatório\",\n",
    "                                     np.where((dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>0.151) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]<=0.317), \"Vendas com desempenho mediano\",\n",
    "                                     np.where((dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>0.317) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]<=0.433), \"Vendas com desempenho insatisfatório\",\n",
    "                                              \"Vendas com desempenho muito insatisfatório\")))\n",
    "\n",
    "\n",
    "                                     #np.where((dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>0.433) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]<=1), \n",
    "\n",
    "dfFinal[\"Volatilidade_SELLOUT\"] = np.where(dfFinal[\"Percentagem_Volatilidade_60\"] > 1.095, \" e com alta volatilidade de sellout.\",\n",
    "                                  np.where(dfFinal[\"Percentagem_Volatilidade_60\"] > 0.91 , \" e com média volatilidade de sellout.\",\n",
    "                                  np.where(dfFinal[\"Percentagem_Volatilidade_60\"] > 0.76 , \" e com baixa volatilidade de sellout.\",\n",
    "                                                                                           \" e com muito baixa volatilidade de sellout.\")))\n",
    "\n",
    "\n",
    "dfFinal[\"Sensibilidade_Rotura\"] = np.where(dfFinal[\"Percentagem_Roturas_60\"]>0.33, \" Produto com muito elevada propensão para rotura\",\n",
    "                                 np.where(dfFinal[\"Percentagem_Roturas_60\"]>0.166666, \" Produto com elevada propensão para rotura\",\n",
    "                                 np.where(dfFinal[\"Percentagem_Roturas_60\"]>0.017, \" Produto com moderada propensão para rotura\",\n",
    "                                 np.where(dfFinal[\"Percentagem_Roturas_60\"]>0, \" Produto com baixa propensão para rotura\",\n",
    "                                 \" Produto com muito baixa ou nula propensão para rotura\"))))\n",
    "\n",
    "dfFinal[\"Order_Sensibilidade_Rotura\"] = np.where(dfFinal[\"Percentagem_Roturas_60\"]>0.33, 5,\n",
    "                                 np.where(dfFinal[\"Percentagem_Roturas_60\"]>0.166666, 4,\n",
    "                                 np.where(dfFinal[\"Percentagem_Roturas_60\"]>0.017, 3,\n",
    "                                 np.where(dfFinal[\"Percentagem_Roturas_60\"]>0, 2,\n",
    "                                 1))))\n",
    "\n",
    "dfFinal[\"PS_Classificacao_60\"] = np.where((dfFinal[\"Percentagem_Dias_Linear_Incompleto_60\"] > 0.51) & (dfFinal[\"Percentagem_Balance_Raw_Count1_60\"]==1) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>0.29), \" e com PS excessivo.\",\n",
    "                                 np.where((dfFinal[\"Percentagem_Dias_Linear_Incompleto_60\"] > 0.51) & (dfFinal[\"Percentagem_Balance_Raw_Count1_60\"]==0) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>0.29), \" e com PS excessivo.\",\n",
    "                                 np.where((dfFinal[\"Percentagem_Dias_Linear_Incompleto_60\"] > 0.31) & (dfFinal[\"Percentagem_Balance_Raw_Count1_60\"]==1) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]>0.29), \" e com PS moderadamente excessivo.\",\n",
    "                                 np.where((dfFinal[\"Percentagem_Dias_Linear_Incompleto_60\"] < 0.07) & (dfFinal[\"Percentagem_Balance_Raw_Count1_60\"]<0.8) & (dfFinal[\"Percentagem_Dias_Sem_Vendas_60\"]<0.07), \" e com PS escasso.\", \n",
    "                                                                                                                                                                                                            \" e com PS equilibrado.\"))))\n",
    "\n",
    "dfFinal[\"RISCO\"] = np.where((dfFinal.Balance_Smart > 2) & (dfFinal.CICLOS_5_Dias_Antes < 0.2) & (dfFinal.Percentagem_Roturas_120 > 5), 1,\n",
    "                   np.where((dfFinal.Balance_Smart > 1) & (dfFinal.Balance_Smart < 2) & (dfFinal.CICLOS_5_Dias_Antes < 0.6) & (dfFinal.Percentagem_Roturas_120 < 3), 2, 3))\n",
    "\n",
    "dfFinal[\"RISCO_ROTURA\"] = np.where((dfFinal.Balance_Smart >= 12.5) | (dfFinal.Balance_Smart < 0), \" O produto apresenta hoje muito elevada probabilidade de rotura a 5 dias caso não haja fornecimento.\", \n",
    "                          np.where((dfFinal.Balance_Smart >= 1.1) & (dfFinal.Balance_Smart < 12.5), \" O produto apresenta hoje elevada probabilidade de rotura a 5 dias caso não haja fornecimento.\",\n",
    "                          np.where((dfFinal.Balance_Smart >= 0.833) & (dfFinal.Balance_Smart < 1.1), \" O produto apresenta hoje média probabilidade de rotura a 5 dias caso não haja fornecimento.\",\n",
    "                          np.where((dfFinal.Balance_Smart >= 0.087) & (dfFinal.Balance_Smart < 0.833), \" O produto apresenta hoje baixa probabilidade de rotura a 5 dias caso não haja fornecimento.\", \n",
    "                                                                                                         \" O produto apresenta hoje muito baixa ou nula probabilidade de rotura a 5 dias caso não haja fornecimento.\"))))         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Conclusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Conclusao1\"] = dfFinal[\"Desempenho_de_Vendas_60\"] + dfFinal[\"Volatilidade_SELLOUT\"] \n",
    "dfFinal[\"Conclusao2\"] = dfFinal[\"Sensibilidade_Rotura\"] + dfFinal[\"PS_Classificacao_60\"] \n",
    "dfFinal[\"Conclusao3\"] = dfFinal[\"RISCO_ROTURA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ano Homólogo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.4 s\n",
      "Wall time: 46.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Ler o ficheiro\n",
    "\n",
    "df_2022 = client.query_df('SELECT * FROM Delta_2022')\n",
    "df_2022 = df_2022.sort_values(by = \"DATA\")\n",
    "dfFinal = pd.concat([df_2022,dfFinal])\n",
    "dfFinal.DATA = pd.to_datetime(dfFinal['DATA'], format='%Y-%m-%d') \n",
    "dfFinal = dfFinal.sort_values(by = [\"DATA\", \"STORE\", \"DESC_ARTIGO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mes</th>\n",
       "      <th>STORE</th>\n",
       "      <th>EAN</th>\n",
       "      <th>Media_Sellout_Mensal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.600693e+12</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.600693e+12</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.609060e+12</td>\n",
       "      <td>9.354839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.609060e+12</td>\n",
       "      <td>6.096774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.601082e+12</td>\n",
       "      <td>0.709677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9364142</th>\n",
       "      <td>12</td>\n",
       "      <td>9665.0</td>\n",
       "      <td>5.601082e+12</td>\n",
       "      <td>0.258065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9364143</th>\n",
       "      <td>12</td>\n",
       "      <td>9665.0</td>\n",
       "      <td>5.601082e+12</td>\n",
       "      <td>0.193548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9364144</th>\n",
       "      <td>12</td>\n",
       "      <td>9665.0</td>\n",
       "      <td>5.601082e+12</td>\n",
       "      <td>0.064516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9364145</th>\n",
       "      <td>12</td>\n",
       "      <td>9665.0</td>\n",
       "      <td>5.601082e+12</td>\n",
       "      <td>0.225806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9364146</th>\n",
       "      <td>12</td>\n",
       "      <td>9665.0</td>\n",
       "      <td>5.601082e+12</td>\n",
       "      <td>0.322581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9364147 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mes   STORE           EAN  Media_Sellout_Mensal\n",
       "0          1     1.0  5.600693e+12              1.000000\n",
       "1          1     1.0  5.600693e+12              0.400000\n",
       "2          1     1.0  5.609060e+12              9.354839\n",
       "3          1     1.0  5.609060e+12              6.096774\n",
       "4          1     1.0  5.601082e+12              0.709677\n",
       "...      ...     ...           ...                   ...\n",
       "9364142   12  9665.0  5.601082e+12              0.258065\n",
       "9364143   12  9665.0  5.601082e+12              0.193548\n",
       "9364144   12  9665.0  5.601082e+12              0.064516\n",
       "9364145   12  9665.0  5.601082e+12              0.225806\n",
       "9364146   12  9665.0  5.601082e+12              0.322581\n",
       "\n",
       "[9364147 rows x 4 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFinal[(dfFinal.Ano==2022)][['Mes', 'STORE', 'EAN', 'Media_Sellout_Mensal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year and month from the 'DATA' column\n",
    "dfFinal['Ano'] = dfFinal['DATA'].dt.year\n",
    "dfFinal['Mes'] = dfFinal['DATA'].dt.month\n",
    "\n",
    "# Média para o mês actual e para o mês anterior\n",
    "dfFinal['Media_Sellout_Mensal'] = dfFinal.groupby(['Ano', 'Mes', 'STORE', 'EAN'])['SELLOUT'].transform('mean')\n",
    "dfFinal['Media_Sellout_Mensal_Mes_Anterior'] = dfFinal.groupby(['Ano', 'Mes', 'STORE', 'EAN'])['SELLOUT'].transform('mean').shift(1)\n",
    "\n",
    "# Calculate the monthly mean for the homologous month in the previous year\n",
    "media_2022 = dfFinal[dfFinal['Ano'] == 2022].groupby(['Mes', 'STORE', 'EAN'])['SELLOUT'].mean().reset_index()\n",
    "media_2022.rename(columns={'SELLOUT': 'Media_Sellout_Mensal_Homologo'}, inplace=True)\n",
    "\n",
    "# Voltar a colocar a média homóloga no DataFrame\n",
    "dfFinal = dfFinal.drop(columns=(\"Media_Sellout_Mensal_Homologo\"))\n",
    "dfFinal = dfFinal.merge(media_2022, on=['Mes', 'STORE', 'EAN'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>Escrever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dias certos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"ROTURA\"] = np.where(dfFinal[\"ROTURA\"]==1, \"ROTURA\", \"PRESENTE\")\n",
    "dfFinal['Subinsignia'] = dfFinal['STORE_NAME'].str.split().str[0]\n",
    "dfFinalEscrever = dfFinal.copy()\n",
    "\n",
    "dfEscrever120 = dfFinalEscrever[dfFinalEscrever.DATA.between(dfFinalEscrever.DATA.unique()[-121],dfFinalEscrever.DATA.unique()[-1])].copy()\n",
    "dfFinalEscrever = dfFinalEscrever.dropna(subset=['SELLOUT'])\n",
    "dfFinalEscrever = dfFinalEscrever.dropna(subset=['SELLOUT_fds_Medio'])\n",
    "\n",
    "\n",
    "# Ficheiro Dia, Mês e 120 dias\n",
    "dfEscreverDia = dfFinalEscrever[dfFinalEscrever.DATA == dfFinalEscrever.DATA.unique()[-1]].copy()\n",
    "\n",
    "dfFinalEscrever = dfFinalEscrever.dropna(subset=['Balance_Smart'])\n",
    "dfEscreverMes = dfFinalEscrever[dfFinalEscrever.DATA.between(dfFinalEscrever.DATA.unique()[-31],dfFinalEscrever.DATA.unique()[-1])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA</th>\n",
       "      <th>DESC_ARTIGO</th>\n",
       "      <th>STORE_NAME</th>\n",
       "      <th>FLUXO</th>\n",
       "      <th>EAN</th>\n",
       "      <th>STORE</th>\n",
       "      <th>STOCK</th>\n",
       "      <th>SELLOUT</th>\n",
       "      <th>INTRANSIT</th>\n",
       "      <th>EXPECTED</th>\n",
       "      <th>...</th>\n",
       "      <th>Balance_Smart</th>\n",
       "      <th>Balance_Smart_5_Dias_Antes</th>\n",
       "      <th>Dias_para_Rotura_Stock</th>\n",
       "      <th>Dias_para_Rotura_Stock_5_Dias_Antes</th>\n",
       "      <th>Dias_Duracao_Linear</th>\n",
       "      <th>Dias_Duracao_Linear_5_Dias_Antes</th>\n",
       "      <th>InterSupply</th>\n",
       "      <th>Media_Sellout_Mensal</th>\n",
       "      <th>Media_Sellout_Mensal_Mes_Anterior</th>\n",
       "      <th>Media_Sellout_Mensal_Homologo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11974049</th>\n",
       "      <td>2023-10-03</td>\n",
       "      <td>100% SALICÓRNIA MOIDA 45G</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>PBL</td>\n",
       "      <td>5.600693e+12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064393</td>\n",
       "      <td>0.180026</td>\n",
       "      <td>42.779412</td>\n",
       "      <td>11.696594</td>\n",
       "      <td>33.029412</td>\n",
       "      <td>8.275542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.354839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11974050</th>\n",
       "      <td>2023-10-03</td>\n",
       "      <td>AZEITONA GALEGA QAMPO FR 210G</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>PBL</td>\n",
       "      <td>5.600693e+12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075066</td>\n",
       "      <td>0.432306</td>\n",
       "      <td>24.392157</td>\n",
       "      <td>16.735294</td>\n",
       "      <td>24.058824</td>\n",
       "      <td>15.735294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.741935</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11974051</th>\n",
       "      <td>2023-10-03</td>\n",
       "      <td>AZEITONA GORDAL 210G</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>PBL</td>\n",
       "      <td>5.600693e+12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171469</td>\n",
       "      <td>0.013495</td>\n",
       "      <td>11.703431</td>\n",
       "      <td>186.894118</td>\n",
       "      <td>4.661765</td>\n",
       "      <td>30.894118</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>1.741935</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11974052</th>\n",
       "      <td>2023-10-03</td>\n",
       "      <td>AZEITONA PRETA OXID DESC FRA QAMPO 160 G</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>PBL</td>\n",
       "      <td>5.600693e+12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223982</td>\n",
       "      <td>0.166356</td>\n",
       "      <td>18.754289</td>\n",
       "      <td>14.126598</td>\n",
       "      <td>18.889706</td>\n",
       "      <td>5.365729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.709677</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11974053</th>\n",
       "      <td>2023-10-03</td>\n",
       "      <td>AZEITONA RETALHADA 210G QAMPO</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>PBL</td>\n",
       "      <td>5.600693e+12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032373</td>\n",
       "      <td>0.064393</td>\n",
       "      <td>43.137771</td>\n",
       "      <td>42.779412</td>\n",
       "      <td>42.111455</td>\n",
       "      <td>33.029412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.161290</td>\n",
       "      <td>3.709677</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12941280</th>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>PACK CAFÉ DELTA Q GRAND MYTHIQ 72+8 CAP</td>\n",
       "      <td>CBD GRIJÓ</td>\n",
       "      <td>PBL</td>\n",
       "      <td>5.601082e+12</td>\n",
       "      <td>9665.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.134409</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.523810</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>9.238095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12941281</th>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>PACK CAFÉ DELTA Q GRAND QALIDUS 72+8 CAP</td>\n",
       "      <td>CBD GRIJÓ</td>\n",
       "      <td>PBL</td>\n",
       "      <td>5.601082e+12</td>\n",
       "      <td>9665.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.888889</td>\n",
       "      <td>inf</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12941282</th>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>PACK CAFÉ DELTA Q INTENSIDADE 40CAP</td>\n",
       "      <td>CBD GRIJÓ</td>\n",
       "      <td>PBS14</td>\n",
       "      <td>5.601082e+12</td>\n",
       "      <td>9665.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037698</td>\n",
       "      <td>inf</td>\n",
       "      <td>33.933333</td>\n",
       "      <td>inf</td>\n",
       "      <td>19.533333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12941283</th>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>PACK CAFÉ DELTA Q QALIDUS 60CAP</td>\n",
       "      <td>CBD GRIJÓ</td>\n",
       "      <td>PBS14</td>\n",
       "      <td>5.601082e+12</td>\n",
       "      <td>9665.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090278</td>\n",
       "      <td>0.089372</td>\n",
       "      <td>16.444444</td>\n",
       "      <td>15.888889</td>\n",
       "      <td>6.444444</td>\n",
       "      <td>11.888889</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12941284</th>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>PACK CAFÉ DELTA Q QHARISMA 40 CAP</td>\n",
       "      <td>CBD GRIJÓ</td>\n",
       "      <td>PBL</td>\n",
       "      <td>5.601082e+12</td>\n",
       "      <td>9665.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012452</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>116.111111</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>32.111111</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>964011 rows × 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               DATA                               DESC_ARTIGO      STORE_NAME  \\\n",
       "11974049 2023-10-03                 100% SALICÓRNIA MOIDA 45G  CNT MATOSINHOS   \n",
       "11974050 2023-10-03             AZEITONA GALEGA QAMPO FR 210G  CNT MATOSINHOS   \n",
       "11974051 2023-10-03                      AZEITONA GORDAL 210G  CNT MATOSINHOS   \n",
       "11974052 2023-10-03  AZEITONA PRETA OXID DESC FRA QAMPO 160 G  CNT MATOSINHOS   \n",
       "11974053 2023-10-03             AZEITONA RETALHADA 210G QAMPO  CNT MATOSINHOS   \n",
       "...             ...                                       ...             ...   \n",
       "12941280 2023-11-02   PACK CAFÉ DELTA Q GRAND MYTHIQ 72+8 CAP       CBD GRIJÓ   \n",
       "12941281 2023-11-02  PACK CAFÉ DELTA Q GRAND QALIDUS 72+8 CAP       CBD GRIJÓ   \n",
       "12941282 2023-11-02       PACK CAFÉ DELTA Q INTENSIDADE 40CAP       CBD GRIJÓ   \n",
       "12941283 2023-11-02           PACK CAFÉ DELTA Q QALIDUS 60CAP       CBD GRIJÓ   \n",
       "12941284 2023-11-02         PACK CAFÉ DELTA Q QHARISMA 40 CAP       CBD GRIJÓ   \n",
       "\n",
       "          FLUXO           EAN   STORE  STOCK  SELLOUT  INTRANSIT  EXPECTED  \\\n",
       "11974049    PBL  5.600693e+12     1.0   13.0      0.0        0.0       0.0   \n",
       "11974050    PBL  5.600693e+12     1.0  122.0      0.0        0.0      12.0   \n",
       "11974051    PBL  5.600693e+12     1.0   19.0      0.0        0.0       0.0   \n",
       "11974052    PBL  5.600693e+12     1.0  114.0      4.0        0.0       0.0   \n",
       "11974053    PBL  5.600693e+12     1.0  123.0      0.0        0.0       0.0   \n",
       "...         ...           ...     ...    ...      ...        ...       ...   \n",
       "12941280    PBL  5.601082e+12  9665.0    6.0      1.0        0.0       0.0   \n",
       "12941281    PBL  5.601082e+12  9665.0   12.0      2.0        0.0       6.0   \n",
       "12941282  PBS14  5.601082e+12  9665.0   17.0      0.0        0.0       0.0   \n",
       "12941283  PBS14  5.601082e+12  9665.0   16.0      0.0        0.0       0.0   \n",
       "12941284    PBL  5.601082e+12  9665.0   29.0      0.0        0.0       0.0   \n",
       "\n",
       "          ...  Balance_Smart Balance_Smart_5_Dias_Antes  \\\n",
       "11974049  ...       0.064393                   0.180026   \n",
       "11974050  ...       0.075066                   0.432306   \n",
       "11974051  ...       0.171469                   0.013495   \n",
       "11974052  ...       0.223982                   0.166356   \n",
       "11974053  ...       0.032373                   0.064393   \n",
       "...       ...            ...                        ...   \n",
       "12941280  ...       0.305556                   0.134409   \n",
       "12941281  ...       0.234568                   0.000000   \n",
       "12941282  ...       0.000000                   0.037698   \n",
       "12941283  ...       0.090278                   0.089372   \n",
       "12941284  ...       0.012452                   0.240741   \n",
       "\n",
       "         Dias_para_Rotura_Stock Dias_para_Rotura_Stock_5_Dias_Antes  \\\n",
       "11974049              42.779412                           11.696594   \n",
       "11974050              24.392157                           16.735294   \n",
       "11974051              11.703431                          186.894118   \n",
       "11974052              18.754289                           14.126598   \n",
       "11974053              43.137771                           42.779412   \n",
       "...                         ...                                 ...   \n",
       "12941280               5.000000                            9.523810   \n",
       "12941281               5.888889                                 inf   \n",
       "12941282                    inf                           33.933333   \n",
       "12941283              16.444444                           15.888889   \n",
       "12941284             116.111111                            7.333333   \n",
       "\n",
       "         Dias_Duracao_Linear Dias_Duracao_Linear_5_Dias_Antes InterSupply  \\\n",
       "11974049           33.029412                         8.275542         NaN   \n",
       "11974050           24.058824                        15.735294         NaN   \n",
       "11974051            4.661765                        30.894118         7.0   \n",
       "11974052           18.889706                         5.365729         NaN   \n",
       "11974053           42.111455                        33.029412         NaN   \n",
       "...                      ...                              ...         ...   \n",
       "12941280            4.333333                         9.238095         NaN   \n",
       "12941281            3.222222                              inf         NaN   \n",
       "12941282                 inf                        19.533333         NaN   \n",
       "12941283            6.444444                        11.888889         6.0   \n",
       "12941284           32.111111                         7.333333         1.0   \n",
       "\n",
       "         Media_Sellout_Mensal Media_Sellout_Mensal_Mes_Anterior  \\\n",
       "11974049             0.322581                          0.064516   \n",
       "11974050             1.741935                          0.322581   \n",
       "11974051             0.516129                          1.741935   \n",
       "11974052             3.709677                          0.516129   \n",
       "11974053             1.161290                          3.709677   \n",
       "...                       ...                               ...   \n",
       "12941280             0.500000                          0.500000   \n",
       "12941281             2.000000                          0.500000   \n",
       "12941282             0.000000                          2.000000   \n",
       "12941283             0.000000                          0.000000   \n",
       "12941284             0.000000                          0.000000   \n",
       "\n",
       "         Media_Sellout_Mensal_Homologo  \n",
       "11974049                      0.354839  \n",
       "11974050                           NaN  \n",
       "11974051                           NaN  \n",
       "11974052                           NaN  \n",
       "11974053                           NaN  \n",
       "...                                ...  \n",
       "12941280                           NaN  \n",
       "12941281                           NaN  \n",
       "12941282                      0.068966  \n",
       "12941283                      0.103448  \n",
       "12941284                      0.241379  \n",
       "\n",
       "[964011 rows x 146 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEscreverMes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfFinal.DESC_ARTIGO.unique())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dfFinal = dfFinal.copy()\n",
    "# Extract year and month from the 'date' column\n",
    "dfFinal['Ano'] = dfFinal['DATA'].dt.year\n",
    "dfFinal['Ano_Anterior'] = dfFinal['Ano'] + 1\n",
    "dfFinal['Mes'] = dfFinal['DATA'].dt.month\n",
    "\n",
    "# Mês Actual\n",
    "media_mes_actual = dfFinal.groupby(['Ano', 'Mes', \"STORE\", \"EAN\"])['SELLOUT'].mean().reset_index()\n",
    "media_mes_actual = media_mes_actual.rename(columns={'SELLOUT': 'Media_Sellout_Mensal'})\n",
    "\n",
    "# Mês Homólogo\n",
    "media_mes_homologo = dfFinal.groupby(['Ano_Anterior', 'Mes', \"STORE\", \"EAN\"])['SELLOUT'].mean().reset_index()\n",
    "media_mes_homologo = media_mes_homologo.rename(columns={'SELLOUT': 'Media_Sellout_Mensal_Homologo'})\n",
    "\n",
    "# Calculate the monthly mean for the previous month\n",
    "media_mes_anterior = dfFinal.groupby(['Ano', 'Mes', \"STORE\", \"EAN\"])['SELLOUT'].mean().shift(1).reset_index()\n",
    "media_mes_anterior.rename(columns={'SELLOUT': 'Media_Sellout_Mensal_Mes_Anterior'}, inplace=True)\n",
    "\n",
    "# Merge the monthly mean back into the original DataFrame\n",
    "dfFinal = dfFinal.merge(media_mes_actual, on=['Ano', 'Mes', \"STORE\", \"EAN\"], how=\"left\")\n",
    "dfFinal = dfFinal.merge(media_mes_homologo, left_on=['Ano', 'Mes', \"STORE\", \"EAN\"], right_on=['Ano_Anterior', 'Mes', \"STORE\", \"EAN\"], how=\"left\")\n",
    "dfFinal = dfFinal.merge(media_mes_anterior, on=['Ano', 'Mes', \"STORE\", \"EAN\"], how=\"left\")\n",
    "\n",
    "dfFinal = dfFinal.drop(columns = [\"Ano_Anterior_x\", \"Ano_Anterior_y\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clickhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clickhouse_connect\n",
    "from clickhouse_driver import Client\n",
    "from unidecode import unidecode\n",
    "\n",
    "client = clickhouse_connect.get_client(host='ch.brandsandninjas.com', \n",
    "                                       port=443, \n",
    "                                       username='chninja', \n",
    "                                       password='ku43ueqnB5Q0AYb2C4FsJRTc7qX',\n",
    "                                       database = \"Delta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A base Delta_dbd_Dia foi exportada para o clickhouse\n",
      "A base Delta_dbd_Mes foi exportada para o clickhouse\n",
      "CPU times: total: 6.3 s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Estabelecer a base a ser lida\n",
    "\n",
    "bases = [1, 2]\n",
    "\n",
    "for qualbase in bases:\n",
    "\n",
    "    if qualbase == 1:\n",
    "        baseCH = dfEscreverDia.copy()\n",
    "        tabela = \"Delta_dbd_Dia\" # BaseGoChillDia\n",
    "\n",
    "    elif qualbase == 2:\n",
    "        baseCH = dfEscreverMes.copy()\n",
    "        tabela = \"Delta_dbd_Mes\" # BaseGoChillMes\n",
    "\n",
    "    elif qualbase == 3:\n",
    "        baseCH = dfEscrever120.copy()\n",
    "        tabela = f\"Delta_dbd_120dias_{base_Clickhouse_120_nova}\" # BaseDelta120\n",
    "\n",
    "    elif qualbase == 4:\n",
    "        baseCH = dfNinjas.copy()\n",
    "        tabela = \"Delta_dbd_Audit\" # BaseDeltaNinja\n",
    "\n",
    "    ## Algumas alterações\n",
    "    baseCH['DATA']= pd.to_datetime(baseCH['DATA'], format='%Y-%m-%d')  # Passar a Data para datetime\n",
    "\n",
    "    baseCH.columns = [unidecode(col) for col in baseCH.columns]        # Tirar acentos e afins dos nomes das colunas porque \n",
    "                                                                       # o Clickhouse não gosta\n",
    "\n",
    "\n",
    "    ## Listas para definir os tipos de dados de cada coluna a inserit\n",
    "    data = [\"DATA\"]\n",
    "    texto = [col for col in baseCH.columns if baseCH[col].dtype == 'object' or baseCH[col].dtype == 'string']\n",
    "    inteiros = [col for col in baseCH.columns if baseCH[col].dtype == 'int64' or baseCH[col].dtype == 'int32']\n",
    "    floats = [col for col in baseCH.columns if baseCH[col].dtype == 'float64']\n",
    "\n",
    "\n",
    "    ## Mudar inteiros para floats porque senão não pode haver missing values\n",
    "    for col_name in inteiros:\n",
    "        baseCH[col_name] = baseCH[col_name].astype(float)\n",
    "\n",
    "    ## Missing values em strings também estragam tudo\n",
    "    baseCH[texto] = baseCH[texto].fillna(\"-\")\n",
    "    baseCH[texto] = baseCH[texto].astype(str)\n",
    "\n",
    "    #Função que vai fazer a schema\n",
    "    def schema(lista, tipo):\n",
    "        result_list = [f\"{element} {tipo}\" for element in lista]\n",
    "        return result_list\n",
    "\n",
    "    # Schema a ser feito\n",
    "    data1 = schema(data, \"Date\")\n",
    "    texto1 = schema(texto, \"String\")\n",
    "    inteiros1 = schema(inteiros, \"Float64\")\n",
    "    floats1 = schema(floats, \"Float64\")\n",
    "    total = tuple(data1 + texto1 + inteiros1 + floats1)\n",
    "    schema = ', '.join([column.replace(\"'\", \"\") for column in total])\n",
    "\n",
    "    # Split the input string by commas\n",
    "    parts = schema.split(', ')\n",
    "    # Process each part and wrap the first word in double quotes\n",
    "    output_parts = []\n",
    "    for part in parts:\n",
    "        words = part.split()\n",
    "        if words:\n",
    "            first_word = words[0]\n",
    "            remaining_words = ' '.join(words[1:])\n",
    "            output_part = f'\"{first_word}\" {remaining_words}'\n",
    "            output_parts.append(output_part)\n",
    "    # Join the modified parts back into a string\n",
    "    schema = ', '.join(output_parts)\n",
    "\n",
    "    # Eliminar tabela que possa existir no CH com o mesmo nome\n",
    "    client.command(f'DROP TABLE IF EXISTS {tabela}')\n",
    "\n",
    "    # Criar tabela no CH\n",
    "    client.command(f'''\n",
    "        CREATE TABLE IF NOT EXISTS {tabela} (\n",
    "            {schema}\n",
    "            ) ENGINE = MergeTree\n",
    "            ORDER BY (DATA)\n",
    "    ''')\n",
    "\n",
    "\n",
    "    # Exportar os dados para o clickhouse\n",
    "    client.insert_df(tabela, baseCH, column_names=baseCH.columns.tolist())\n",
    "    print(f\"A base {tabela} foi exportada para o clickhouse\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "freq = 440  # Hz\n",
    "duration = 1  # seconds\n",
    "samples = int(duration * 44100)  # 44100 samples per second\n",
    "t = np.linspace(0, duration, samples, False)\n",
    "note = np.sin(freq * t * 2 * np.pi)\n",
    "Audio(note, rate=44100, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B&N prevê rotura:\n",
    "\n",
    "Risco de rotura tem de ser diferente de -1 quando stk = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotura evitada \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "                                 \\                                           /"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "                                   \\                                       /"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "                                     \\                                   /"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "                                       \\                               /                        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "                                        | 26 minutos para correr tudo |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Passar para csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "escrever_csv(dfEscreverDia, \"DataBaseDeltaDia\")\n",
    "escrever_csv(dfEscreverMes, \"DataBaseDeltaMes\")\n",
    "escrever_csv(dfEscrever180, \"DataBaseDelta180Dias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ler ficheiro novo se estiver já no Clickhouse"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Ler o ficheiro\n",
    "\n",
    "dfNovo = client.query_df('SELECT * FROM BaseDeltaSonae')\n",
    "\n",
    "dfNovo = dfNovo[['DATA', 'EAN', 'DESC_ARTIGO', 'STORE', \"STORE_NAME\", \n",
    "                         \"SOH\", \"INTRANSIT\", \"EXPECTED\", \"PRES_STOCK\", \"VND (D-1)\"]]\n",
    "\n",
    "# Renomear colunas e criar as do dia\n",
    "\n",
    "dfNovo = dfNovo.rename(columns={\"VND (D-1)\": \"SELLOUT_1_Dias_Antes\", \n",
    "                                \"SOH\": \"STOCK_1_Dias_Antes\",\n",
    "                                \"INTRANSIT\": \"INTRANSIT_1_Dias_Antes\", \n",
    "                                \"EXPECTED\": \"EXPECTED_1_Dias_Antes\", \n",
    "                                \"PRES_STOCK\": \"PRES_STOCK_1_Dias_Antes\"})\n",
    "\n",
    "dfNovo[\"SELLOUT_1_Dias_Antes\"] = np.where(dfNovo[\"SELLOUT_1_Dias_Antes\"]<0, 0, dfNovo[\"SELLOUT_1_Dias_Antes\"])\n",
    "dfNovo['SELLOUT'] = dfNovo.groupby([\"STORE\",\"EAN\"])['SELLOUT_1_Dias_Antes'].shift(-1)\n",
    "dfNovo['STOCK'] = dfNovo.groupby([\"STORE\",\"EAN\"])['STOCK_1_Dias_Antes'].shift(-1)\n",
    "dfNovo['INTRANSIT'] = dfNovo.groupby([\"STORE\",\"EAN\"])['INTRANSIT_1_Dias_Antes'].shift(-1)\n",
    "dfNovo['EXPECTED'] = dfNovo.groupby([\"STORE\",\"EAN\"])['EXPECTED_1_Dias_Antes'].shift(-1)\n",
    "dfNovo['PRES_STOCK'] = dfNovo.groupby([\"STORE\",\"EAN\"])['PRES_STOCK_1_Dias_Antes'].shift(-1)\n",
    "\n",
    "#DATETIME\n",
    "# se xlsx\n",
    "#dfNovo['DATA'] = pd.to_datetime(dfNovo['DATA'], format='%d-%m-%Y') \n",
    "\n",
    "# se xlsb\n",
    "dfNovo['DATA'] = pd.to_datetime(dfNovo['DATA'], unit='d', origin=datetime.datetime(1899, 12, 30)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Produtos específicos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Passar produtos e lojas para listas\n",
    "\n",
    "produtos = dfClick.DESC_ARTIGO.unique().tolist()\n",
    "lojas = dfClick.STORE.unique().tolist()\n",
    "\n",
    "# Alterar o dataframe para apenas incluir os produtos e lojas em causa\n",
    "\n",
    "dfNovo = dfNovo[(dfNovo[\"DESC_ARTIGO\"].isin(produtos)) & (dfNovo[\"STORE\"].isin(lojas))].copy()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
