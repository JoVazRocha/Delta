{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumo do código\n",
    "\n",
    "### <u>Código que gera os ficheiros para estudo do comportamento da Delta</u>\n",
    "---\n",
    "O objectivo é receber dados da Delta e devolver um conjunto de métricas para prever roturas. Devolve um ficheiro que pode entrar no código 1 para juntar aos dados dos ninjas.\n",
    "\n",
    "---\n",
    "- Inputs\n",
    "\n",
    "> __Dados completos da Delta em pastas de ficheiros__ (de azul a verde)\n",
    "> - Stocks e trânsito, Sellout do dia anterior\n",
    "\n",
    "                    ou\n",
    "\n",
    "> __Ficheiro já completo__ (de vermelho a verde)\n",
    "> - Stocks e trânsito, Sellout do dia anterior\n",
    "\n",
    "- Outputs\n",
    "\n",
    "> __Ficheiro com produtos em causa__ em formato Long\n",
    "\n",
    "> __Métricas novas:__\n",
    "> - Roturas de Stock e Pré-rotura\n",
    "> - Sinal\n",
    "> - Ciclos e Adequação de Stock\n",
    "> - MSA (média de sellouts 10 dias antes)\n",
    "> - STK (Stock disponível + trânsito)\n",
    "> - (Novo) Balanço médio, mediano, liberal e conservador \n",
    "> - (Novo) Dias para a rotura de stock e de prateleira\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "\n",
    "def escrever_csv(dfa, nome): \n",
    "    dfa.to_csv('D:\\\\B&N Dados\\\\Delta\\\\Stocks\\\\StocksTotal\\\\%s.csv' %nome, index=False)\n",
    "\n",
    "def escrever_txt(dfa, nome): \n",
    "    dfa.to_csv('D:\\\\B&N Dados\\\\Delta\\\\Stocks\\\\StocksTotal\\\\%s.txt' %nome, index=False, header=False)\n",
    "    \n",
    "def escrever_excel(dfa, nome):\n",
    "    dfa.to_excel(f'D:\\\\B&N Dados\\\\Delta\\\\Stocks\\\\StocksTotal\\\\{nome}.xlsx' , index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:red\"><u>Ler Ficheiro Completo</u> </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 21.9 s\n",
      "Wall time: 30.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Ler os ficheiros\n",
    "df_2022 = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Stocks\\\\Stocks2022\\\\Stocks_Delta_2022_Limpo.csv')\n",
    "df_2023 = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Stocks\\\\Stocks2023\\\\Stocks_Delta_2023_Limpo.csv')\n",
    "\n",
    "# Juntar as bases\n",
    "dataframes = [df_2022, df_2023]\n",
    "df_Fusão = pd.concat(dataframes, ignore_index=True)\n",
    "df_Fusão['DATA']= pd.to_datetime(df_Fusão['DATA'], format='%Y-%m-%d')\n",
    "\n",
    "# Ficheiro de previsão\n",
    "df_Prophet = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Forecast\\\\Prophet.csv')\n",
    "df_Prophet['DATA']= pd.to_datetime(df_Prophet['DATA'], format='%Y-%m-%d')\n",
    "\n",
    "df_XGBoost = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Forecast\\\\XGBoost.csv')\n",
    "df_XGBoost['DATA']= pd.to_datetime(df_XGBoost['DATA'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181\n",
      "334\n"
     ]
    }
   ],
   "source": [
    "print(len(df_2023.DESC_ARTIGO.unique()))\n",
    "print(len(df_2023.STORE.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red>Opcional:</font> Definir produtos em causa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Produtos específicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 844 ms\n",
      "Wall time: 857 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Ler ficheiro dos produtos e lojas para dataframe\n",
    "df_produtos = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Piloto\\\\produtos.txt', header=None)\n",
    "df_lojas = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Piloto\\\\lojas.txt', header=None)\n",
    "\n",
    "# Passar para uma lista\n",
    "produtos = df_produtos[0].tolist()\n",
    "lojas = df_lojas[0].tolist()\n",
    "produtos+=[\"CAFÉ DELTA Q MYTHIQ 10CAP\", \"CAFÉ DELTA Q MYTHIQ XL 40CAP\", \"CAFÉ DELTA Q QALIDUS 10CAP\", \"CAFÉ DELTA Q QALIDUS 40CAP\",\n",
    "                'CAFÉ DELTA Q QHARACTER 10CAP','CAFÉ DELTA Q QHARACTER 40CAP','CAFÉ DELTA Q DEQAFEINATUS 10CAP','CAFÉ DELTA Q DEQAFEINATUS XL 40CAP',\n",
    "               'CAFÉ DELTA MOAGEM UNIVERSAL ANGOLA 220G','CAFÉ DELTA MOAGEM UNIVERSAL BRASIL 220G']\n",
    "# Alterar o dataframe para apenas incluir os produtos e lojas em causa\n",
    "dfFinal = df_Fusão[(df_Fusão[\"DESC_ARTIGO\"].isin(produtos)) & (df_Fusão[\"STORE_NAME\"].isin(lojas))].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>Fim</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal['SELLOUT'] = dfFinal.groupby([\"STORE\",\"EAN\"])['SELLOUT_1_Dias_Antes'].shift(-1)\n",
    "dfFinal['STOCK'] = dfFinal.groupby([\"STORE\",\"EAN\"])['STOCK_1_Dias_Antes'].shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fundir o Ficheiro da Delta com a previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 656 ms\n",
      "Wall time: 616 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Prophet\n",
    "dfFinal = pd.merge(dfFinal, df_Prophet[['DATA', 'STORE', 'DESC_ARTIGO', 'Prophet']], how=\"left\", on=['DATA', 'STORE', 'DESC_ARTIGO',] )\n",
    "# XGBoost\n",
    "dfFinal = pd.merge(dfFinal, df_XGBoost[['DATA', 'STORE', 'DESC_ARTIGO', 'XGBoost']], how=\"left\", on=['DATA', 'STORE', 'DESC_ARTIGO',] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=green>Ficheiro Lido<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def historico(titulo, alvo, function):\n",
    "    dfFinal[\"%s_30\" %titulo] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['%s' %alvo].shift(1).transform(lambda x: x.rolling(window=30).apply(function))\n",
    "    dfFinal[\"%s_60\" %titulo] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['%s' %alvo].shift(1).transform(lambda x: x.rolling(window=60).apply(function))\n",
    "    dfFinal[\"%s_120\" %titulo] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['%s' %alvo].shift(1).transform(lambda x: x.rolling(window=120).apply(function))\n",
    "    dfFinal[\"%s_180\" %titulo] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['%s' %alvo].shift(1).transform(lambda x: x.rolling(window=160).apply(function))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colunas de métricas interessantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - ROTURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir coluna de rotura (se stock menor ou igual a 0 e existe Linear)\n",
    "\n",
    "dfFinal[\"ROTURA\"] = np.where((dfFinal[\"STOCK\"] <= 0) & (dfFinal[\"PRES_STOCK\"] > 0), 1, 0)\n",
    "dfFinal[\"ROTURA_1_Dias_Antes\"] = np.where((dfFinal[\"STOCK_1_Dias_Antes\"] <= 0) & (dfFinal[\"PRES_STOCK\"].shift(1) > 0), 1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - PRÉ_ROTURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir coluna de rotura (se stock menor ou igual a 0)\n",
    "\n",
    "dfFinal[\"PRE_ROTURA\"] = (dfFinal[\"STOCK\"] < dfFinal[\"PRES_STOCK\"]).astype(int)\n",
    "dfFinal[\"PRE_ROTURA_1_Dias_Antes\"] = (dfFinal[\"STOCK_1_Dias_Antes\"] < dfFinal[\"PRES_STOCK\"].shift(1)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colunas de métricas 30, 60, 120 e 180 dias antes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Volatilidade de Procura: <br>\n",
    "coeficiente de variação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "diasMetHist = [30, 60, 120, 180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Volatilidade_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).std())/\n",
    "                             dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Teste\n",
    "colunas = dfFinal.filter(like='Percentagem_Volatilidade_').columns.tolist()\n",
    "\n",
    "dfFinal[dfFinal.STORE==2][[\"DATA\", \"DESC_ARTIGO\",\"STORE\",\"SELLOUT_1_Dias_Antes\"]+colunas[0:1]].head(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Percentagem de Rotura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Roturas_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).mean()))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Percentagem de Supply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sempre que é pedido abastecimento, fazer com que seja 1\n",
    "\n",
    "dfFinal[\"New_Supply\"] = np.where((dfFinal[\"EXPECTED\"].shift(1)==0) & (dfFinal[\"EXPECTED\"]>0), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Supply_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['New_Supply'].transform(lambda x: x.rolling(window=i, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Teste\n",
    "colunas = dfFinal.filter(like='Percentagem_Supply_').columns.tolist()\n",
    "\n",
    "dfFinal[dfFinal.STORE==2][[\"DATA\", \"DESC_ARTIGO\",\"STORE\",\"New_Supply\"]+colunas[0:1]].head(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Efeito fim de semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfFinal['SELLOUT_fds'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([4,5,6])][\"SELLOUT\"].copy()\n",
    "#dfFinal['SELLOUT_semana'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([0,1,2,3])][\"SELLOUT\"].copy()\n",
    "dfFinal['SELLOUT_fds_1_Dias_Antes'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([5,6,0])][\"SELLOUT_1_Dias_Antes\"].copy()\n",
    "dfFinal['SELLOUT_semana_1_Dias_Antes'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([1,2,3,4])][\"SELLOUT_1_Dias_Antes\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Efeito_Fds_{i}\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "                                               .transform(lambda x: x.rolling(window=i, min_periods=1).mean())/\n",
    "                                              (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "                                               .transform(lambda x: x.rolling(window=i, min_periods=1).mean())))-1)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Teste\n",
    "colunas = dfFinal.filter(like='Percentagem_Efeito_Fds_').columns.tolist()\n",
    "\n",
    "dfFinal[dfFinal.STORE==2][[\"DATA\", \"DESC_ARTIGO\",\"STORE\", \"SELLOUT_semana_1_Dias_Antes\",\"SELLOUT_fds_1_Dias_Antes\"]+colunas[0:1]].head(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Tempo médio inter-supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"InterSupply\"] = np.where(dfFinal[\"EXPECTED\"]==0, 1, 0)\n",
    "\n",
    "groups = (dfFinal['InterSupply'] != dfFinal['InterSupply'].shift()).cumsum()\n",
    "result = dfFinal.groupby(groups).agg({'DATA': 'first', 'DESC_ARTIGO': 'first', 'STORE': 'first', 'InterSupply': 'sum'}).reset_index(drop=True)\n",
    "result = result[result['InterSupply'] > 0]\n",
    "\n",
    "dfFinal = dfFinal.drop(columns=['InterSupply'])\n",
    "\n",
    "dfFinal = pd.merge(dfFinal, result, how=\"left\", on=[\"DATA\",\"DESC_ARTIGO\", \"STORE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_InterSupplyMed_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['InterSupply'].transform(lambda x: x.rolling(window=i, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Tempo indisponível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''O que vai acontecer é: no primeiro dia em que há rotura vai aparecer a soma de todos os dias com rotura a seguir a esse!\n",
    "Todos os outros valores serão NaN para não serem considerados quando for feita a média. Assim a média corresponderá ao\n",
    "número médio de dias em que se deixa um produto em rotura.'''\n",
    "\n",
    "dfFinal[\"Dias_Indisponível_1_Dias_Antes\"] = np.where(dfFinal[\"ROTURA_1_Dias_Antes\"]==1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Dias_Indisponível_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Dias_Indisponível_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Percentagem de dias em Stock Borderline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Percentagem_Stock_Borderline_1_Dias_Antes\"] = np.where(dfFinal[\"STOCK_1_Dias_Antes\"]<0.2*dfFinal[\"PRES_STOCK\"].shift(1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Dias_Stock_Borderline_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Percentagem_Stock_Borderline_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Percentagem de dias de Linear Incompleto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Percentagem_Linear_Incompleto_1_Dias_Antes\"] = np.where(dfFinal[\"STOCK_1_Dias_Antes\"]<dfFinal[\"PRES_STOCK\"].shift(1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Dias_Linear_Incompleto_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Percentagem_Linear_Incompleto_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Percentagem de dias sem vendas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Sem_Vendas_1_Dias_Antes\"] = np.where(dfFinal[\"SELLOUT_1_Dias_Antes\"] == 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Dias_Sem_Vendas_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Sem_Vendas_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Vendas perdidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal['ROTURA_fds_1_Dias_Antes'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([5,6,0])][\"ROTURA_1_Dias_Antes\"].copy()\n",
    "dfFinal['ROTURA_semana_1_Dias_Antes'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([1,2,3,4])][\"ROTURA_1_Dias_Antes\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Vendas_Perdidas_em_{i}_Dias\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_fds_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).sum())\\\n",
    "                                                  * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).median())) \\\n",
    "                                                  + \n",
    "                                               (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_semana_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).sum()) \\\n",
    "                                                  * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes'].transform(lambda x: x.rolling(window=i, min_periods=1).median())))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA</th>\n",
       "      <th>DESC_ARTIGO</th>\n",
       "      <th>STORE</th>\n",
       "      <th>ROTURA_fds_1_Dias_Antes</th>\n",
       "      <th>ROTURA_semana_1_Dias_Antes</th>\n",
       "      <th>Vendas_Perdidas_em_30_Dias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>2022-01-09</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2022-01-10</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2022-01-11</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2022-01-12</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2022-01-13</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2022-01-14</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>2022-01-15</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>2022-01-16</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>2022-01-17</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>2022-01-18</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>2022-01-19</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>2022-01-20</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>2022-01-22</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>2022-01-23</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>2022-01-24</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>2022-01-26</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>2022-01-27</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>2022-01-30</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATA                             DESC_ARTIGO  STORE  \\\n",
       "351 2022-01-01  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "352 2022-01-02  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "353 2022-01-03  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "354 2022-01-04  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "355 2022-01-05  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "356 2022-01-06  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "357 2022-01-07  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "358 2022-01-08  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "359 2022-01-09  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "360 2022-01-10  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "361 2022-01-11  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "362 2022-01-12  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "363 2022-01-13  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "364 2022-01-14  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "365 2022-01-15  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "366 2022-01-16  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "367 2022-01-17  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "368 2022-01-18  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "369 2022-01-19  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "370 2022-01-20  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "371 2022-01-21  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "372 2022-01-22  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "373 2022-01-23  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "374 2022-01-24  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "375 2022-01-25  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "376 2022-01-26  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "377 2022-01-27  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "378 2022-01-28  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "379 2022-01-29  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "380 2022-01-30  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "381 2022-01-31  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      2   \n",
       "\n",
       "     ROTURA_fds_1_Dias_Antes  ROTURA_semana_1_Dias_Antes  \\\n",
       "351                      0.0                         NaN   \n",
       "352                      0.0                         NaN   \n",
       "353                      0.0                         NaN   \n",
       "354                      NaN                         0.0   \n",
       "355                      NaN                         0.0   \n",
       "356                      NaN                         0.0   \n",
       "357                      NaN                         0.0   \n",
       "358                      0.0                         NaN   \n",
       "359                      0.0                         NaN   \n",
       "360                      0.0                         NaN   \n",
       "361                      NaN                         0.0   \n",
       "362                      NaN                         0.0   \n",
       "363                      NaN                         0.0   \n",
       "364                      NaN                         0.0   \n",
       "365                      0.0                         NaN   \n",
       "366                      0.0                         NaN   \n",
       "367                      0.0                         NaN   \n",
       "368                      NaN                         0.0   \n",
       "369                      NaN                         0.0   \n",
       "370                      NaN                         0.0   \n",
       "371                      NaN                         0.0   \n",
       "372                      0.0                         NaN   \n",
       "373                      0.0                         NaN   \n",
       "374                      0.0                         NaN   \n",
       "375                      NaN                         0.0   \n",
       "376                      NaN                         0.0   \n",
       "377                      NaN                         0.0   \n",
       "378                      NaN                         0.0   \n",
       "379                      0.0                         NaN   \n",
       "380                      0.0                         NaN   \n",
       "381                      0.0                         NaN   \n",
       "\n",
       "     Vendas_Perdidas_em_30_Dias  \n",
       "351                         NaN  \n",
       "352                         NaN  \n",
       "353                         NaN  \n",
       "354                         0.0  \n",
       "355                         0.0  \n",
       "356                         0.0  \n",
       "357                         0.0  \n",
       "358                         0.0  \n",
       "359                         0.0  \n",
       "360                         0.0  \n",
       "361                         0.0  \n",
       "362                         0.0  \n",
       "363                         0.0  \n",
       "364                         0.0  \n",
       "365                         0.0  \n",
       "366                         0.0  \n",
       "367                         0.0  \n",
       "368                         0.0  \n",
       "369                         0.0  \n",
       "370                         0.0  \n",
       "371                         0.0  \n",
       "372                         0.0  \n",
       "373                         0.0  \n",
       "374                         0.0  \n",
       "375                         0.0  \n",
       "376                         0.0  \n",
       "377                         0.0  \n",
       "378                         0.0  \n",
       "379                         0.0  \n",
       "380                         0.0  \n",
       "381                         0.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colunas = dfFinal.filter(like='Vendas_Perdidas_em_').columns.tolist()\n",
    "\n",
    "dfFinal[dfFinal.STORE==2][[\"DATA\", \"DESC_ARTIGO\",\"STORE\",\"ROTURA_fds_1_Dias_Antes\", \"ROTURA_semana_1_Dias_Antes\"]+colunas[0:1]].head(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas 4, 5 e 10 antes:\n",
    "\n",
    "- INSTRANSIT\n",
    "- EXPECTED\n",
    "- SELLOUT\n",
    "- CICLOS\n",
    "- Dias para Rotura\n",
    "- Adequação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantos dias antes:\n",
    "\n",
    "diasMet = [1, 4, 5, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para colunas de dias anteriores\n",
    "def dias(df, dia, coluna):         #dia é quantos dias antes\n",
    "    a=int(dia)\n",
    "\n",
    "    valores = df.groupby(['DESC_ARTIGO', 'STORE'])[coluna].transform(lambda x: x.shift(a))\n",
    "    valores[:a] = np.nan\n",
    "    \n",
    "    df.loc[:,'%s_%s_Dias_Antes' % (coluna, a)] = valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - SELLOUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 281 ms\n",
      "Wall time: 276 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Usar função para sellouts até 10 dias antes\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"SELLOUT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - STOCKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar função para Stocks até 10 dias antes\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"STOCK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> > - Ordenar"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "previsões = 2\n",
    "dfOrg = dfFinal.iloc[:, np.r_[:9, 10, 12, 13, 12+previsões, 13+previsões, 9, \n",
    "                                (23+previsões):(32+previsões), 11, (14+previsões):(23+previsões)]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "df_columns = dfOrg.columns.tolist()\n",
    "indexed_columns = [f\"{index}: {column}\" for index, column in enumerate(df_columns)]\n",
    "indexed_columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dfFinal = dfFinal.iloc[:, np.r_[:9, 10, 12, 13, 12+previsões, 13+previsões, 9, \n",
    "                                (23+previsões):(32+previsões), 11, (14+previsões):(23+previsões)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - INTRANSIT e EXPECTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar função para Trânsito até 10 dias antes\n",
    "\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"INTRANSIT\")\n",
    "    \n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"EXPECTED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - STK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STK do dia = soma dos stocks em loja com os stocks em trânsito no próprio dia\n",
    "\n",
    "dfFinal[\"STK\"] = dfFinal[\"STOCK\"] + dfFinal[\"INTRANSIT\"] + dfFinal[\"EXPECTED\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"STK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - MSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSA do dia = média dos sellouts dos 10 dias anteriores ao dia em causa\n",
    "\n",
    "dfFinal[\"MSA10\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10).mean())\n",
    "dfFinal[\"MSA10Dp\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10).std())\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"MSA10\")\n",
    "\n",
    "    \n",
    "dfFinal[\"MSA20\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=20).mean())\n",
    "dfFinal[\"MSA20Dp\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=20).std())\n",
    "  \n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"MSA20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - CICLOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coluna de Ciclos de reposição\n",
    "\n",
    "dfFinal[\"CICLOS\"] = dfFinal[\"STOCK\"]/dfFinal[\"PRES_STOCK\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"CICLOS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Dias para rotura de Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal = dfFinal.copy()\n",
    "# Dias para a rotura mas com o Sellout médio (móvel) dos últimos 10 dias \n",
    "dfFinal[\"Dias_para_Rotura_Stock\"] = dfFinal[\"STOCK\"] / dfFinal[\"MSA10\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"Dias_para_Rotura_Stock\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Dias para rotura de Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a métrica: Preslinear / med(Sellouts 10 dias)\n",
    "dfFinal['Dias_Duração_Linear'] = dfFinal[\"PRES_STOCK\"] / dfFinal[\"MSA10\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"Dias_Duração_Linear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Adequação de Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coluna de adequação de stock\n",
    "\n",
    "\n",
    "dfFinal[\"Adequação\"]= np.where(dfFinal[\"CICLOS\"] > 1.1, \"Stock Suficiente\", \n",
    "                      np.where((dfFinal[\"CICLOS\"] <= 1.1) & (dfFinal[\"INTRANSIT\"]+dfFinal[\"EXPECTED\"]+dfFinal[\"STOCK\"]>=dfFinal[\"PRES_STOCK\"]), \"Stock Insuf c Forn Adequado\", \n",
    "                      np.where((dfFinal[\"CICLOS\"] <= 1.1) & (dfFinal[\"INTRANSIT\"]+dfFinal[\"EXPECTED\"]+dfFinal[\"STOCK\"]<dfFinal[\"PRES_STOCK\"]), \"Stock Insuf c Forn Desadequado\", \n",
    "                      \"\")))\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"Adequação\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- Balance: sellout / soma stock disponível mais transito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas de balanço\n",
    "\n",
    "\n",
    "# Balance do dia = razão entre o sellout médio e o stock para o dia actual\n",
    "dfFinal[\"Balance\"] =  dfFinal[\"MSA10\"] / dfFinal[\"STK\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    \n",
    "    \n",
    "    valores = i * dfFinal[\"Balance\"].shift(i)\n",
    "    valores[:i] = np.nan\n",
    "    \n",
    "    dfFinal.loc[:,'%s_%s_Dias_Antes' % (\"Balance\", i)] = valores\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- Balance optimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "dfFinal[\"Balance_Optimized\"] = np.where((dfFinal[\"MSA10Dp\"] / dfFinal[\"MSA10\"]) * 100 > 100, dfFinal[\"MSA20\"] / dfFinal[\"STK\"],\n",
    "                                dfFinal[\"MSA10\"] / dfFinal[\"STK\"])   \n",
    "\n",
    "for i in diasMet:\n",
    "    \n",
    "    \n",
    "    valores = i * dfFinal[\"Balance_Optimized\"].shift(i)\n",
    "    valores[:i] = np.nan\n",
    "    \n",
    "    dfFinal.loc[:,'%s_%s_Dias_Antes' % (\"Balance_Optimized\", i)] = valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Mediano é com o mínimo dos ultimos 10 dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coluna de adequação de stock\n",
    "\n",
    "\n",
    "# MSA_med do dia = mediana dos sellouts dos 10 dias anteriores (exclui o próprio dia)\n",
    "# dfFinal[\"MdSA\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10).median())\n",
    "\n",
    "\n",
    "# Balance do dia = razão entre o sellout médio e o stock para o dia actual\n",
    "dfFinal[\"Balance_Mediano\"] =  dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10).median()) / dfFinal[\"STK\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    \n",
    "    \n",
    "    valores = i * dfFinal[\"Balance_Mediano\"].shift(i)\n",
    "    valores[:i] = np.nan\n",
    "    \n",
    "    dfFinal.loc[:,'%s_%s_Dias_Antes' % (\"Balance_Mediano\", i)] = valores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Liberal é com o mínimo dos ultimos 10 dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liberal\n",
    "\n",
    "\n",
    "# MSA do dia = média dos stocks dos 10 dias anteriores (exclui o próprio dia)\n",
    "#dfFinal[\"LSA\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10).min())\n",
    "\n",
    "\n",
    "# Balance do dia = razão entre o sellout médio e o stock para o dia actual\n",
    "dfFinal[\"Balance_Liberal\"] =  dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10).min()) / dfFinal[\"STK\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    \n",
    "    \n",
    "    valores = i * dfFinal[\"Balance_Liberal\"].shift(i)\n",
    "    valores[:i] = np.nan\n",
    "    \n",
    "    dfFinal.loc[:,'%s_%s_Dias_Antes' % (\"Balance_Liberal\", i)] = valores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Conservador é com o máximo dos ultimos 10 dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conservador\n",
    "\n",
    "# MSA_max do dia = máximo dos stocks dos 10 dias anteriores (exclui o próprio dia)\n",
    "#dfFinal[\"CSA\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10).max())\n",
    " \n",
    "    \n",
    "# Balance do dia = razão entre o sellout médio e o stock para o dia actual\n",
    "dfFinal[\"Balance_Conservador\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10).max()) / dfFinal[\"STK\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    \n",
    "    # Multiplicar os balances pelo número de dias+1 antes do dia actual\n",
    "    valores = i * dfFinal[\"Balance_Conservador\"].shift(i)\n",
    "    valores[:i] = np.nan\n",
    "    \n",
    "    dfFinal.loc[:,'%s_%s_Dias_Antes' % (\"Balance_Conservador\", i)] = valores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Smart 5 dias antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 25.8 s\n",
      "Wall time: 25.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# Define a function to calculate weekday and weekend counts\n",
    "def calculate_weekday_weekend_counts(date):\n",
    "    weekday_count = 0\n",
    "    weekend_count = 0\n",
    "    \n",
    "    for _ in range(5):\n",
    "        if date.weekday() < 4:  # Monday to Thursday\n",
    "            weekday_count += 1\n",
    "        else:  # Friday to Sunday\n",
    "            weekend_count += 1\n",
    "        \n",
    "        date += timedelta(days=1)\n",
    "    \n",
    "    return pd.Series({\"CONTAGEM_SEMANA\": weekday_count, \"CONTAGEM_FIMSEMANA\": weekend_count})\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "dfFinal[[\"CONTAGEM_SEMANA\", \"CONTAGEM_FIMSEMANA\"]] = dfFinal[\"DATA\"].apply(calculate_weekday_weekend_counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "escrever_excel(dfFinal[[\"DATA\",\"DESC_ARTIGO\",\"STORE\",\"CONTAGEM_SEMANA\", \"CONTAGEM_FIMSEMANA\",\"SELLOUT_fds\", \"SELLOUT_semana\",\"STK\", \"Balance_Smart_5_Dias_Antes\"]].head(20), \"TESTE\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "escrever_excel(dfFinal[[\"DATA\",\"CONTAGEM_SEMANA\", \"CONTAGEM_FIMSEMANA\",\"SELLOUT_fds\", \"SELLOUT_semana\",\"STK\",\"Balance_Smart\", \"Balance_Smart_5_Dias_Antes\"]].head(20), \"TESTE2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smart\n",
    "\n",
    "# 5 dias antes\n",
    "dfFinal[\"Balance_Smart\"] = ((\n",
    "    (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_FIMSEMANA'])\n",
    "    +\n",
    "    (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana_1_Dias_Antes']\\\n",
    "    .transform(lambda x: x.rolling(window=30, min_periods=1).mean())* dfFinal['CONTAGEM_SEMANA']))\n",
    "     / dfFinal[\"STK_1_Dias_Antes\"])\n",
    "dfFinal[\"Balance_Smart\"] = np.where(dfFinal[\"STK\"]<=0, -1, dfFinal[\"Balance_Smart\"])\n",
    "dfFinal[\"Balance_Smart_5_Dias_Antes\"] = dfFinal[\"Balance_Smart\"].shift(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"RISCO\"] = np.where((dfFinal.Balance_Smart > 2) & (dfFinal.CICLOS_5_Dias_Antes < 0.2) & (dfFinal.Percentagem_Roturas_120 > 5), 1,\n",
    "                   np.where((dfFinal.Balance_Smart > 1) & (dfFinal.Balance_Smart < 2) & (dfFinal.CICLOS_5_Dias_Antes < 0.6) & (dfFinal.Percentagem_Roturas_120 < 3), 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"RISCO_ROTURA\"] = np.where((dfFinal.Balance_Smart >= 12.5) | (dfFinal.Balance_Smart < 0), 1, \n",
    "                          np.where((dfFinal.Balance_Smart >= 1.1) & (dfFinal.Balance_Smart < 12.5), 2,\n",
    "                          np.where((dfFinal.Balance_Smart >= 0.833) & (dfFinal.Balance_Smart < 1.1), 3,\n",
    "                          np.where((dfFinal.Balance_Smart >= 0.087) & (dfFinal.Balance_Smart < 0.833), 4, 5))))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfVendedor=pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Vendedor2.xlsx\", sheet_name = \"Lojas Sonae para o desafio\")\n",
    "dfVendedor = dfVendedor.rename(columns={\"Cód. Loja\":\"STORE\"})\n",
    "\n",
    "# Criar coluna de reposição\n",
    "dfFinal = pd.merge(dfFinal, dfVendedor[[\"STORE\",\"Vendedor\"]], how=\"left\", on = \"STORE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escrever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0's e 1's"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Novo dataframe que apenas inclui dias em que existe a 1ª rotura e o dia anterior a essa rotura\n",
    "\n",
    "# Tirar 1's depois do primeiro\n",
    "dfFinalLimitado = dfFinal[~((dfFinal[\"ROTURA\"] == 1) & (dfFinal[\"ROTURA\"].shift(1) == 1))].copy()\n",
    "\n",
    "# Apenas incluir primeira rotura\n",
    "dfFinalLimitadoRoturas = dfFinal[((dfFinal[\"ROTURA\"] == 1) & (dfFinal[\"ROTURA\"].shift(1) == 0))].copy() #| ((dfFinal[\"ROTURA\"] == 0) & (dfFinal[\"ROTURA\"].shift(-1) == 1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dias certos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfEscrever2022 = dfFinal.copy()\n",
    "#dfEscrever2023 = dfFinal.loc[(dfFinal['DATA'] >= '2023-01-01') ].copy()\n",
    "\n",
    "#df_DiasCertos = dfFinalLimitado.loc[(dfFinalLimitado['DATA'] >= '2023-01-01') ].copy()\n",
    "#df_RoturasDiasCertos = dfFinalLimitadoRoturas.loc[(dfFinalLimitadoRoturas['DATA'] >= '2023-01-01') ].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ficheiro Dia\n",
    "dfEscreverDia = dfFinal[dfFinal.DATA == dfFinal.DATA.unique()[-1]].copy()\n",
    "\n",
    "#Ficheiro Mês\n",
    "dfEscreverMes = dfFinal[dfFinal.DATA >= dfFinal.DATA.unique()[-30]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Passar para csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "escrever_excel(dfEscreverDia, \"DataBaseDeltaDia\")\n",
    "escrever_excel(dfEscreverMes, \"DataBaseDeltaMes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA</th>\n",
       "      <th>STORE</th>\n",
       "      <th>DESC_ARTIGO</th>\n",
       "      <th>ROTURA</th>\n",
       "      <th>CICLOS_5_Dias_Antes</th>\n",
       "      <th>Balance_Smart_5_Dias_Antes</th>\n",
       "      <th>Percentagem_Roturas_120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0</td>\n",
       "      <td>1.325000</td>\n",
       "      <td>0.209459</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2022-03-02</td>\n",
       "      <td>1</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>1</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>0.216814</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2022-03-04</td>\n",
       "      <td>1</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.198020</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2022-03-05</td>\n",
       "      <td>1</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0</td>\n",
       "      <td>0.841667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87775</th>\n",
       "      <td>2023-05-06</td>\n",
       "      <td>459</td>\n",
       "      <td>CEVADA SOLÚVEL DELTA FRASCO 200G</td>\n",
       "      <td>0</td>\n",
       "      <td>8.375000</td>\n",
       "      <td>0.177384</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87776</th>\n",
       "      <td>2023-05-07</td>\n",
       "      <td>459</td>\n",
       "      <td>CEVADA SOLÚVEL DELTA FRASCO 200G</td>\n",
       "      <td>0</td>\n",
       "      <td>7.046875</td>\n",
       "      <td>0.209246</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87777</th>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>459</td>\n",
       "      <td>CEVADA SOLÚVEL DELTA FRASCO 200G</td>\n",
       "      <td>0</td>\n",
       "      <td>4.921875</td>\n",
       "      <td>0.183099</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87778</th>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>459</td>\n",
       "      <td>CEVADA SOLÚVEL DELTA FRASCO 200G</td>\n",
       "      <td>0</td>\n",
       "      <td>3.453125</td>\n",
       "      <td>0.175337</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87779</th>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>459</td>\n",
       "      <td>CEVADA SOLÚVEL DELTA FRASCO 200G</td>\n",
       "      <td>0</td>\n",
       "      <td>3.796875</td>\n",
       "      <td>0.151724</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77762 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DATA  STORE                             DESC_ARTIGO  ROTURA  \\\n",
       "59    2022-03-01      1  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G       0   \n",
       "60    2022-03-02      1  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G       0   \n",
       "61    2022-03-03      1  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G       0   \n",
       "62    2022-03-04      1  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G       0   \n",
       "63    2022-03-05      1  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G       0   \n",
       "...          ...    ...                                     ...     ...   \n",
       "87775 2023-05-06    459        CEVADA SOLÚVEL DELTA FRASCO 200G       0   \n",
       "87776 2023-05-07    459        CEVADA SOLÚVEL DELTA FRASCO 200G       0   \n",
       "87777 2023-05-08    459        CEVADA SOLÚVEL DELTA FRASCO 200G       0   \n",
       "87778 2023-05-09    459        CEVADA SOLÚVEL DELTA FRASCO 200G       0   \n",
       "87779 2023-05-10    459        CEVADA SOLÚVEL DELTA FRASCO 200G       0   \n",
       "\n",
       "       CICLOS_5_Dias_Antes  Balance_Smart_5_Dias_Antes  \\\n",
       "59                1.325000                    0.209459   \n",
       "60                1.233333                    0.203125   \n",
       "61                1.066667                    0.216814   \n",
       "62                0.941667                    0.198020   \n",
       "63                0.841667                    0.333333   \n",
       "...                    ...                         ...   \n",
       "87775             8.375000                    0.177384   \n",
       "87776             7.046875                    0.209246   \n",
       "87777             4.921875                    0.183099   \n",
       "87778             3.453125                    0.175337   \n",
       "87779             3.796875                    0.151724   \n",
       "\n",
       "       Percentagem_Roturas_120  \n",
       "59                         0.0  \n",
       "60                         0.0  \n",
       "61                         0.0  \n",
       "62                         0.0  \n",
       "63                         0.0  \n",
       "...                        ...  \n",
       "87775                      0.0  \n",
       "87776                      0.0  \n",
       "87777                      0.0  \n",
       "87778                      0.0  \n",
       "87779                      0.0  \n",
       "\n",
       "[77762 rows x 7 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEscrever2023[[\"DATA\", \"STORE\",\"DESC_ARTIGO\", \"ROTURA\", \"CICLOS_5_Dias_Antes\", \"Balance_Smart_5_Dias_Antes\", \"Percentagem_Roturas_120\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 453 ms\n",
      "Wall time: 445 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#escrever_csv(dfEscrever2022, \"FinalDataBaseDeltaTotal\")\n",
    "escrever_csv(dfEscrever2023[[\"DATA\", \"STORE\",\"DESC_ARTIGO\", \"ROTURA\", \"CICLOS_5_Dias_Antes\", \"Balance_Smart_5_Dias_Antes\", \"Percentagem_Roturas_120\"]], \"FinalDataBaseDeltaTotal2023\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clickhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clickhouse_connect\n",
    "from clickhouse_driver import Client\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estabelecer a base a ser lida\n",
    "\n",
    "baseCH = dfEscreverDia.copy()\n",
    "#2023\n",
    "tabela = \"DataBaseDeltaDia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<clickhouse_connect.driver.summary.QuerySummary at 0x1d614366f80>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "client = clickhouse_connect.get_client(host='e28fluocjc.europe-west4.gcp.clickhouse.cloud', \n",
    "                                       port=8443, \n",
    "                                       username='default', \n",
    "                                       password='eKn4CWkTDFpi_',\n",
    "                                       database='Delta')\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "baseCH['DATA']= pd.to_datetime(baseCH['DATA'], format='%Y-%m-%d')  # Passar para datetime\n",
    "new_columns = [unidecode(col) for col in baseCH.columns]           # Tirar acentos e afins\n",
    "baseCH.columns = new_columns                                       # Aplicar alterações da linha anterior\n",
    "###\n",
    "\n",
    "# Tipos de dados\n",
    "data = [\"DATA\"]\n",
    "texto = [col for col in baseCH.columns if baseCH[col].dtype == 'object']\n",
    "inteiros = [col for col in baseCH.columns if baseCH[col].dtype == 'int64' or baseCH[col].dtype == 'int32']\n",
    "floats = [col for col in baseCH.columns if baseCH[col].dtype == 'float64']\n",
    "\n",
    "\n",
    "# Só floats é que permitem missing values\n",
    "for col_name in inteiros:\n",
    "    baseCH[col_name] = baseCH[col_name].astype(float)\n",
    "# Missing values em strings estragam tudo\n",
    "baseCH[texto] = baseCH[texto].fillna(\"-\")\n",
    "\n",
    "\n",
    "def schema(lista, tipo):\n",
    "    result_list = [f\"{element} {tipo}\" for element in lista]\n",
    "    return result_list\n",
    "\n",
    "data1 = schema(data, \"Date\")\n",
    "texto1 = schema(texto, \"String\")\n",
    "inteiros1 = schema(inteiros, \"Float64\")\n",
    "floats1 = schema(floats, \"Float64\")\n",
    "total = tuple(data1 + texto1 + inteiros1 + floats1)\n",
    "\n",
    "schema = ', '.join([column.replace(\"'\", \"\") for column in total])\n",
    "\n",
    "# Split the input string by commas\n",
    "parts = schema.split(', ')\n",
    "# Process each part and wrap the first word in double quotes\n",
    "output_parts = []\n",
    "for part in parts:\n",
    "    words = part.split()\n",
    "    if words:\n",
    "        first_word = words[0]\n",
    "        remaining_words = ' '.join(words[1:])\n",
    "        output_part = f'\"{first_word}\" {remaining_words}'\n",
    "        output_parts.append(output_part)\n",
    "# Join the modified parts back into a string\n",
    "schema = ', '.join(output_parts)\n",
    "\n",
    "\n",
    "\n",
    "# Eliminar tabela no CH\n",
    "client.command(f'DROP TABLE IF EXISTS {tabela}')\n",
    "\n",
    "# Criar tabela no CH\n",
    "client.command(f'''\n",
    "    CREATE TABLE IF NOT EXISTS {tabela} (\n",
    "        {schema}\n",
    "        ) ENGINE = MergeTree\n",
    "        ORDER BY (DATA)\n",
    "''')\n",
    "\n",
    "client.insert_df(tabela, baseCH, column_names=baseCH.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
