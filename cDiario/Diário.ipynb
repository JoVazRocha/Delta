{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumo do código\n",
    "\n",
    "### <u>Código que gera os ficheiros para estudo do comportamento da Delta</u>\n",
    "---\n",
    "O objectivo é receber dados da Delta e devolver um conjunto de métricas para prever roturas. Devolve um ficheiro que pode entrar no código 1 para juntar aos dados dos ninjas.\n",
    "\n",
    "---\n",
    "- Inputs\n",
    "\n",
    "> __Dados completos da Delta em pastas de ficheiros__ (de azul a verde)\n",
    "> - Stocks e trânsito, Sellout do dia anterior\n",
    "\n",
    "                    ou\n",
    "\n",
    "> __Ficheiro já completo__ (de vermelho a verde)\n",
    "> - Stocks e trânsito, Sellout do dia anterior\n",
    "\n",
    "- Outputs\n",
    "\n",
    "> __Ficheiro com produtos em causa__ em formato Long\n",
    "\n",
    "> __Métricas novas:__\n",
    "> - Roturas de Stock e Pré-rotura\n",
    "> - Sinal\n",
    "> - Ciclos e Adequação de Stock\n",
    "> - MSA (média de sellouts 10 dias antes)\n",
    "> - STK (Stock disponível + trânsito)\n",
    "> - (Novo) Balanço médio, mediano, liberal e conservador \n",
    "> - (Novo) Dias para a rotura de stock e de prateleira\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 844 ms\n",
      "Wall time: 2.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import clickhouse_connect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:Blue\">Juntar Ficheiros</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importar do Clickhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = clickhouse_connect.get_client(host='e28fluocjc.europe-west4.gcp.clickhouse.cloud', \n",
    "                                       port=8443, \n",
    "                                       username='default', \n",
    "                                       password='eKn4CWkTDFpi_',\n",
    "                                       database='Delta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 438 ms\n",
      "Wall time: 944 ms\n"
     ]
    }
   ],
   "source": [
    "#Ler o ficheiro\n",
    "\n",
    "dfClick = client.query_df('SELECT * FROM FinalDataBaseDelta2023')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importar ficheiros novos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfNovo = pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Diário\\\\dia_actual.xlsb\") #xlsx\n",
    "\n",
    "\n",
    "dfNovo = dfNovo[['DATA', 'EAN', 'DESC_ARTIGO', 'STORE', \"STORE_NAME\", \n",
    "                         \"SOH\", \"INTRANSIT\", \"EXPECTED\", \"PRES_STOCK\", \"VND (D-1)\"]]\n",
    "\n",
    "# se xlsx\n",
    "#dfDelta['DATA'] = pd.to_datetime(dfDelta['DATA'], format='%d-%m-%Y') \n",
    "\n",
    "# se xlsb\n",
    "dfDelta['DATA'] = pd.to_datetime(dfDelta['DATA'], unit='d', origin=datetime.datetime(1899, 12, 30)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Juntar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDelta=pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red>Opcional:</font> Definir produtos em causa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Produtos específicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 433 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Ler ficheiro dos produtos e lojas para dataframe\n",
    "df_produtos = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Piloto\\\\produtos.txt', header=None)\n",
    "df_lojas = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Piloto\\\\lojas.txt', header=None)\n",
    "\n",
    "# Passar para uma lista\n",
    "produtos = df_produtos[0].tolist()\n",
    "#lojas = df_lojas[0].tolist()\n",
    "produtos+=[\"CAFÉ DELTA Q MYTHIQ 10CAP\", \"CAFÉ DELTA Q MYTHIQ XL 40CAP\", \"CAFÉ DELTA Q QALIDUS 10CAP\", \"CAFÉ DELTA Q QALIDUS 40CAP\",\n",
    "                'CAFÉ DELTA Q QHARACTER 10CAP','CAFÉ DELTA Q QHARACTER 40CAP','CAFÉ DELTA Q DEQAFEINATUS 10CAP','CAFÉ DELTA Q DEQAFEINATUS XL 40CAP',\n",
    "               'CAFÉ DELTA MOAGEM UNIVERSAL ANGOLA 220G','CAFÉ DELTA MOAGEM UNIVERSAL BRASIL 220G']\n",
    "# Alterar o dataframe para apenas incluir os produtos e lojas em causa\n",
    "#dfFinal = df_Fusão[(df_Fusão[\"DESC_ARTIGO\"].isin(produtos)) & (df_Fusão[\"STORE_NAME\"].isin(lojas))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAFÉ DELTA Q MYTHIQ 80CAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAFÉ DELTA Q QALIDUS 80CAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAFÉ DELTA Q QALIDUS 10CAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAFÉ MOÍDO MÁQUINA CHÁVENA DELTA 250G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAFÉ BELLISSIMO INTENSO 200GR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CAFÉ DELTA RITUAL MU 220G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CAFÉ SOLÚVEL DELTA FRASCO 100G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CAFÉ SOLÚVEL DELTA FRASCO 200G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CEVADA SOLÚVEL DELTA FRASCO 200G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        0\n",
       "0               CAFÉ DELTA Q MYTHIQ 80CAP\n",
       "1              CAFÉ DELTA Q QALIDUS 80CAP\n",
       "2              CAFÉ DELTA Q QALIDUS 10CAP\n",
       "3   CAFÉ MOÍDO MÁQUINA CHÁVENA DELTA 250G\n",
       "4           CAFÉ BELLISSIMO INTENSO 200GR\n",
       "5               CAFÉ DELTA RITUAL MU 220G\n",
       "6          CAFÉ SOLÚVEL DELTA FRASCO 100G\n",
       "7          CAFÉ SOLÚVEL DELTA FRASCO 200G\n",
       "8        CEVADA SOLÚVEL DELTA FRASCO 200G\n",
       "9  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_produtos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>Fim</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal = df_Fusão[(df_Fusão[\"DESC_ARTIGO\"].isin(produtos))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal['SELLOUT'] = dfFinal.groupby([\"STORE\",\"EAN\"])['SELLOUT_1_Dias_Antes'].shift(-1)\n",
    "dfFinal['STOCK'] = dfFinal.groupby([\"STORE\",\"EAN\"])['STOCK_1_Dias_Antes'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA</th>\n",
       "      <th>EAN</th>\n",
       "      <th>DESC_ARTIGO</th>\n",
       "      <th>STORE</th>\n",
       "      <th>STORE_NAME</th>\n",
       "      <th>INTRANSIT</th>\n",
       "      <th>EXPECTED</th>\n",
       "      <th>PRES_STOCK</th>\n",
       "      <th>STOCK</th>\n",
       "      <th>STOCK_1_Dias_Antes</th>\n",
       "      <th>SELLOUT</th>\n",
       "      <th>SELLOUT_1_Dias_Antes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60608</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>120</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60609</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>120</td>\n",
       "      <td>137.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60610</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>175.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60611</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>162.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60612</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>120</td>\n",
       "      <td>195.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            DATA            EAN                             DESC_ARTIGO  \\\n",
       "60608 2022-01-01  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "60609 2022-01-02  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "60610 2022-01-03  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "60611 2022-01-04  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "60612 2022-01-05  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "\n",
       "       STORE      STORE_NAME  INTRANSIT  EXPECTED  PRES_STOCK  STOCK  \\\n",
       "60608      1  CNT MATOSINHOS          0        48         120  151.0   \n",
       "60609      1  CNT MATOSINHOS          0        48         120  137.0   \n",
       "60610      1  CNT MATOSINHOS         48         0         120  175.0   \n",
       "60611      1  CNT MATOSINHOS          0         0         120  162.0   \n",
       "60612      1  CNT MATOSINHOS          0        48         120  195.0   \n",
       "\n",
       "       STOCK_1_Dias_Antes  SELLOUT  SELLOUT_1_Dias_Antes  \n",
       "60608               151.0      0.0                  11.0  \n",
       "60609               151.0     14.0                   0.0  \n",
       "60610               137.0     10.0                  14.0  \n",
       "60611               175.0     13.0                  10.0  \n",
       "60612               162.0     15.0                  13.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFinal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fundir o Ficheiro da Delta com a previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.42 s\n",
      "Wall time: 2.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Prophet\n",
    "dfFinal = pd.merge(dfFinal, df_Prophet[['DATA', 'STORE', 'DESC_ARTIGO', 'Prophet']], how=\"left\", on=['DATA', 'STORE', 'DESC_ARTIGO',] )\n",
    "# XGBoost\n",
    "dfFinal = pd.merge(dfFinal, df_XGBoost[['DATA', 'STORE', 'DESC_ARTIGO', 'XGBoost']], how=\"left\", on=['DATA', 'STORE', 'DESC_ARTIGO',] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=green>Ficheiro Lido<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def historico(titulo, alvo, function):\n",
    "    dfFinal[\"%s_30\" %titulo] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['%s' %alvo].shift(1).transform(lambda x: x.rolling(window=30).apply(function))\n",
    "    dfFinal[\"%s_60\" %titulo] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['%s' %alvo].shift(1).transform(lambda x: x.rolling(window=60).apply(function))\n",
    "    dfFinal[\"%s_120\" %titulo] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['%s' %alvo].shift(1).transform(lambda x: x.rolling(window=120).apply(function))\n",
    "    dfFinal[\"%s_180\" %titulo] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['%s' %alvo].shift(1).transform(lambda x: x.rolling(window=160).apply(function))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colunas de métricas interessantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - ROTURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir coluna de rotura (se stock menor ou igual a 0 e existe Linear)\n",
    "\n",
    "dfFinal[\"ROTURA\"] = np.where((dfFinal[\"STOCK\"] <= 0) & (dfFinal[\"PRES_STOCK\"] > 0), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - PRÉ_ROTURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir coluna de rotura (se stock menor ou igual a 0)\n",
    "\n",
    "dfFinal[\"PRE_ROTURA\"] = (dfFinal[\"STOCK\"] < dfFinal[\"PRES_STOCK\"]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colunas de métricas 30, 60, 120 e 180 dias antes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Volatilidade de Procura: <br>\n",
    "coeficiente de variação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.53 s\n",
      "Wall time: 4.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfFinal[\"Volatilidade_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).std())/\n",
    "                             dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).mean()))\n",
    "\n",
    "dfFinal[\"Volatilidade_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).std())/\n",
    "                             dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).mean()))\n",
    "\n",
    "dfFinal[\"Volatilidade_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).std())/\n",
    "                              dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).mean()))\n",
    "\n",
    "dfFinal[\"Volatilidade_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).std())/\n",
    "                              dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).mean()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Percentagem de Rotura: <br>\n",
    "média de roturas $* 100$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.19 s\n",
      "Wall time: 2.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#historico(\"Percentagem_Roturas\", \"ROTURA\", pd.Series.mean)\n",
    "\n",
    "dfFinal[\"Percentagem_Roturas_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Percentagem_Roturas_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Percentagem_Roturas_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Percentagem_Roturas_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Percentagem de Supply:<br>\n",
    "média de vezes que foi pedido stock $*100$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"New_Supply\"] = np.where((dfFinal[\"EXPECTED\"].shift(1)==0) & (dfFinal[\"EXPECTED\"]>0), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historico(\"Percentagem_Supply\", \"New_Supply\", pd.Series.mean)\n",
    "\n",
    "dfFinal[\"Percentagem_Supply_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['New_Supply'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).sum())/30)*100\n",
    "\n",
    "dfFinal[\"Percentagem_Supply_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['New_Supply'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).sum())/60)*100\n",
    "\n",
    "dfFinal[\"Percentagem_Supply_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['New_Supply'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).sum())/120)*100\n",
    "\n",
    "dfFinal[\"Percentagem_Supply_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['New_Supply'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).sum())/180)*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Efeito fim de semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal['SELLOUT_fds'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([4,5,6])][\"SELLOUT\"].copy()\n",
    "dfFinal['SELLOUT_semana'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([0,1,2,3])][\"SELLOUT\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Efeito_Fds_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).median())/\n",
    "                            (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).median())))-1\n",
    "\n",
    "dfFinal[\"Efeito_Fds_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).median())/\n",
    "                            (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).median())))-1\n",
    "\n",
    "dfFinal[\"Efeito_Fds_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).median())/\n",
    "                            (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).median())))-1\n",
    "\n",
    "dfFinal[\"Efeito_Fds_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).median())/\n",
    "                            (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).median())))-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Tempo médio inter-supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"InterSupply\"] = np.where(dfFinal[\"EXPECTED\"]==0, 1, 0)\n",
    "\n",
    "groups = (dfFinal['InterSupply'] != dfFinal['InterSupply'].shift()).cumsum()\n",
    "result = dfFinal.groupby(groups).agg({'DATA': 'first', 'DESC_ARTIGO': 'first', 'STORE': 'first', 'InterSupply': 'sum'}).reset_index(drop=True)\n",
    "result = result[result['InterSupply'] > 0]\n",
    "\n",
    "dfFinal = dfFinal.drop(columns=['InterSupply'])\n",
    "\n",
    "dfFinal = pd.merge(dfFinal, result, how=\"left\", on=[\"DATA\",\"DESC_ARTIGO\", \"STORE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historico(\"InterSupplyMed\", \"InterSupply\", pd.Series.mean)\n",
    "\n",
    "dfFinal[\"InterSupplyMed_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['InterSupply'].transform(lambda x: x.rolling(window=30, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"InterSupplyMed_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['InterSupply'].transform(lambda x: x.rolling(window=60, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"InterSupplyMed_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['InterSupply'].transform(lambda x: x.rolling(window=120, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"InterSupplyMed_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['InterSupply'].transform(lambda x: x.rolling(window=180, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Tempo indisponível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''O que vai acontecer é: no primeiro dia em que há rotura vai aparecer a soma de todos os dias com rotura a seguir a esse!\n",
    "Todos os outros valores serão NaN para não serem considerados quando for feita a média. Assim a média corresponderá ao\n",
    "número médio de dias em que se deixa um produto em rotura.'''\n",
    "\n",
    "dfFinal[\"Tempo_Indisponível\"] = np.where(dfFinal[\"ROTURA\"]==1, 1, 0)\n",
    "\n",
    "groups = (dfFinal['Tempo_Indisponível'] != dfFinal['Tempo_Indisponível'].shift()).cumsum()\n",
    "result = dfFinal.groupby(groups).agg({'DATA': 'first', 'DESC_ARTIGO': 'first', 'STORE': 'first', 'Tempo_Indisponível': 'sum'}).reset_index(drop=True)\n",
    "result = result[result['Tempo_Indisponível'] > 0]\n",
    "\n",
    "dfFinal = dfFinal.drop(columns=['Tempo_Indisponível'])\n",
    "\n",
    "dfFinal = pd.merge(dfFinal, result, how=\"left\", on=[\"DATA\",\"DESC_ARTIGO\", \"STORE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historico(\"Percentagem_Supply\", \"New_Supply\", pd.Series.mean)\n",
    "\n",
    "dfFinal[\"Tempo_Indisponível_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Tempo_Indisponível'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).mean()))\n",
    "\n",
    "dfFinal[\"Tempo_Indisponível_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Tempo_Indisponível'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).mean()))\n",
    "\n",
    "dfFinal[\"Tempo_Indisponível_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Tempo_Indisponível'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).mean()))\n",
    "\n",
    "dfFinal[\"Tempo_Indisponível_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Tempo_Indisponível'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Percentagem de dias em Stock Borderline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Stock_Borderline\"] = np.where(dfFinal[\"STOCK\"]<0.2*dfFinal[\"PRES_STOCK\"], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Tempo_Stock_Borderline_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Stock_Borderline'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Tempo_Stock_Borderline_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Stock_Borderline'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Tempo_Stock_Borderline_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Stock_Borderline'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Tempo_Stock_Borderline_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Stock_Borderline'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Percentagem de dias de Linear Incompleto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Linear_Incompleto\"] = np.where(dfFinal[\"STOCK\"]<dfFinal[\"PRES_STOCK\"], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Tempo_Linear_Incompleto_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Linear_Incompleto'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Tempo_Linear_Incompleto_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Linear_Incompleto'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Tempo_Linear_Incompleto_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Linear_Incompleto'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Tempo_Linear_Incompleto_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Linear_Incompleto'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Percentagem de dias sem vendas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Sem_Vendas\"] = np.where(dfFinal[\"SELLOUT\"] == 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historico(\"Sem_Vendas\", \"Sem_Vendas\", pd.Series.mean)\n",
    "\n",
    "dfFinal[\"Sem_Vendas_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Sem_Vendas'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Sem_Vendas_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Sem_Vendas'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Sem_Vendas_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Sem_Vendas'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Sem_Vendas_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Sem_Vendas'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Vendas perdidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal['ROTURA_fds'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([4,5,6])][\"ROTURA\"].copy()\n",
    "dfFinal['ROTURA_semana'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([0,1,2,3])][\"ROTURA\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Mediana de fins de semana e mediana de semana a multiplicar pelo nº de dias em que há rotura, soma dos valores para\n",
    "ter as perdas de vendas estimadas'''\n",
    "\n",
    "#mediana fds*roturas fds + mediana semana*roturas semana\n",
    "\n",
    "dfFinal[\"Vendas_Perdidas_30\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_fds'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).median())) + \n",
    "                                (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_semana'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).median()))\n",
    ")\n",
    "dfFinal[\"Vendas_Perdidas_60\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_fds'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).median())) + \n",
    "                                (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_semana'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).median()))\n",
    ")\n",
    "dfFinal[\"Vendas_Perdidas_120\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_fds'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).median())) + \n",
    "                                 (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_semana'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).median()))\n",
    ")\n",
    "dfFinal[\"Vendas_Perdidas_180\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_fds'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).median())) + \n",
    "                                 (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_semana'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).median()))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas até 10 dias antes:\n",
    "\n",
    "- INSTRANSIT\n",
    "- EXPECTED\n",
    "- SELLOUT\n",
    "- CICLOS\n",
    "- Dias para Rotura\n",
    "- Adequação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantos dias antes:\n",
    "\n",
    "diaI=4         #dia inicial\n",
    "diaF=5       #dia final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para colunas de dias anteriores\n",
    "def dias(df, dia, coluna):         #dia é quantos dias antes\n",
    "    a=int(dia)\n",
    "\n",
    "    valores = df.groupby(['DESC_ARTIGO', 'STORE'])[coluna].transform(lambda x: x.shift(a))\n",
    "    valores[:a] = np.nan\n",
    "    \n",
    "    df.loc[:,'%s_%s_Dias_Antes' % (coluna, a)] = valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - SELLOUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.66 s\n",
      "Wall time: 1.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Usar função para sellouts até 10 dias antes\n",
    "\n",
    "for i in range(diaI+1, diaF+1):\n",
    "    dias(dfFinal, i, \"SELLOUT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - STOCKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar função para Stocks até 10 dias antes\n",
    "\n",
    "for i in range(diaI, diaF+1):\n",
    "    dias(dfFinal, i, \"STOCK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> > - Ordenar"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "previsões = 2\n",
    "dfOrg = dfFinal.iloc[:, np.r_[:9, 10, 12, 13, 12+previsões, 13+previsões, 9, \n",
    "                                (23+previsões):(32+previsões), 11, (14+previsões):(23+previsões)]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "df_columns = dfOrg.columns.tolist()\n",
    "indexed_columns = [f\"{index}: {column}\" for index, column in enumerate(df_columns)]\n",
    "indexed_columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dfFinal = dfFinal.iloc[:, np.r_[:9, 10, 12, 13, 12+previsões, 13+previsões, 9, \n",
    "                                (23+previsões):(32+previsões), 11, (14+previsões):(23+previsões)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - INTRANSIT e EXPECTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar função para Trânsito até 10 dias antes\n",
    "\n",
    "\n",
    "for i in range(diaI, diaF+1):\n",
    "    dias(dfFinal, i, \"INTRANSIT\")\n",
    "    \n",
    "for i in range(diaI, diaF+1):\n",
    "    dias(dfFinal, i, \"EXPECTED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - STK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STK do dia = soma dos stocks em loja com os stocks em trânsito no próprio dia\n",
    "\n",
    "dfFinal[\"STK\"] = dfFinal[\"STOCK\"] + dfFinal[\"INTRANSIT\"] + dfFinal[\"EXPECTED\"]\n",
    "\n",
    "for i in range(diaI, diaF+1):\n",
    "    dias(dfFinal, i, \"STK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - MSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSA do dia = média dos sellouts dos 10 dias anteriores ao dia em causa\n",
    "\n",
    "dfFinal[\"MSA10\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10, min_periods=1).mean())\n",
    "dfFinal[\"MSA10Dp\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10, min_periods=1).std())\n",
    "\n",
    "for i in range(diaI, diaF+1):\n",
    "    dias(dfFinal, i, \"MSA10\")\n",
    "\n",
    "    \n",
    "dfFinal[\"MSA20\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=20, min_periods=1).mean())\n",
    "dfFinal[\"MSA20Dp\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=20, min_periods=1).std())\n",
    "  \n",
    "for i in range(diaI, diaF+1):\n",
    "    dias(dfFinal, i, \"MSA20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - CICLOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coluna de Ciclos de reposição\n",
    "\n",
    "dfFinal[\"CICLOS\"] = dfFinal[\"STOCK\"]/dfFinal[\"PRES_STOCK\"]\n",
    "\n",
    "for i in range(diaI, diaF+1):\n",
    "    dias(dfFinal, i, \"CICLOS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Dias para rotura de Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfFinal = dfFinal.copy()\n",
    "# Dias para a rotura mas com o Sellout médio (móvel) dos últimos 10 dias \n",
    "dfFinal[\"Dias_para_Rotura_Stock\"] = dfFinal[\"STOCK\"] / dfFinal[\"MSA10\"]\n",
    "\n",
    "for i in range(diaI, diaF+1):\n",
    "    dias(dfFinal, i, \"Dias_para_Rotura_Stock\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Dias para rotura de Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a métrica: Preslinear / med(Sellouts 10 dias)\n",
    "dfFinal['Dias_Duração_Linear'] = dfFinal[\"PRES_STOCK\"] / dfFinal[\"MSA10\"]\n",
    "\n",
    "for i in range(diaI, diaF+1):\n",
    "    dias(dfFinal, i, \"Dias_Duração_Linear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Adequação de Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coluna de adequação de stock\n",
    "\n",
    "\n",
    "dfFinal[\"Adequação\"]= np.where(dfFinal[\"CICLOS\"] > 1.1, \"Stock Suficiente\", \n",
    "                      np.where((dfFinal[\"CICLOS\"] <= 1.1) & (dfFinal[\"INTRANSIT\"]+dfFinal[\"EXPECTED\"]+dfFinal[\"STOCK\"]>=dfFinal[\"PRES_STOCK\"]), \"Stock Insuf c Forn Adequado\", \n",
    "                      np.where((dfFinal[\"CICLOS\"] <= 1.1) & (dfFinal[\"INTRANSIT\"]+dfFinal[\"EXPECTED\"]+dfFinal[\"STOCK\"]<dfFinal[\"PRES_STOCK\"]), \"Stock Insuf c Forn Desadequado\", \n",
    "                      \"\")))\n",
    "\n",
    "for i in range(diaI, diaF+1):\n",
    "    dias(dfFinal, i, \"Adequação\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- Balance: sellout / soma stock disponível mais transito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas de balanço\n",
    "\n",
    "\n",
    "# Balance do dia = razão entre o sellout médio e o stock para o dia actual\n",
    "dfFinal[\"Balance\"] =  dfFinal[\"MSA10\"] / dfFinal[\"STK\"]\n",
    "\n",
    "for i in range(diaI, diaF+1):\n",
    "    \n",
    "    \n",
    "    valores = (i+1) * dfFinal[\"Balance\"].shift(i)\n",
    "    valores[:i] = np.nan\n",
    "    \n",
    "    dfFinal.loc[:,'%s_%s_Dias_Antes' % (\"Balance\", i)] = valores\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA</th>\n",
       "      <th>STORE_NAME</th>\n",
       "      <th>DESC_ARTIGO</th>\n",
       "      <th>Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-01-09</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-01-10</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022-01-11</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0.135294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022-01-12</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0.109023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022-01-13</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0.121429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022-01-14</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0.053086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022-01-15</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0.083226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022-01-16</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0.087838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022-01-17</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0.088112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-01-18</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0.088971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022-01-19</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0.068421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022-01-20</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0.061983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0.068421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2022-01-22</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0.075728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2022-01-23</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0.084848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2022-01-24</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0.087629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0.081319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2022-01-26</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0.025098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2022-01-27</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0.036527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0.035503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0.036416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2022-01-30</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>0.045033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATA      STORE_NAME                             DESC_ARTIGO  \\\n",
       "0  2022-01-01  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "1  2022-01-02  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "2  2022-01-03  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "3  2022-01-04  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "4  2022-01-05  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "5  2022-01-06  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "6  2022-01-07  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "7  2022-01-08  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "8  2022-01-09  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "9  2022-01-10  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "10 2022-01-11  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "11 2022-01-12  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "12 2022-01-13  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "13 2022-01-14  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "14 2022-01-15  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "15 2022-01-16  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "16 2022-01-17  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "17 2022-01-18  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "18 2022-01-19  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "19 2022-01-20  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "20 2022-01-21  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "21 2022-01-22  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "22 2022-01-23  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "23 2022-01-24  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "24 2022-01-25  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "25 2022-01-26  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "26 2022-01-27  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "27 2022-01-28  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "28 2022-01-29  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "29 2022-01-30  CNT MATOSINHOS  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "\n",
       "     Balance  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  \n",
       "5        NaN  \n",
       "6        NaN  \n",
       "7        NaN  \n",
       "8        NaN  \n",
       "9        NaN  \n",
       "10  0.135294  \n",
       "11  0.109023  \n",
       "12  0.121429  \n",
       "13  0.053086  \n",
       "14  0.083226  \n",
       "15  0.087838  \n",
       "16  0.088112  \n",
       "17  0.088971  \n",
       "18  0.068421  \n",
       "19  0.061983  \n",
       "20  0.068421  \n",
       "21  0.075728  \n",
       "22  0.084848  \n",
       "23  0.087629  \n",
       "24  0.081319  \n",
       "25  0.025098  \n",
       "26  0.036527  \n",
       "27  0.035503  \n",
       "28  0.036416  \n",
       "29  0.045033  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFinal[[\"DATA\", \"STORE_NAME\", \"DESC_ARTIGO\", \"Balance\"]].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- Balance optimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "dfFinal[\"Balance_Optimized\"] = np.where((dfFinal[\"MSA10Dp\"] / dfFinal[\"MSA10\"]) * 100 > 100, dfFinal[\"MSA20\"] / dfFinal[\"STK\"],\n",
    "                                dfFinal[\"MSA10\"] / dfFinal[\"STK\"])   \n",
    "\n",
    "for i in range(diaI, diaF+1):\n",
    "    \n",
    "    \n",
    "    valores = (i+1) * dfFinal[\"Balance_Optimized\"].shift(i)\n",
    "    valores[:i] = np.nan\n",
    "    \n",
    "    dfFinal.loc[:,'%s_%s_Dias_Antes' % (\"Balance_Optimized\", i)] = valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Mediano é com o mínimo dos ultimos 10 dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coluna de adequação de stock\n",
    "\n",
    "\n",
    "# MSA_med do dia = mediana dos sellouts dos 10 dias anteriores (exclui o próprio dia)\n",
    "# dfFinal[\"MdSA\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10).median())\n",
    "\n",
    "\n",
    "# Balance do dia = razão entre o sellout médio e o stock para o dia actual\n",
    "dfFinal[\"Balance_Mediano\"] =  dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10).median()) / dfFinal[\"STK\"]\n",
    "\n",
    "for i in range(diaI, diaF+1):\n",
    "    \n",
    "    \n",
    "    valores = (i+1) * dfFinal[\"Balance_Mediano\"].shift(i)\n",
    "    valores[:i] = np.nan\n",
    "    \n",
    "    dfFinal.loc[:,'%s_%s_Dias_Antes' % (\"Balance_Mediano\", i)] = valores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Liberal é com o mínimo dos ultimos 10 dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liberal\n",
    "\n",
    "\n",
    "# MSA do dia = média dos stocks dos 10 dias anteriores (exclui o próprio dia)\n",
    "#dfFinal[\"LSA\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10).min())\n",
    "\n",
    "\n",
    "# Balance do dia = razão entre o sellout médio e o stock para o dia actual\n",
    "dfFinal[\"Balance_Liberal\"] =  dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10).min()) / dfFinal[\"STK\"]\n",
    "\n",
    "for i in range(diaI, diaF+1):\n",
    "    \n",
    "    \n",
    "    valores = (i+1) * dfFinal[\"Balance_Liberal\"].shift(i)\n",
    "    valores[:i] = np.nan\n",
    "    \n",
    "    dfFinal.loc[:,'%s_%s_Dias_Antes' % (\"Balance_Liberal\", i)] = valores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Conservador é com o máximo dos ultimos 10 dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conservador\n",
    "\n",
    "# MSA_max do dia = máximo dos stocks dos 10 dias anteriores (exclui o próprio dia)\n",
    "#dfFinal[\"CSA\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10).max())\n",
    " \n",
    "    \n",
    "# Balance do dia = razão entre o sellout médio e o stock para o dia actual\n",
    "dfFinal[\"Balance_Conservador\"] =  dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10).max()) / dfFinal[\"STK\"]\n",
    "\n",
    "for i in range(diaI, diaF+1):\n",
    "    \n",
    "    # Multiplicar os balances pelo número de dias+1 antes do dia actual\n",
    "    valores = (i+1) * dfFinal[\"Balance_Conservador\"].shift(i)\n",
    "    valores[:i] = np.nan\n",
    "    \n",
    "    dfFinal.loc[:,'%s_%s_Dias_Antes' % (\"Balance_Conservador\", i)] = valores\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "> - Smart é com semana e fim de semana"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Real\n",
    "\n",
    "\n",
    "    \n",
    "dfFinal[\"Balance_Optimized\"] = np.where((dfFinal[\"MSA10Dp\"] / dfFinal[\"MSA10\"]) * 100 > 100, dfFinal[\"MSA20\"] / dfFinal[\"STK\"],\n",
    "                                dfFinal[\"MSA10\"] / dfFinal[\"STK\"])   \n",
    "\n",
    "for i in range(diaI, diaF+1):\n",
    "    \n",
    "    \n",
    "    valores = (i+1) * dfFinal[\"Balance_Optimized\"].shift(i)\n",
    "    valores[:i] = np.nan\n",
    "    \n",
    "    dfFinal.loc[:,'%s_%s_Dias_Antes' % (\"Balance_Optimized\", i)] = valores\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "dfFinal[[\"DATA\",\"STORE\",\"DESC_ARTIGO\",\"STOCK\",\"INTRANSIT\",\"EXPECTED\",\"SELLOUT\",\"Balance\",\"Balance_4_Dias_Antes\",\"Balance_Liberal\",\"Balance_Liberal_4_Dias_Antes\",\"Balance_Mediano_4_Dias_Antes\",\"Balance_Conservador_4_Dias_Antes\"]].tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escrever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0's e 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Novo dataframe que apenas inclui dias em que existe a 1ª rotura e o dia anterior a essa rotura\n",
    "\n",
    "# Tirar 1's depois do primeiro\n",
    "dfFinalLimitado = dfFinal[~((dfFinal[\"ROTURA\"] == 1) & (dfFinal[\"ROTURA\"].shift(1) == 1))].copy()\n",
    "\n",
    "# Apenas incluir primeira rotura\n",
    "dfFinalLimitadoRoturas = dfFinal[((dfFinal[\"ROTURA\"] == 1) & (dfFinal[\"ROTURA\"].shift(1) == 0))].copy() #| ((dfFinal[\"ROTURA\"] == 0) & (dfFinal[\"ROTURA\"].shift(-1) == 1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dias certos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal2 = dfFinal.loc[(dfFinal['DATA'] >= '2023-01-01') ].copy()\n",
    "#df_DiasCertos = dfFinalLimitado.loc[(dfFinalLimitado['DATA'] >= '2023-01-01') ].copy()\n",
    "#df_RoturasDiasCertos = dfFinalLimitadoRoturas.loc[(dfFinalLimitadoRoturas['DATA'] >= '2023-01-01') ].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2023-01-01T00:00:00.000000000', '2023-01-02T00:00:00.000000000',\n",
       "       '2023-01-03T00:00:00.000000000', '2023-01-04T00:00:00.000000000',\n",
       "       '2023-01-05T00:00:00.000000000', '2023-01-06T00:00:00.000000000',\n",
       "       '2023-01-07T00:00:00.000000000', '2023-01-08T00:00:00.000000000',\n",
       "       '2023-01-09T00:00:00.000000000', '2023-01-10T00:00:00.000000000',\n",
       "       '2023-01-11T00:00:00.000000000', '2023-01-12T00:00:00.000000000',\n",
       "       '2023-01-13T00:00:00.000000000', '2023-01-14T00:00:00.000000000',\n",
       "       '2023-01-15T00:00:00.000000000', '2023-01-16T00:00:00.000000000',\n",
       "       '2023-01-17T00:00:00.000000000', '2023-01-18T00:00:00.000000000',\n",
       "       '2023-01-19T00:00:00.000000000', '2023-01-20T00:00:00.000000000',\n",
       "       '2023-01-21T00:00:00.000000000', '2023-01-22T00:00:00.000000000',\n",
       "       '2023-01-23T00:00:00.000000000', '2023-01-24T00:00:00.000000000',\n",
       "       '2023-01-25T00:00:00.000000000', '2023-01-26T00:00:00.000000000',\n",
       "       '2023-01-27T00:00:00.000000000', '2023-01-28T00:00:00.000000000',\n",
       "       '2023-01-29T00:00:00.000000000', '2023-01-30T00:00:00.000000000',\n",
       "       '2023-01-31T00:00:00.000000000', '2023-02-01T00:00:00.000000000',\n",
       "       '2023-02-02T00:00:00.000000000', '2023-02-03T00:00:00.000000000',\n",
       "       '2023-02-04T00:00:00.000000000', '2023-02-05T00:00:00.000000000',\n",
       "       '2023-02-07T00:00:00.000000000', '2023-02-08T00:00:00.000000000',\n",
       "       '2023-02-09T00:00:00.000000000', '2023-02-10T00:00:00.000000000',\n",
       "       '2023-02-11T00:00:00.000000000', '2023-02-12T00:00:00.000000000',\n",
       "       '2023-02-13T00:00:00.000000000', '2023-02-14T00:00:00.000000000',\n",
       "       '2023-02-15T00:00:00.000000000', '2023-02-16T00:00:00.000000000',\n",
       "       '2023-02-17T00:00:00.000000000', '2023-02-18T00:00:00.000000000',\n",
       "       '2023-02-19T00:00:00.000000000', '2023-02-20T00:00:00.000000000',\n",
       "       '2023-02-21T00:00:00.000000000', '2023-02-22T00:00:00.000000000',\n",
       "       '2023-02-24T00:00:00.000000000', '2023-02-25T00:00:00.000000000',\n",
       "       '2023-02-26T00:00:00.000000000', '2023-02-27T00:00:00.000000000',\n",
       "       '2023-02-28T00:00:00.000000000', '2023-03-01T00:00:00.000000000',\n",
       "       '2023-03-02T00:00:00.000000000', '2023-03-03T00:00:00.000000000',\n",
       "       '2023-03-04T00:00:00.000000000', '2023-03-05T00:00:00.000000000',\n",
       "       '2023-03-06T00:00:00.000000000', '2023-03-07T00:00:00.000000000',\n",
       "       '2023-03-08T00:00:00.000000000', '2023-03-09T00:00:00.000000000',\n",
       "       '2023-03-10T00:00:00.000000000', '2023-03-11T00:00:00.000000000',\n",
       "       '2023-03-12T00:00:00.000000000', '2023-03-13T00:00:00.000000000',\n",
       "       '2023-03-14T00:00:00.000000000', '2023-03-15T00:00:00.000000000',\n",
       "       '2023-03-16T00:00:00.000000000', '2023-03-17T00:00:00.000000000',\n",
       "       '2023-03-18T00:00:00.000000000', '2023-03-19T00:00:00.000000000',\n",
       "       '2023-03-20T00:00:00.000000000', '2023-03-21T00:00:00.000000000',\n",
       "       '2023-03-22T00:00:00.000000000', '2023-03-23T00:00:00.000000000',\n",
       "       '2023-03-24T00:00:00.000000000', '2023-03-25T00:00:00.000000000',\n",
       "       '2023-03-26T00:00:00.000000000', '2023-03-27T00:00:00.000000000',\n",
       "       '2023-03-28T00:00:00.000000000', '2023-03-29T00:00:00.000000000',\n",
       "       '2023-03-30T00:00:00.000000000', '2023-03-31T00:00:00.000000000',\n",
       "       '2023-04-01T00:00:00.000000000', '2023-04-02T00:00:00.000000000',\n",
       "       '2023-04-03T00:00:00.000000000', '2023-04-04T00:00:00.000000000',\n",
       "       '2023-04-05T00:00:00.000000000', '2023-04-06T00:00:00.000000000',\n",
       "       '2023-04-07T00:00:00.000000000', '2023-04-08T00:00:00.000000000',\n",
       "       '2023-04-09T00:00:00.000000000', '2023-04-10T00:00:00.000000000',\n",
       "       '2023-04-11T00:00:00.000000000', '2023-04-12T00:00:00.000000000',\n",
       "       '2023-04-13T00:00:00.000000000', '2023-04-14T00:00:00.000000000',\n",
       "       '2023-04-15T00:00:00.000000000', '2023-04-16T00:00:00.000000000',\n",
       "       '2023-04-17T00:00:00.000000000', '2023-04-18T00:00:00.000000000',\n",
       "       '2023-04-19T00:00:00.000000000', '2023-04-20T00:00:00.000000000',\n",
       "       '2023-04-21T00:00:00.000000000', '2023-04-22T00:00:00.000000000',\n",
       "       '2023-04-23T00:00:00.000000000', '2023-04-24T00:00:00.000000000',\n",
       "       '2023-04-25T00:00:00.000000000', '2023-04-26T00:00:00.000000000',\n",
       "       '2023-04-27T00:00:00.000000000', '2023-04-28T00:00:00.000000000',\n",
       "       '2023-04-29T00:00:00.000000000', '2023-04-30T00:00:00.000000000',\n",
       "       '2023-05-01T00:00:00.000000000', '2023-05-02T00:00:00.000000000',\n",
       "       '2023-05-03T00:00:00.000000000', '2023-05-04T00:00:00.000000000',\n",
       "       '2023-05-05T00:00:00.000000000', '2023-05-06T00:00:00.000000000',\n",
       "       '2023-05-07T00:00:00.000000000', '2023-05-08T00:00:00.000000000',\n",
       "       '2023-05-09T00:00:00.000000000', '2023-05-10T00:00:00.000000000'],\n",
       "      dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFinal2.DATA.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Passar para csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 219 ms\n",
      "Wall time: 524 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "escrever_csv(filtered_oi, \"Métricas3060120_Piloto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "escrever_csv(dfFinal2, \"Mil_MétricasCerto07\")\n",
    "#escrever_csv(df_DiasCertos, \"StocksDelta_2023_10prod_Limpo\")\n",
    "#escrever_csv(df_RoturasDiasCertos, \"StocksDelta_2023_10prod_Roturas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escrever_excel(dataFrame, nomeFicheiro):\n",
    "    dataFrame.to_excel('D:\\\\B&N Dados\\\\Delta\\\\Piloto\\\\%s.xlsx' %nomeFicheiro, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "escrever_excel(oi, \"ParaTestarCoisas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m oiEscrever \u001b[38;5;241m=\u001b[39m oi[(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-04-14\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39moi[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATA\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-04-16\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-04-21\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39moi[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATA\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-04-23\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-04-28\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39moi[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATA\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-04-30\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-05-05\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39moi[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATA\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-05-07\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\core\\generic.py:1527\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__nonzero__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1528\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe truth value of a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is ambiguous. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1529\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1530\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "oiEscrever = oi[(\"2023-04-14\"<=oi[\"DATA\"]<=\"2023-04-16\") or (\"2023-04-21\"<=oi[\"DATA\"]<=\"2023-04-23\") or (\"2023-04-28\"<=oi[\"DATA\"]<=\"2023-04-30\") or (\"2023-05-05\"<=oi[\"DATA\"]<=\"2023-05-07\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_oi = oi[oi[\"DATA\"].between(\"2023-04-14\", \"2023-04-16\") |\n",
    "                  oi[\"DATA\"].between(\"2023-04-21\", \"2023-04-23\") |\n",
    "                  oi[\"DATA\"].between(\"2023-04-28\", \"2023-04-30\") |\n",
    "                  oi[\"DATA\"].between(\"2023-05-05\", \"2023-05-07\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clickhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clickhouse_connect\n",
    "from clickhouse_driver import Client\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estabelecer a base a ser lida\n",
    "\n",
    "baseCH = dfFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(baseCH.DESC_ARTIGO.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"DATA\" Date, \"DESC_ARTIGO\" String, \"STORE_NAME\" String, \"Adequacao\" String, \"Adequacao_4_Dias_Antes\" String, \"Adequacao_5_Dias_Antes\" String, \"EAN\" Float64, \"STORE\" Float64, \"INTRANSIT\" Float64, \"EXPECTED\" Float64, \"PRES_STOCK\" Float64, \"STOCK\" Float64, \"STOCK_1_Dias_Antes\" Float64, \"SELLOUT\" Float64, \"SELLOUT_1_Dias_Antes\" Float64, \"Prophet\" Float64, \"XGBoost\" Float64, \"Volatilidade_30\" Float64, \"Volatilidade_60\" Float64, \"Volatilidade_120\" Float64, \"Volatilidade_180\" Float64, \"Percentagem_Roturas_30\" Float64, \"Percentagem_Roturas_60\" Float64, \"Percentagem_Roturas_120\" Float64, \"Percentagem_Roturas_180\" Float64, \"Percentagem_Supply_30\" Float64, \"Percentagem_Supply_60\" Float64, \"Percentagem_Supply_120\" Float64, \"Percentagem_Supply_180\" Float64, \"SELLOUT_fds\" Float64, \"SELLOUT_semana\" Float64, \"Efeito_Fds_30\" Float64, \"Efeito_Fds_60\" Float64, \"Efeito_Fds_120\" Float64, \"Efeito_Fds_180\" Float64, \"InterSupply\" Float64, \"InterSupplyMed_30\" Float64, \"InterSupplyMed_60\" Float64, \"InterSupplyMed_120\" Float64, \"InterSupplyMed_180\" Float64, \"Tempo_Indisponivel\" Float64, \"Tempo_Indisponivel_30\" Float64, \"Tempo_Indisponivel_60\" Float64, \"Tempo_Indisponivel_120\" Float64, \"Tempo_Indisponivel_180\" Float64, \"Tempo_Stock_Borderline_30\" Float64, \"Tempo_Stock_Borderline_60\" Float64, \"Tempo_Stock_Borderline_120\" Float64, \"Tempo_Stock_Borderline_180\" Float64, \"Tempo_Linear_Incompleto_30\" Float64, \"Tempo_Linear_Incompleto_60\" Float64, \"Tempo_Linear_Incompleto_120\" Float64, \"Tempo_Linear_Incompleto_180\" Float64, \"Sem_Vendas_30\" Float64, \"Sem_Vendas_60\" Float64, \"Sem_Vendas_120\" Float64, \"Sem_Vendas_180\" Float64, \"ROTURA_fds\" Float64, \"ROTURA_semana\" Float64, \"Vendas_Perdidas_30\" Float64, \"Vendas_Perdidas_60\" Float64, \"Vendas_Perdidas_120\" Float64, \"Vendas_Perdidas_180\" Float64, \"SELLOUT_5_Dias_Antes\" Float64, \"STOCK_4_Dias_Antes\" Float64, \"STOCK_5_Dias_Antes\" Float64, \"INTRANSIT_4_Dias_Antes\" Float64, \"INTRANSIT_5_Dias_Antes\" Float64, \"EXPECTED_4_Dias_Antes\" Float64, \"EXPECTED_5_Dias_Antes\" Float64, \"STK\" Float64, \"STK_4_Dias_Antes\" Float64, \"STK_5_Dias_Antes\" Float64, \"MSA10\" Float64, \"MSA10Dp\" Float64, \"MSA10_4_Dias_Antes\" Float64, \"MSA10_5_Dias_Antes\" Float64, \"MSA20\" Float64, \"MSA20Dp\" Float64, \"MSA20_4_Dias_Antes\" Float64, \"MSA20_5_Dias_Antes\" Float64, \"CICLOS\" Float64, \"CICLOS_4_Dias_Antes\" Float64, \"CICLOS_5_Dias_Antes\" Float64, \"Dias_para_Rotura_Stock\" Float64, \"Dias_para_Rotura_Stock_4_Dias_Antes\" Float64, \"Dias_para_Rotura_Stock_5_Dias_Antes\" Float64, \"Dias_Duracao_Linear\" Float64, \"Dias_Duracao_Linear_4_Dias_Antes\" Float64, \"Dias_Duracao_Linear_5_Dias_Antes\" Float64, \"Balance\" Float64, \"Balance_4_Dias_Antes\" Float64, \"Balance_5_Dias_Antes\" Float64, \"Balance_Optimized\" Float64, \"Balance_Optimized_4_Dias_Antes\" Float64, \"Balance_Optimized_5_Dias_Antes\" Float64, \"Balance_Mediano\" Float64, \"Balance_Mediano_4_Dias_Antes\" Float64, \"Balance_Mediano_5_Dias_Antes\" Float64, \"Balance_Liberal\" Float64, \"Balance_Liberal_4_Dias_Antes\" Float64, \"Balance_Liberal_5_Dias_Antes\" Float64, \"Balance_Conservador\" Float64, \"Balance_Conservador_4_Dias_Antes\" Float64, \"Balance_Conservador_5_Dias_Antes\" Float64'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<clickhouse_connect.driver.summary.QuerySummary at 0x1defa82a5f0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "client = clickhouse_connect.get_client(host='e28fluocjc.europe-west4.gcp.clickhouse.cloud', \n",
    "                                       port=8443, \n",
    "                                       username='default', \n",
    "                                       password='N_Mx30OFTC1hN',\n",
    "                                       database='Delta')\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "baseCH['DATA']= pd.to_datetime(baseCH['DATA'], format='%Y-%m-%d')  # Passar para datetime\n",
    "new_columns = [unidecode(col) for col in baseCH.columns]           # Tirar acentos e afins\n",
    "baseCH.columns = new_columns                                       # Aplicar alterações da linha anterior\n",
    "###\n",
    "\n",
    "# Tipos de dados\n",
    "data = [\"DATA\"]\n",
    "texto = [col for col in baseCH.columns if baseCH[col].dtype == 'object']\n",
    "inteiros = [col for col in baseCH.columns if baseCH[col].dtype in ['int64', 'int32']]\n",
    "floats = [col for col in baseCH.columns if baseCH[col].dtype == 'float64']\n",
    "\n",
    "\n",
    "# Só floats é que permitem missing values\n",
    "for col_name in inteiros:\n",
    "    baseCH[col_name] = baseCH[col_name].astype(float)\n",
    "# Missing values em strings estragam tudo\n",
    "baseCH[texto] = baseCH[texto].fillna(\"-\")\n",
    "\n",
    "\n",
    "def schema(lista, tipo):\n",
    "    result_list = [f\"{element} {tipo}\" for element in lista]\n",
    "    return result_list\n",
    "\n",
    "data1 = schema(data, \"Date\")\n",
    "texto1 = schema(texto, \"String\")\n",
    "inteiros1 = schema(inteiros, \"Float64\")\n",
    "floats1 = schema(floats, \"Float64\")\n",
    "total = tuple(data1 + texto1 + inteiros1 + floats1)\n",
    "\n",
    "schema = ', '.join([column.replace(\"'\", \"\") for column in total])\n",
    "\n",
    "# Split the input string by commas\n",
    "parts = schema.split(', ')\n",
    "# Process each part and wrap the first word in double quotes\n",
    "output_parts = []\n",
    "for part in parts:\n",
    "    words = part.split()\n",
    "    if words:\n",
    "        first_word = words[0]\n",
    "        remaining_words = ' '.join(words[1:])\n",
    "        output_part = f'\"{first_word}\" {remaining_words}'\n",
    "        output_parts.append(output_part)\n",
    "# Join the modified parts back into a string\n",
    "schema = ', '.join(output_parts)\n",
    "\n",
    "tabela = \"Daily\"\n",
    "\n",
    "# Eliminar tabela no CH\n",
    "client.command(f'DROP TABLE IF EXISTS {tabela}')\n",
    "\n",
    "# Criar tabela no CH\n",
    "client.command(f'''\n",
    "    CREATE TABLE IF NOT EXISTS {tabela} (\n",
    "        {schema}\n",
    "        ) ENGINE = MergeTree\n",
    "        ORDER BY (DATA)\n",
    "''')\n",
    "\n",
    "client.insert_df(tabela, baseCH, column_names=baseCH.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA</th>\n",
       "      <th>EAN</th>\n",
       "      <th>DESC_ARTIGO</th>\n",
       "      <th>STORE</th>\n",
       "      <th>STORE_NAME</th>\n",
       "      <th>INTRANSIT</th>\n",
       "      <th>EXPECTED</th>\n",
       "      <th>PRES_STOCK</th>\n",
       "      <th>STOCK</th>\n",
       "      <th>STOCK_1_Dias_Antes</th>\n",
       "      <th>...</th>\n",
       "      <th>Balance_Optimized_5_Dias_Antes</th>\n",
       "      <th>Balance_Mediano</th>\n",
       "      <th>Balance_Mediano_4_Dias_Antes</th>\n",
       "      <th>Balance_Mediano_5_Dias_Antes</th>\n",
       "      <th>Balance_Liberal</th>\n",
       "      <th>Balance_Liberal_4_Dias_Antes</th>\n",
       "      <th>Balance_Liberal_5_Dias_Antes</th>\n",
       "      <th>Balance_Conservador</th>\n",
       "      <th>Balance_Conservador_4_Dias_Antes</th>\n",
       "      <th>Balance_Conservador_5_Dias_Antes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>5.609060e+12</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>5.609060e+12</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>5.609060e+12</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>5.609060e+12</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>5.609060e+12</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATA           EAN                             DESC_ARTIGO  STORE  \\\n",
       "0 2022-01-01  5.609060e+12  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G    1.0   \n",
       "1 2022-01-02  5.609060e+12  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G    1.0   \n",
       "2 2022-01-03  5.609060e+12  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G    1.0   \n",
       "3 2022-01-04  5.609060e+12  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G    1.0   \n",
       "4 2022-01-05  5.609060e+12  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G    1.0   \n",
       "\n",
       "       STORE_NAME  INTRANSIT  EXPECTED  PRES_STOCK  STOCK  STOCK_1_Dias_Antes  \\\n",
       "0  CNT MATOSINHOS        0.0      48.0       120.0  151.0               151.0   \n",
       "1  CNT MATOSINHOS        0.0      48.0       120.0  137.0               151.0   \n",
       "2  CNT MATOSINHOS       48.0       0.0       120.0  175.0               137.0   \n",
       "3  CNT MATOSINHOS        0.0       0.0       120.0  162.0               175.0   \n",
       "4  CNT MATOSINHOS        0.0      48.0       120.0  195.0               162.0   \n",
       "\n",
       "   ...  Balance_Optimized_5_Dias_Antes  Balance_Mediano  \\\n",
       "0  ...                             NaN              NaN   \n",
       "1  ...                             NaN              NaN   \n",
       "2  ...                             NaN              NaN   \n",
       "3  ...                             NaN              NaN   \n",
       "4  ...                             NaN              NaN   \n",
       "\n",
       "   Balance_Mediano_4_Dias_Antes  Balance_Mediano_5_Dias_Antes  \\\n",
       "0                           NaN                           NaN   \n",
       "1                           NaN                           NaN   \n",
       "2                           NaN                           NaN   \n",
       "3                           NaN                           NaN   \n",
       "4                           NaN                           NaN   \n",
       "\n",
       "   Balance_Liberal  Balance_Liberal_4_Dias_Antes  \\\n",
       "0              NaN                           NaN   \n",
       "1              NaN                           NaN   \n",
       "2              NaN                           NaN   \n",
       "3              NaN                           NaN   \n",
       "4              NaN                           NaN   \n",
       "\n",
       "   Balance_Liberal_5_Dias_Antes  Balance_Conservador  \\\n",
       "0                           NaN                  NaN   \n",
       "1                           NaN                  NaN   \n",
       "2                           NaN                  NaN   \n",
       "3                           NaN                  NaN   \n",
       "4                           NaN                  NaN   \n",
       "\n",
       "   Balance_Conservador_4_Dias_Antes  Balance_Conservador_5_Dias_Antes  \n",
       "0                               NaN                               NaN  \n",
       "1                               NaN                               NaN  \n",
       "2                               NaN                               NaN  \n",
       "3                               NaN                               NaN  \n",
       "4                               NaN                               NaN  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFinal.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
