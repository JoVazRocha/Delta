{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumo do código\n",
    "\n",
    "### <u>Código que gera os ficheiros para estudo do comportamento da Delta</u>\n",
    "---\n",
    "O objectivo é receber dados da Delta e devolver um conjunto de métricas para prever roturas. Devolve um ficheiro que pode entrar no código 1 para juntar aos dados dos ninjas.\n",
    "\n",
    "---\n",
    "- Inputs\n",
    "\n",
    "> __Dados completos da Delta em pastas de ficheiros__ (de azul a verde)\n",
    "> - Stocks e trânsito, Sellout do dia anterior\n",
    "\n",
    "                    ou\n",
    "\n",
    "> __Ficheiro já completo__ (de vermelho a verde)\n",
    "> - Stocks e trânsito, Sellout do dia anterior\n",
    "\n",
    "- Outputs\n",
    "\n",
    "> __Ficheiro com produtos em causa__ em formato Long\n",
    "\n",
    "> __Métricas novas:__\n",
    "> - Roturas de Stock e Pré-rotura\n",
    "> - Sinal\n",
    "> - Ciclos e Adequação de Stock\n",
    "> - MSA (média de sellouts 10 dias antes)\n",
    "> - STK (Stock disponível + trânsito)\n",
    "> - (Novo) Balanço médio, mediano, liberal e conservador \n",
    "> - (Novo) Dias para a rotura de stock e de prateleira\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "\n",
    "def escrever_csv(dfa, nome): \n",
    "    dfa.to_csv('D:\\\\B&N Dados\\\\Delta\\\\Stocks\\\\StocksTotal\\\\%s.csv' %nome, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:red\"><u>Ler Ficheiro Completo</u> </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 22.5 s\n",
      "Wall time: 30.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Ler os ficheiros\n",
    "df_2022 = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Stocks\\\\Stocks2022\\\\Stocks_Delta_2022_Limpo.csv')\n",
    "df_2023 = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Stocks\\\\Stocks2023\\\\Stocks_Delta_2023_Limpo.csv')\n",
    "\n",
    "# Juntar as bases\n",
    "dataframes = [df_2022, df_2023]\n",
    "df_Fusão = pd.concat(dataframes, ignore_index=True)\n",
    "df_Fusão['DATA']= pd.to_datetime(df_Fusão['DATA'], format='%Y-%m-%d')\n",
    "\n",
    "# Ficheiro de previsão\n",
    "df_Prophet = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Forecast\\\\Prophet.csv')\n",
    "df_Prophet['DATA']= pd.to_datetime(df_Prophet['DATA'], format='%Y-%m-%d')\n",
    "\n",
    "df_XGBoost = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Forecast\\\\XGBoost.csv')\n",
    "df_XGBoost['DATA']= pd.to_datetime(df_XGBoost['DATA'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181\n",
      "334\n"
     ]
    }
   ],
   "source": [
    "print(len(df_2023.DESC_ARTIGO.unique()))\n",
    "print(len(df_2023.STORE.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red>Opcional:</font> Definir produtos em causa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Produtos específicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.77 s\n",
      "Wall time: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Ler ficheiro dos produtos e lojas para dataframe\n",
    "df_produtos = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Piloto\\\\produtos.txt', header=None)\n",
    "df_lojas = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Piloto\\\\lojas.txt', header=None)\n",
    "\n",
    "# Passar para uma lista\n",
    "produtos = df_produtos[0].tolist()\n",
    "lojas = df_lojas[0].tolist()\n",
    "produtos+=[\"CAFÉ DELTA Q MYTHIQ 10CAP\", \"CAFÉ DELTA Q MYTHIQ XL 40CAP\", \"CAFÉ DELTA Q QALIDUS 10CAP\", \"CAFÉ DELTA Q QALIDUS 40CAP\",\n",
    "                'CAFÉ DELTA Q QHARACTER 10CAP','CAFÉ DELTA Q QHARACTER 40CAP','CAFÉ DELTA Q DEQAFEINATUS 10CAP','CAFÉ DELTA Q DEQAFEINATUS XL 40CAP',\n",
    "               'CAFÉ DELTA MOAGEM UNIVERSAL ANGOLA 220G','CAFÉ DELTA MOAGEM UNIVERSAL BRASIL 220G']\n",
    "# Alterar o dataframe para apenas incluir os produtos e lojas em causa\n",
    "dfFinal = df_Fusão[(df_Fusão[\"DESC_ARTIGO\"].isin(produtos)) & (df_Fusão[\"STORE_NAME\"].isin(lojas))].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>Fim</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfFinal = df_Fusão[(df_Fusão[\"DESC_ARTIGO\"].isin(produtos))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal['SELLOUT'] = dfFinal.groupby([\"STORE\",\"EAN\"])['SELLOUT_1_Dias_Antes'].shift(-1)\n",
    "dfFinal['STOCK'] = dfFinal.groupby([\"STORE\",\"EAN\"])['STOCK_1_Dias_Antes'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA</th>\n",
       "      <th>EAN</th>\n",
       "      <th>DESC_ARTIGO</th>\n",
       "      <th>STORE</th>\n",
       "      <th>STORE_NAME</th>\n",
       "      <th>INTRANSIT</th>\n",
       "      <th>EXPECTED</th>\n",
       "      <th>PRES_STOCK</th>\n",
       "      <th>STOCK</th>\n",
       "      <th>STOCK_1_Dias_Antes</th>\n",
       "      <th>SELLOUT</th>\n",
       "      <th>SELLOUT_1_Dias_Antes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60608</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>120</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60609</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>120</td>\n",
       "      <td>137.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60610</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>175.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60611</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>162.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60612</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>120</td>\n",
       "      <td>195.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            DATA            EAN                             DESC_ARTIGO  \\\n",
       "60608 2022-01-01  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "60609 2022-01-02  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "60610 2022-01-03  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "60611 2022-01-04  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "60612 2022-01-05  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G   \n",
       "\n",
       "       STORE      STORE_NAME  INTRANSIT  EXPECTED  PRES_STOCK  STOCK  \\\n",
       "60608      1  CNT MATOSINHOS          0        48         120  151.0   \n",
       "60609      1  CNT MATOSINHOS          0        48         120  137.0   \n",
       "60610      1  CNT MATOSINHOS         48         0         120  175.0   \n",
       "60611      1  CNT MATOSINHOS          0         0         120  162.0   \n",
       "60612      1  CNT MATOSINHOS          0        48         120  195.0   \n",
       "\n",
       "       STOCK_1_Dias_Antes  SELLOUT  SELLOUT_1_Dias_Antes  \n",
       "60608               151.0      0.0                  11.0  \n",
       "60609               151.0     14.0                   0.0  \n",
       "60610               137.0     10.0                  14.0  \n",
       "60611               175.0     13.0                  10.0  \n",
       "60612               162.0     15.0                  13.0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFinal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fundir o Ficheiro da Delta com a previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 594 ms\n",
      "Wall time: 634 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Prophet\n",
    "dfFinal = pd.merge(dfFinal, df_Prophet[['DATA', 'STORE', 'DESC_ARTIGO', 'Prophet']], how=\"left\", on=['DATA', 'STORE', 'DESC_ARTIGO',] )\n",
    "# XGBoost\n",
    "dfFinal = pd.merge(dfFinal, df_XGBoost[['DATA', 'STORE', 'DESC_ARTIGO', 'XGBoost']], how=\"left\", on=['DATA', 'STORE', 'DESC_ARTIGO',] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=green>Ficheiro Lido<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def historico(titulo, alvo, function):\n",
    "    dfFinal[\"%s_30\" %titulo] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['%s' %alvo].shift(1).transform(lambda x: x.rolling(window=30).apply(function))\n",
    "    dfFinal[\"%s_60\" %titulo] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['%s' %alvo].shift(1).transform(lambda x: x.rolling(window=60).apply(function))\n",
    "    dfFinal[\"%s_120\" %titulo] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['%s' %alvo].shift(1).transform(lambda x: x.rolling(window=120).apply(function))\n",
    "    dfFinal[\"%s_180\" %titulo] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['%s' %alvo].shift(1).transform(lambda x: x.rolling(window=160).apply(function))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colunas de métricas interessantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - ROTURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir coluna de rotura (se stock menor ou igual a 0 e existe Linear)\n",
    "\n",
    "dfFinal[\"ROTURA\"] = np.where((dfFinal[\"STOCK\"] <= 0) & (dfFinal[\"PRES_STOCK\"] > 0), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - PRÉ_ROTURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir coluna de rotura (se stock menor ou igual a 0)\n",
    "\n",
    "dfFinal[\"PRE_ROTURA\"] = (dfFinal[\"STOCK\"] < dfFinal[\"PRES_STOCK\"]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colunas de métricas 30, 60, 120 e 180 dias antes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Volatilidade de Procura: <br>\n",
    "coeficiente de variação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 125 ms\n",
      "Wall time: 122 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfFinal[\"Volatilidade_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).std())/\n",
    "                             dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).mean()))\n",
    "\n",
    "dfFinal[\"Volatilidade_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).std())/\n",
    "                             dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).mean()))\n",
    "\n",
    "dfFinal[\"Volatilidade_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).std())/\n",
    "                              dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).mean()))\n",
    "\n",
    "dfFinal[\"Volatilidade_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).std())/\n",
    "                              dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).mean()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Percentagem de Rotura: <br>\n",
    "média de roturas $* 100$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 62.5 ms\n",
      "Wall time: 62.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#historico(\"Percentagem_Roturas\", \"ROTURA\", pd.Series.mean)\n",
    "\n",
    "dfFinal[\"Percentagem_Roturas_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Percentagem_Roturas_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Percentagem_Roturas_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Percentagem_Roturas_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Percentagem de Supply:<br>\n",
    "média de vezes que foi pedido stock $*100$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"New_Supply\"] = np.where((dfFinal[\"EXPECTED\"].shift(1)==0) & (dfFinal[\"EXPECTED\"]>0), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historico(\"Percentagem_Supply\", \"New_Supply\", pd.Series.mean)\n",
    "\n",
    "dfFinal[\"Percentagem_Supply_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['New_Supply'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).sum())/30)*100\n",
    "\n",
    "dfFinal[\"Percentagem_Supply_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['New_Supply'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).sum())/60)*100\n",
    "\n",
    "dfFinal[\"Percentagem_Supply_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['New_Supply'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).sum())/120)*100\n",
    "\n",
    "dfFinal[\"Percentagem_Supply_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['New_Supply'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).sum())/180)*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Efeito fim de semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal['SELLOUT_fds'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([4,5,6])][\"SELLOUT\"].copy()\n",
    "dfFinal['SELLOUT_semana'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([0,1,2,3])][\"SELLOUT\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Efeito_Fds_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).median())/\n",
    "                            (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).median())))-1\n",
    "\n",
    "dfFinal[\"Efeito_Fds_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).median())/\n",
    "                            (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).median())))-1\n",
    "\n",
    "dfFinal[\"Efeito_Fds_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).median())/\n",
    "                            (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).median())))-1\n",
    "\n",
    "dfFinal[\"Efeito_Fds_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).median())/\n",
    "                            (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).median())))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA</th>\n",
       "      <th>EAN</th>\n",
       "      <th>DESC_ARTIGO</th>\n",
       "      <th>STORE</th>\n",
       "      <th>STORE_NAME</th>\n",
       "      <th>INTRANSIT</th>\n",
       "      <th>EXPECTED</th>\n",
       "      <th>PRES_STOCK</th>\n",
       "      <th>STOCK</th>\n",
       "      <th>STOCK_1_Dias_Antes</th>\n",
       "      <th>...</th>\n",
       "      <th>Percentagem_Supply_30</th>\n",
       "      <th>Percentagem_Supply_60</th>\n",
       "      <th>Percentagem_Supply_120</th>\n",
       "      <th>Percentagem_Supply_180</th>\n",
       "      <th>SELLOUT_fds</th>\n",
       "      <th>SELLOUT_semana</th>\n",
       "      <th>Efeito_Fds_30</th>\n",
       "      <th>Efeito_Fds_60</th>\n",
       "      <th>Efeito_Fds_120</th>\n",
       "      <th>Efeito_Fds_180</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>120</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>120</td>\n",
       "      <td>137.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>175.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>162.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>120</td>\n",
       "      <td>195.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.391304</td>\n",
       "      <td>-0.391304</td>\n",
       "      <td>-0.391304</td>\n",
       "      <td>-0.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>184.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-0.461538</td>\n",
       "      <td>-0.461538</td>\n",
       "      <td>-0.461538</td>\n",
       "      <td>-0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>174.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>-0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>137.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-01-09</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>118.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-01-10</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>109.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022-01-11</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>102.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022-01-12</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>120</td>\n",
       "      <td>115.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022-01-13</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>112.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022-01-14</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>120</td>\n",
       "      <td>171.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022-01-15</td>\n",
       "      <td>5609060007087</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>155.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATA            EAN                             DESC_ARTIGO  STORE  \\\n",
       "0  2022-01-01  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      1   \n",
       "1  2022-01-02  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      1   \n",
       "2  2022-01-03  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      1   \n",
       "3  2022-01-04  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      1   \n",
       "4  2022-01-05  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      1   \n",
       "5  2022-01-06  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      1   \n",
       "6  2022-01-07  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      1   \n",
       "7  2022-01-08  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      1   \n",
       "8  2022-01-09  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      1   \n",
       "9  2022-01-10  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      1   \n",
       "10 2022-01-11  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      1   \n",
       "11 2022-01-12  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      1   \n",
       "12 2022-01-13  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      1   \n",
       "13 2022-01-14  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      1   \n",
       "14 2022-01-15  5609060007087  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G      1   \n",
       "\n",
       "        STORE_NAME  INTRANSIT  EXPECTED  PRES_STOCK  STOCK  \\\n",
       "0   CNT MATOSINHOS          0        48         120  151.0   \n",
       "1   CNT MATOSINHOS          0        48         120  137.0   \n",
       "2   CNT MATOSINHOS         48         0         120  175.0   \n",
       "3   CNT MATOSINHOS          0         0         120  162.0   \n",
       "4   CNT MATOSINHOS          0        48         120  195.0   \n",
       "5   CNT MATOSINHOS          0         0         120  184.0   \n",
       "6   CNT MATOSINHOS          0         0         120  174.0   \n",
       "7   CNT MATOSINHOS          0         0         120  137.0   \n",
       "8   CNT MATOSINHOS          0         0         120  118.0   \n",
       "9   CNT MATOSINHOS          0         0         120  109.0   \n",
       "10  CNT MATOSINHOS          0         0         120  102.0   \n",
       "11  CNT MATOSINHOS          0        18         120  115.0   \n",
       "12  CNT MATOSINHOS          0         0         120  112.0   \n",
       "13  CNT MATOSINHOS          0        72         120  171.0   \n",
       "14  CNT MATOSINHOS          0         0         120  155.0   \n",
       "\n",
       "    STOCK_1_Dias_Antes  ...  Percentagem_Supply_30  Percentagem_Supply_60  \\\n",
       "0                151.0  ...                    NaN                    NaN   \n",
       "1                151.0  ...               0.000000               0.000000   \n",
       "2                137.0  ...               0.000000               0.000000   \n",
       "3                175.0  ...               0.000000               0.000000   \n",
       "4                162.0  ...               0.000000               0.000000   \n",
       "5                195.0  ...               3.333333               1.666667   \n",
       "6                184.0  ...               3.333333               1.666667   \n",
       "7                174.0  ...               3.333333               1.666667   \n",
       "8                137.0  ...               3.333333               1.666667   \n",
       "9                118.0  ...               3.333333               1.666667   \n",
       "10               109.0  ...               3.333333               1.666667   \n",
       "11               102.0  ...               3.333333               1.666667   \n",
       "12               115.0  ...               6.666667               3.333333   \n",
       "13               112.0  ...               6.666667               3.333333   \n",
       "14               171.0  ...              10.000000               5.000000   \n",
       "\n",
       "    Percentagem_Supply_120  Percentagem_Supply_180  SELLOUT_fds  \\\n",
       "0                      NaN                     NaN          0.0   \n",
       "1                 0.000000                0.000000         14.0   \n",
       "2                 0.000000                0.000000          NaN   \n",
       "3                 0.000000                0.000000          NaN   \n",
       "4                 0.000000                0.000000          NaN   \n",
       "5                 0.833333                0.555556          NaN   \n",
       "6                 0.833333                0.555556         10.0   \n",
       "7                 0.833333                0.555556         37.0   \n",
       "8                 0.833333                0.555556         19.0   \n",
       "9                 0.833333                0.555556          NaN   \n",
       "10                0.833333                0.555556          NaN   \n",
       "11                0.833333                0.555556          NaN   \n",
       "12                1.666667                1.111111          NaN   \n",
       "13                1.666667                1.111111         13.0   \n",
       "14                2.500000                1.666667         16.0   \n",
       "\n",
       "    SELLOUT_semana  Efeito_Fds_30  Efeito_Fds_60  Efeito_Fds_120  \\\n",
       "0              NaN            NaN            NaN             NaN   \n",
       "1              NaN            NaN            NaN             NaN   \n",
       "2             10.0            NaN            NaN             NaN   \n",
       "3             13.0      -0.300000      -0.300000       -0.300000   \n",
       "4             15.0      -0.391304      -0.391304       -0.391304   \n",
       "5             11.0      -0.461538      -0.461538       -0.461538   \n",
       "6              NaN      -0.416667      -0.416667       -0.416667   \n",
       "7              NaN      -0.166667      -0.166667       -0.166667   \n",
       "8              NaN       0.000000       0.000000        0.000000   \n",
       "9              9.0       0.166667       0.166667        0.166667   \n",
       "10             7.0       0.272727       0.272727        0.272727   \n",
       "11             5.0       0.333333       0.333333        0.333333   \n",
       "12             3.0       0.400000       0.400000        0.400000   \n",
       "13             NaN       0.473684       0.473684        0.473684   \n",
       "14             NaN       0.421053       0.421053        0.421053   \n",
       "\n",
       "    Efeito_Fds_180  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3        -0.300000  \n",
       "4        -0.391304  \n",
       "5        -0.461538  \n",
       "6        -0.416667  \n",
       "7        -0.166667  \n",
       "8         0.000000  \n",
       "9         0.166667  \n",
       "10        0.272727  \n",
       "11        0.333333  \n",
       "12        0.400000  \n",
       "13        0.473684  \n",
       "14        0.421053  \n",
       "\n",
       "[15 rows x 35 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFinal.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Tempo médio inter-supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"InterSupply\"] = np.where(dfFinal[\"EXPECTED\"]==0, 1, 0)\n",
    "\n",
    "groups = (dfFinal['InterSupply'] != dfFinal['InterSupply'].shift()).cumsum()\n",
    "result = dfFinal.groupby(groups).agg({'DATA': 'first', 'DESC_ARTIGO': 'first', 'STORE': 'first', 'InterSupply': 'sum'}).reset_index(drop=True)\n",
    "result = result[result['InterSupply'] > 0]\n",
    "\n",
    "dfFinal = dfFinal.drop(columns=['InterSupply'])\n",
    "\n",
    "dfFinal = pd.merge(dfFinal, result, how=\"left\", on=[\"DATA\",\"DESC_ARTIGO\", \"STORE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historico(\"InterSupplyMed\", \"InterSupply\", pd.Series.mean)\n",
    "\n",
    "dfFinal[\"InterSupplyMed_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['InterSupply'].transform(lambda x: x.rolling(window=30, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"InterSupplyMed_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['InterSupply'].transform(lambda x: x.rolling(window=60, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"InterSupplyMed_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['InterSupply'].transform(lambda x: x.rolling(window=120, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"InterSupplyMed_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['InterSupply'].transform(lambda x: x.rolling(window=180, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Tempo indisponível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''O que vai acontecer é: no primeiro dia em que há rotura vai aparecer a soma de todos os dias com rotura a seguir a esse!\n",
    "Todos os outros valores serão NaN para não serem considerados quando for feita a média. Assim a média corresponderá ao\n",
    "número médio de dias em que se deixa um produto em rotura.'''\n",
    "\n",
    "dfFinal[\"Tempo_Indisponível\"] = np.where(dfFinal[\"ROTURA\"]==1, 1, 0)\n",
    "\n",
    "groups = (dfFinal['Tempo_Indisponível'] != dfFinal['Tempo_Indisponível'].shift()).cumsum()\n",
    "result = dfFinal.groupby(groups).agg({'DATA': 'first', 'DESC_ARTIGO': 'first', 'STORE': 'first', 'Tempo_Indisponível': 'sum'}).reset_index(drop=True)\n",
    "result = result[result['Tempo_Indisponível'] > 0]\n",
    "\n",
    "dfFinal = dfFinal.drop(columns=['Tempo_Indisponível'])\n",
    "\n",
    "dfFinal = pd.merge(dfFinal, result, how=\"left\", on=[\"DATA\",\"DESC_ARTIGO\", \"STORE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historico(\"Percentagem_Supply\", \"New_Supply\", pd.Series.mean)\n",
    "\n",
    "dfFinal[\"Tempo_Indisponível_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Tempo_Indisponível'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).mean()))\n",
    "\n",
    "dfFinal[\"Tempo_Indisponível_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Tempo_Indisponível'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).mean()))\n",
    "\n",
    "dfFinal[\"Tempo_Indisponível_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Tempo_Indisponível'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).mean()))\n",
    "\n",
    "dfFinal[\"Tempo_Indisponível_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Tempo_Indisponível'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Percentagem de dias em Stock Borderline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Stock_Borderline\"] = np.where(dfFinal[\"STOCK\"]<0.2*dfFinal[\"PRES_STOCK\"], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Tempo_Stock_Borderline_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Stock_Borderline'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Tempo_Stock_Borderline_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Stock_Borderline'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Tempo_Stock_Borderline_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Stock_Borderline'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Tempo_Stock_Borderline_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Stock_Borderline'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Percentagem de dias de Linear Incompleto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Linear_Incompleto\"] = np.where(dfFinal[\"STOCK\"]<dfFinal[\"PRES_STOCK\"], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Tempo_Linear_Incompleto_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Linear_Incompleto'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Tempo_Linear_Incompleto_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Linear_Incompleto'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Tempo_Linear_Incompleto_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Linear_Incompleto'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Tempo_Linear_Incompleto_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Linear_Incompleto'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Percentagem de dias sem vendas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Sem_Vendas\"] = np.where(dfFinal[\"SELLOUT\"] == 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historico(\"Sem_Vendas\", \"Sem_Vendas\", pd.Series.mean)\n",
    "\n",
    "dfFinal[\"Sem_Vendas_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Sem_Vendas'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Sem_Vendas_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Sem_Vendas'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Sem_Vendas_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Sem_Vendas'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Sem_Vendas_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Sem_Vendas'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Vendas perdidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal['ROTURA_fds'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([4,5,6])][\"ROTURA\"].copy()\n",
    "dfFinal['ROTURA_semana'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([0,1,2,3])][\"ROTURA\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Mediana de fins de semana e mediana de semana a multiplicar pelo nº de dias em que há rotura, soma dos valores para\n",
    "ter as perdas de vendas estimadas'''\n",
    "\n",
    "#mediana fds*roturas fds + mediana semana*roturas semana\n",
    "\n",
    "dfFinal[\"Vendas_Perdidas_30\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_fds'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).median())) + \n",
    "                                (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_semana'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).median()))\n",
    ")\n",
    "dfFinal[\"Vendas_Perdidas_60\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_fds'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).median())) + \n",
    "                                (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_semana'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).median()))\n",
    ")\n",
    "dfFinal[\"Vendas_Perdidas_120\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_fds'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).median())) + \n",
    "                                 (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_semana'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).median()))\n",
    ")\n",
    "dfFinal[\"Vendas_Perdidas_180\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_fds'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).median())) + \n",
    "                                 (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_semana'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).median()))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas 4, 5 e 10 antes:\n",
    "\n",
    "- INSTRANSIT\n",
    "- EXPECTED\n",
    "- SELLOUT\n",
    "- CICLOS\n",
    "- Dias para Rotura\n",
    "- Adequação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantos dias antes:\n",
    "\n",
    "diasMet = [4, 5, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para colunas de dias anteriores\n",
    "def dias(df, dia, coluna):         #dia é quantos dias antes\n",
    "    a=int(dia)\n",
    "\n",
    "    valores = df.groupby(['DESC_ARTIGO', 'STORE'])[coluna].transform(lambda x: x.shift(a))\n",
    "    valores[:a] = np.nan\n",
    "    \n",
    "    df.loc[:,'%s_%s_Dias_Antes' % (coluna, a)] = valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - SELLOUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 125 ms\n",
      "Wall time: 128 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Usar função para sellouts até 10 dias antes\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"SELLOUT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - STOCKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar função para Stocks até 10 dias antes\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"STOCK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> > - Ordenar"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "previsões = 2\n",
    "dfOrg = dfFinal.iloc[:, np.r_[:9, 10, 12, 13, 12+previsões, 13+previsões, 9, \n",
    "                                (23+previsões):(32+previsões), 11, (14+previsões):(23+previsões)]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "df_columns = dfOrg.columns.tolist()\n",
    "indexed_columns = [f\"{index}: {column}\" for index, column in enumerate(df_columns)]\n",
    "indexed_columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dfFinal = dfFinal.iloc[:, np.r_[:9, 10, 12, 13, 12+previsões, 13+previsões, 9, \n",
    "                                (23+previsões):(32+previsões), 11, (14+previsões):(23+previsões)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - INTRANSIT e EXPECTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar função para Trânsito até 10 dias antes\n",
    "\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"INTRANSIT\")\n",
    "    \n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"EXPECTED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - STK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STK do dia = soma dos stocks em loja com os stocks em trânsito no próprio dia\n",
    "\n",
    "dfFinal[\"STK\"] = dfFinal[\"STOCK\"] + dfFinal[\"INTRANSIT\"] + dfFinal[\"EXPECTED\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"STK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - MSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSA do dia = média dos sellouts dos 10 dias anteriores ao dia em causa\n",
    "\n",
    "dfFinal[\"MSA10\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10).mean())\n",
    "dfFinal[\"MSA10Dp\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10).std())\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"MSA10\")\n",
    "\n",
    "    \n",
    "dfFinal[\"MSA20\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=20).mean())\n",
    "dfFinal[\"MSA20Dp\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=20).std())\n",
    "  \n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"MSA20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - CICLOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coluna de Ciclos de reposição\n",
    "\n",
    "dfFinal[\"CICLOS\"] = dfFinal[\"STOCK\"]/dfFinal[\"PRES_STOCK\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"CICLOS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Dias para rotura de Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal = dfFinal.copy()\n",
    "# Dias para a rotura mas com o Sellout médio (móvel) dos últimos 10 dias \n",
    "dfFinal[\"Dias_para_Rotura_Stock\"] = dfFinal[\"STOCK\"] / dfFinal[\"MSA10\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"Dias_para_Rotura_Stock\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Dias para rotura de Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a métrica: Preslinear / med(Sellouts 10 dias)\n",
    "dfFinal['Dias_Duração_Linear'] = dfFinal[\"PRES_STOCK\"] / dfFinal[\"MSA10\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"Dias_Duração_Linear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Adequação de Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coluna de adequação de stock\n",
    "\n",
    "\n",
    "dfFinal[\"Adequação\"]= np.where(dfFinal[\"CICLOS\"] > 1.1, \"Stock Suficiente\", \n",
    "                      np.where((dfFinal[\"CICLOS\"] <= 1.1) & (dfFinal[\"INTRANSIT\"]+dfFinal[\"EXPECTED\"]+dfFinal[\"STOCK\"]>=dfFinal[\"PRES_STOCK\"]), \"Stock Insuf c Forn Adequado\", \n",
    "                      np.where((dfFinal[\"CICLOS\"] <= 1.1) & (dfFinal[\"INTRANSIT\"]+dfFinal[\"EXPECTED\"]+dfFinal[\"STOCK\"]<dfFinal[\"PRES_STOCK\"]), \"Stock Insuf c Forn Desadequado\", \n",
    "                      \"\")))\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"Adequação\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- Balance: sellout / soma stock disponível mais transito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas de balanço\n",
    "\n",
    "\n",
    "# Balance do dia = razão entre o sellout médio e o stock para o dia actual\n",
    "dfFinal[\"Balance\"] =  dfFinal[\"MSA10\"] / dfFinal[\"STK\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    \n",
    "    \n",
    "    valores = (i+1) * dfFinal[\"Balance\"].shift(i)\n",
    "    valores[:i] = np.nan\n",
    "    \n",
    "    dfFinal.loc[:,'%s_%s_Dias_Antes' % (\"Balance\", i)] = valores\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- Balance optimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "dfFinal[\"Balance_Optimized\"] = np.where((dfFinal[\"MSA10Dp\"] / dfFinal[\"MSA10\"]) * 100 > 100, dfFinal[\"MSA20\"] / dfFinal[\"STK\"],\n",
    "                                dfFinal[\"MSA10\"] / dfFinal[\"STK\"])   \n",
    "\n",
    "for i in diasMet:\n",
    "    \n",
    "    \n",
    "    valores = (i+1) * dfFinal[\"Balance_Optimized\"].shift(i)\n",
    "    valores[:i] = np.nan\n",
    "    \n",
    "    dfFinal.loc[:,'%s_%s_Dias_Antes' % (\"Balance_Optimized\", i)] = valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Mediano é com o mínimo dos ultimos 10 dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coluna de adequação de stock\n",
    "\n",
    "\n",
    "# MSA_med do dia = mediana dos sellouts dos 10 dias anteriores (exclui o próprio dia)\n",
    "# dfFinal[\"MdSA\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10).median())\n",
    "\n",
    "\n",
    "# Balance do dia = razão entre o sellout médio e o stock para o dia actual\n",
    "dfFinal[\"Balance_Mediano\"] =  dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10).median()) / dfFinal[\"STK\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    \n",
    "    \n",
    "    valores = (i+1) * dfFinal[\"Balance_Mediano\"].shift(i)\n",
    "    valores[:i] = np.nan\n",
    "    \n",
    "    dfFinal.loc[:,'%s_%s_Dias_Antes' % (\"Balance_Mediano\", i)] = valores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Liberal é com o mínimo dos ultimos 10 dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liberal\n",
    "\n",
    "\n",
    "# MSA do dia = média dos stocks dos 10 dias anteriores (exclui o próprio dia)\n",
    "#dfFinal[\"LSA\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10).min())\n",
    "\n",
    "\n",
    "# Balance do dia = razão entre o sellout médio e o stock para o dia actual\n",
    "dfFinal[\"Balance_Liberal\"] =  dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10).min()) / dfFinal[\"STK\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    \n",
    "    \n",
    "    valores = (i+1) * dfFinal[\"Balance_Liberal\"].shift(i)\n",
    "    valores[:i] = np.nan\n",
    "    \n",
    "    dfFinal.loc[:,'%s_%s_Dias_Antes' % (\"Balance_Liberal\", i)] = valores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Conservador é com o máximo dos ultimos 10 dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conservador\n",
    "\n",
    "# MSA_max do dia = máximo dos stocks dos 10 dias anteriores (exclui o próprio dia)\n",
    "#dfFinal[\"CSA\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10).max())\n",
    " \n",
    "    \n",
    "# Balance do dia = razão entre o sellout médio e o stock para o dia actual\n",
    "dfFinal[\"Balance_Conservador\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10).max()) / dfFinal[\"STK\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    \n",
    "    # Multiplicar os balances pelo número de dias+1 antes do dia actual\n",
    "    valores = (i+1) * dfFinal[\"Balance_Conservador\"].shift(i)\n",
    "    valores[:i] = np.nan\n",
    "    \n",
    "    dfFinal.loc[:,'%s_%s_Dias_Antes' % (\"Balance_Conservador\", i)] = valores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Smart é com semana e fim de semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 25.5 s\n",
      "Wall time: 25.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# Define a function to calculate weekday and weekend counts\n",
    "def calculate_weekday_weekend_counts(date):\n",
    "    weekday_count = 0\n",
    "    weekend_count = 0\n",
    "    \n",
    "    for _ in range(5):\n",
    "        if date.weekday() < 4:  # Monday to Thursday\n",
    "            weekday_count += 1\n",
    "        else:  # Friday to Sunday\n",
    "            weekend_count += 1\n",
    "        \n",
    "        date += timedelta(days=1)\n",
    "    \n",
    "    return pd.Series({\"CONTAGEM_SEMANA\": weekday_count, \"CONTAGEM_FIMSEMANA\": weekend_count})\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "dfFinal[[\"CONTAGEM_SEMANA\", \"CONTAGEM_FIMSEMANA\"]] = dfFinal[\"DATA\"].apply(calculate_weekday_weekend_counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smart\n",
    "\n",
    "\n",
    "\n",
    "dfFinal[\"Balance_Smart_5_Dias_Antes\"] = ((\n",
    "    (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].transform(lambda x: x.rolling(window=30, min_periods=1).median())\n",
    "     * dfFinal['CONTAGEM_FIMSEMANA'])\n",
    "    +\n",
    "    (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].transform(lambda x: x.rolling(window=30, min_periods=1).median())\n",
    "     * dfFinal['CONTAGEM_SEMANA']))\n",
    "     / dfFinal[\"STK\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfVendedor=pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Vendedor2.xlsx\", sheet_name = \"Lojas Sonae para o desafio\")\n",
    "dfVendedor = dfVendedor.rename(columns={\"Cód. Loja\":\"STORE\"})\n",
    "\n",
    "# Criar coluna de reposição\n",
    "dfFinal = pd.merge(dfFinal, dfVendedor[[\"STORE\",\"Vendedor\"]], how=\"left\", on = \"STORE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escrever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0's e 1's"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Novo dataframe que apenas inclui dias em que existe a 1ª rotura e o dia anterior a essa rotura\n",
    "\n",
    "# Tirar 1's depois do primeiro\n",
    "dfFinalLimitado = dfFinal[~((dfFinal[\"ROTURA\"] == 1) & (dfFinal[\"ROTURA\"].shift(1) == 1))].copy()\n",
    "\n",
    "# Apenas incluir primeira rotura\n",
    "dfFinalLimitadoRoturas = dfFinal[((dfFinal[\"ROTURA\"] == 1) & (dfFinal[\"ROTURA\"].shift(1) == 0))].copy() #| ((dfFinal[\"ROTURA\"] == 0) & (dfFinal[\"ROTURA\"].shift(-1) == 1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dias certos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEscrever2022 = dfFinal.copy()\n",
    "dfEscrever2023 = dfFinal.loc[(dfFinal['DATA'] >= '2023-01-01') ].copy()\n",
    "\n",
    "#df_DiasCertos = dfFinalLimitado.loc[(dfFinalLimitado['DATA'] >= '2023-01-01') ].copy()\n",
    "#df_RoturasDiasCertos = dfFinalLimitadoRoturas.loc[(dfFinalLimitadoRoturas['DATA'] >= '2023-01-01') ].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Passar para csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CNT MATOSINHOS', 'CNT AMADORA', 'CNT CASCAIS', 'CNT LEIRIA',\n",
       "       'CNT COIMBRASHOPPING', 'CNT PORTIMÃO', 'CNT VIANA', 'CNT SANTAREM',\n",
       "       'MDL T. VEDRAS', 'CNT BRAGA'], dtype=object)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFinal.STORE_NAME.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.3 s\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "escrever_csv(dfEscrever2022, \"FinalDataBaseDeltaTotal\")\n",
    "escrever_csv(dfEscrever2023, \"FinalDataBaseDeltaTotal2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNinjas2 = pd.read_csv(\"D:\\\\B&N Dados\\\\Delta\\\\Stocks\\\\StocksTotal\\\\CHMetNaoSmart2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24290, 129)\n",
      "(24290, 130)\n"
     ]
    }
   ],
   "source": [
    "print(dfNinjas2.shape)\n",
    "print(dfNinjas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DATA',\n",
       " 'EAN',\n",
       " 'DESC_ARTIGO',\n",
       " 'STORE',\n",
       " 'STORE_NAME',\n",
       " 'INTRANSIT',\n",
       " 'EXPECTED',\n",
       " 'PRES_STOCK',\n",
       " 'STOCK',\n",
       " 'STOCK_1_Dias_Antes',\n",
       " 'SELLOUT',\n",
       " 'SELLOUT_1_Dias_Antes',\n",
       " 'Prophet',\n",
       " 'XGBoost',\n",
       " 'ROTURA',\n",
       " 'PRE_ROTURA',\n",
       " 'Volatilidade_30',\n",
       " 'Volatilidade_60',\n",
       " 'Volatilidade_120',\n",
       " 'Volatilidade_180',\n",
       " 'Percentagem_Roturas_30',\n",
       " 'Percentagem_Roturas_60',\n",
       " 'Percentagem_Roturas_120',\n",
       " 'Percentagem_Roturas_180',\n",
       " 'New_Supply',\n",
       " 'Percentagem_Supply_30',\n",
       " 'Percentagem_Supply_60',\n",
       " 'Percentagem_Supply_120',\n",
       " 'Percentagem_Supply_180',\n",
       " 'SELLOUT_fds',\n",
       " 'SELLOUT_semana',\n",
       " 'Efeito_Fds_30',\n",
       " 'Efeito_Fds_60',\n",
       " 'Efeito_Fds_120',\n",
       " 'Efeito_Fds_180',\n",
       " 'InterSupply',\n",
       " 'InterSupplyMed_30',\n",
       " 'InterSupplyMed_60',\n",
       " 'InterSupplyMed_120',\n",
       " 'InterSupplyMed_180',\n",
       " 'Tempo_Indisponível',\n",
       " 'Tempo_Indisponível_30',\n",
       " 'Tempo_Indisponível_60',\n",
       " 'Tempo_Indisponível_120',\n",
       " 'Tempo_Indisponível_180',\n",
       " 'Stock_Borderline',\n",
       " 'Tempo_Stock_Borderline_30',\n",
       " 'Tempo_Stock_Borderline_60',\n",
       " 'Tempo_Stock_Borderline_120',\n",
       " 'Tempo_Stock_Borderline_180',\n",
       " 'Linear_Incompleto',\n",
       " 'Tempo_Linear_Incompleto_30',\n",
       " 'Tempo_Linear_Incompleto_60',\n",
       " 'Tempo_Linear_Incompleto_120',\n",
       " 'Tempo_Linear_Incompleto_180',\n",
       " 'Sem_Vendas',\n",
       " 'Sem_Vendas_30',\n",
       " 'Sem_Vendas_60',\n",
       " 'Sem_Vendas_120',\n",
       " 'Sem_Vendas_180',\n",
       " 'ROTURA_fds',\n",
       " 'ROTURA_semana',\n",
       " 'Vendas_Perdidas_30',\n",
       " 'Vendas_Perdidas_60',\n",
       " 'Vendas_Perdidas_120',\n",
       " 'Vendas_Perdidas_180',\n",
       " 'SELLOUT_4_Dias_Antes',\n",
       " 'SELLOUT_5_Dias_Antes',\n",
       " 'SELLOUT_10_Dias_Antes',\n",
       " 'STOCK_4_Dias_Antes',\n",
       " 'STOCK_5_Dias_Antes',\n",
       " 'STOCK_10_Dias_Antes',\n",
       " 'INTRANSIT_4_Dias_Antes',\n",
       " 'INTRANSIT_5_Dias_Antes',\n",
       " 'INTRANSIT_10_Dias_Antes',\n",
       " 'EXPECTED_4_Dias_Antes',\n",
       " 'EXPECTED_5_Dias_Antes',\n",
       " 'EXPECTED_10_Dias_Antes',\n",
       " 'STK',\n",
       " 'STK_4_Dias_Antes',\n",
       " 'STK_5_Dias_Antes',\n",
       " 'STK_10_Dias_Antes',\n",
       " 'MSA10',\n",
       " 'MSA10Dp',\n",
       " 'MSA10_4_Dias_Antes',\n",
       " 'MSA10_5_Dias_Antes',\n",
       " 'MSA10_10_Dias_Antes',\n",
       " 'MSA20',\n",
       " 'MSA20Dp',\n",
       " 'MSA20_4_Dias_Antes',\n",
       " 'MSA20_5_Dias_Antes',\n",
       " 'MSA20_10_Dias_Antes',\n",
       " 'CICLOS',\n",
       " 'CICLOS_4_Dias_Antes',\n",
       " 'CICLOS_5_Dias_Antes',\n",
       " 'CICLOS_10_Dias_Antes',\n",
       " 'Dias_para_Rotura_Stock',\n",
       " 'Dias_para_Rotura_Stock_4_Dias_Antes',\n",
       " 'Dias_para_Rotura_Stock_5_Dias_Antes',\n",
       " 'Dias_para_Rotura_Stock_10_Dias_Antes',\n",
       " 'Dias_Duração_Linear',\n",
       " 'Dias_Duração_Linear_4_Dias_Antes',\n",
       " 'Dias_Duração_Linear_5_Dias_Antes',\n",
       " 'Dias_Duração_Linear_10_Dias_Antes',\n",
       " 'Adequação',\n",
       " 'Adequação_4_Dias_Antes',\n",
       " 'Adequação_5_Dias_Antes',\n",
       " 'Adequação_10_Dias_Antes',\n",
       " 'Balance',\n",
       " 'Balance_4_Dias_Antes',\n",
       " 'Balance_5_Dias_Antes',\n",
       " 'Balance_10_Dias_Antes',\n",
       " 'Balance_Optimized',\n",
       " 'Balance_Optimized_4_Dias_Antes',\n",
       " 'Balance_Optimized_5_Dias_Antes',\n",
       " 'Balance_Optimized_10_Dias_Antes',\n",
       " 'Balance_Mediano',\n",
       " 'Balance_Mediano_4_Dias_Antes',\n",
       " 'Balance_Mediano_5_Dias_Antes',\n",
       " 'Balance_Mediano_10_Dias_Antes',\n",
       " 'Balance_Liberal',\n",
       " 'Balance_Liberal_4_Dias_Antes',\n",
       " 'Balance_Liberal_5_Dias_Antes',\n",
       " 'Balance_Liberal_10_Dias_Antes',\n",
       " 'Balance_Conservador',\n",
       " 'Balance_Conservador_4_Dias_Antes',\n",
       " 'Balance_Conservador_5_Dias_Antes',\n",
       " 'Balance_Conservador_10_Dias_Antes',\n",
       " 'Vendedor']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNinjas2.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Worksheet named 'Lista Lojas Sonae' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ler ficheiro\u001b[39;00m\n\u001b[0;32m      2\u001b[0m dfNinjas \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mB&N Dados\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDelta\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mStocks\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mStocksTotal\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCHMetNaoSmart.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m dfVendedor\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mB&N Dados\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mDelta\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mVendedor2.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLista Lojas Sonae\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m dfVendedor \u001b[38;5;241m=\u001b[39m dfVendedor\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCód. Loja\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTORE\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Criar coluna de reposição\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\io\\excel\\_base.py:490\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    485\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m     )\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 490\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmangle_dupe_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmangle_dupe_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_close:\n",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1734\u001b[0m, in \u001b[0;36mExcelFile.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m   1700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\n\u001b[0;32m   1701\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1702\u001b[0m     sheet_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1721\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[0;32m   1722\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, DataFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, DataFrame]:\n\u001b[0;32m   1723\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1724\u001b[0m \u001b[38;5;124;03m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1725\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;124;03m        DataFrame from the passed in Excel file.\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mparse(\n\u001b[0;32m   1735\u001b[0m         sheet_name\u001b[38;5;241m=\u001b[39msheet_name,\n\u001b[0;32m   1736\u001b[0m         header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   1737\u001b[0m         names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m   1738\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   1739\u001b[0m         usecols\u001b[38;5;241m=\u001b[39musecols,\n\u001b[0;32m   1740\u001b[0m         squeeze\u001b[38;5;241m=\u001b[39msqueeze,\n\u001b[0;32m   1741\u001b[0m         converters\u001b[38;5;241m=\u001b[39mconverters,\n\u001b[0;32m   1742\u001b[0m         true_values\u001b[38;5;241m=\u001b[39mtrue_values,\n\u001b[0;32m   1743\u001b[0m         false_values\u001b[38;5;241m=\u001b[39mfalse_values,\n\u001b[0;32m   1744\u001b[0m         skiprows\u001b[38;5;241m=\u001b[39mskiprows,\n\u001b[0;32m   1745\u001b[0m         nrows\u001b[38;5;241m=\u001b[39mnrows,\n\u001b[0;32m   1746\u001b[0m         na_values\u001b[38;5;241m=\u001b[39mna_values,\n\u001b[0;32m   1747\u001b[0m         parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[0;32m   1748\u001b[0m         date_parser\u001b[38;5;241m=\u001b[39mdate_parser,\n\u001b[0;32m   1749\u001b[0m         thousands\u001b[38;5;241m=\u001b[39mthousands,\n\u001b[0;32m   1750\u001b[0m         comment\u001b[38;5;241m=\u001b[39mcomment,\n\u001b[0;32m   1751\u001b[0m         skipfooter\u001b[38;5;241m=\u001b[39mskipfooter,\n\u001b[0;32m   1752\u001b[0m         convert_float\u001b[38;5;241m=\u001b[39mconvert_float,\n\u001b[0;32m   1753\u001b[0m         mangle_dupe_cols\u001b[38;5;241m=\u001b[39mmangle_dupe_cols,\n\u001b[0;32m   1754\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[0;32m   1755\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\io\\excel\\_base.py:760\u001b[0m, in \u001b[0;36mBaseExcelReader.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, squeeze, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReading sheet \u001b[39m\u001b[38;5;132;01m{\u001b[39;00masheetname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(asheetname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 760\u001b[0m     sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sheet_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43masheetname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# assume an integer if not a string\u001b[39;00m\n\u001b[0;32m    762\u001b[0m     sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sheet_by_index(asheetname)\n",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:577\u001b[0m, in \u001b[0;36mOpenpyxlReader.get_sheet_by_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_sheet_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 577\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_if_bad_sheet_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbook[name]\n",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\io\\excel\\_base.py:602\u001b[0m, in \u001b[0;36mBaseExcelReader.raise_if_bad_sheet_by_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_if_bad_sheet_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msheet_names:\n\u001b[1;32m--> 602\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWorksheet named \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Worksheet named 'Lista Lojas Sonae' not found"
     ]
    }
   ],
   "source": [
    "# Ler ficheiro\n",
    "dfNinjas = pd.read_csv(\"D:\\\\B&N Dados\\\\Delta\\\\Stocks\\\\StocksTotal\\\\CHMetNaoSmart.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfVendedor=pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Vendedor2.xlsx\", sheet_name = \"Lojas Sonae para o desafio\")\n",
    "dfVendedor = dfVendedor.rename(columns={\"Cód. Loja\":\"STORE\"})\n",
    "\n",
    "# Criar coluna de reposição\n",
    "dfNinjas = pd.merge(dfNinjas, dfVendedor[[\"STORE\",\"Vendedor\"]], how=\"left\", on = \"STORE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "escrever_csv(dfFinal2, \"Mil_MétricasCerto07\")\n",
    "#escrever_csv(df_DiasCertos, \"StocksDelta_2023_10prod_Limpo\")\n",
    "#escrever_csv(df_RoturasDiasCertos, \"StocksDelta_2023_10prod_Roturas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escrever_excel(dataFrame, nomeFicheiro):\n",
    "    dataFrame.to_excel('D:\\\\B&N Dados\\\\Delta\\\\Piloto\\\\%s.xlsx' %nomeFicheiro, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "escrever_excel(oi, \"ParaTestarCoisas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m oiEscrever \u001b[38;5;241m=\u001b[39m oi[(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-04-14\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39moi[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATA\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-04-16\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-04-21\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39moi[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATA\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-04-23\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-04-28\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39moi[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATA\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-04-30\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-05-05\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39moi[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATA\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-05-07\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\core\\generic.py:1527\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__nonzero__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1528\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe truth value of a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is ambiguous. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1529\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1530\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "oiEscrever = oi[(\"2023-04-14\"<=oi[\"DATA\"]<=\"2023-04-16\") or (\"2023-04-21\"<=oi[\"DATA\"]<=\"2023-04-23\") or (\"2023-04-28\"<=oi[\"DATA\"]<=\"2023-04-30\") or (\"2023-05-05\"<=oi[\"DATA\"]<=\"2023-05-07\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_oi = oi[oi[\"DATA\"].between(\"2023-04-14\", \"2023-04-16\") |\n",
    "                  oi[\"DATA\"].between(\"2023-04-21\", \"2023-04-23\") |\n",
    "                  oi[\"DATA\"].between(\"2023-04-28\", \"2023-04-30\") |\n",
    "                  oi[\"DATA\"].between(\"2023-05-05\", \"2023-05-07\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Vendedor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Vendedor'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdfNinjas\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVendedor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3_recent\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Vendedor'"
     ]
    }
   ],
   "source": [
    "dfNinjas[\"Vendedor\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clickhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clickhouse_connect\n",
    "from clickhouse_driver import Client\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estabelecer a base a ser lida\n",
    "\n",
    "baseCH = dfEscrever2023.copy()\n",
    "#2023\n",
    "tabela = \"FinalDataBaseDelta2023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<clickhouse_connect.driver.summary.QuerySummary at 0x1b581267520>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "client = clickhouse_connect.get_client(host='e28fluocjc.europe-west4.gcp.clickhouse.cloud', \n",
    "                                       port=8443, \n",
    "                                       username='default', \n",
    "                                       password='eKn4CWkTDFpi_',\n",
    "                                       database='Delta')\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "baseCH['DATA']= pd.to_datetime(baseCH['DATA'], format='%Y-%m-%d')  # Passar para datetime\n",
    "new_columns = [unidecode(col) for col in baseCH.columns]           # Tirar acentos e afins\n",
    "baseCH.columns = new_columns                                       # Aplicar alterações da linha anterior\n",
    "###\n",
    "\n",
    "# Tipos de dados\n",
    "data = [\"DATA\"]\n",
    "texto = [col for col in baseCH.columns if baseCH[col].dtype == 'object']\n",
    "inteiros = [col for col in baseCH.columns if baseCH[col].dtype == 'int64' or baseCH[col].dtype == 'int32']\n",
    "floats = [col for col in baseCH.columns if baseCH[col].dtype == 'float64']\n",
    "\n",
    "\n",
    "# Só floats é que permitem missing values\n",
    "for col_name in inteiros:\n",
    "    baseCH[col_name] = baseCH[col_name].astype(float)\n",
    "# Missing values em strings estragam tudo\n",
    "baseCH[texto] = baseCH[texto].fillna(\"-\")\n",
    "\n",
    "\n",
    "def schema(lista, tipo):\n",
    "    result_list = [f\"{element} {tipo}\" for element in lista]\n",
    "    return result_list\n",
    "\n",
    "data1 = schema(data, \"Date\")\n",
    "texto1 = schema(texto, \"String\")\n",
    "inteiros1 = schema(inteiros, \"Float64\")\n",
    "floats1 = schema(floats, \"Float64\")\n",
    "total = tuple(data1 + texto1 + inteiros1 + floats1)\n",
    "\n",
    "schema = ', '.join([column.replace(\"'\", \"\") for column in total])\n",
    "\n",
    "# Split the input string by commas\n",
    "parts = schema.split(', ')\n",
    "# Process each part and wrap the first word in double quotes\n",
    "output_parts = []\n",
    "for part in parts:\n",
    "    words = part.split()\n",
    "    if words:\n",
    "        first_word = words[0]\n",
    "        remaining_words = ' '.join(words[1:])\n",
    "        output_part = f'\"{first_word}\" {remaining_words}'\n",
    "        output_parts.append(output_part)\n",
    "# Join the modified parts back into a string\n",
    "schema = ', '.join(output_parts)\n",
    "\n",
    "\n",
    "\n",
    "# Eliminar tabela no CH\n",
    "client.command(f'DROP TABLE IF EXISTS {tabela}')\n",
    "\n",
    "# Criar tabela no CH\n",
    "client.command(f'''\n",
    "    CREATE TABLE IF NOT EXISTS {tabela} (\n",
    "        {schema}\n",
    "        ) ENGINE = MergeTree\n",
    "        ORDER BY (DATA)\n",
    "''')\n",
    "\n",
    "client.insert_df(tabela, baseCH, column_names=baseCH.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
