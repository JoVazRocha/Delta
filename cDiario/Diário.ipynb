{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumo do código\n",
    "\n",
    "### <u>Código que gera os ficheiros para estudo do comportamento da Delta</u>\n",
    "---\n",
    "O objectivo é receber dados da Delta e devolver um conjunto de métricas para prever roturas. Devolve um ficheiro que pode entrar no código 1 para juntar aos dados dos ninjas.\n",
    "\n",
    "---\n",
    "- Inputs\n",
    "\n",
    "> __Dados completos da Delta em pastas de ficheiros__ (de azul a verde)\n",
    "> - Stocks e trânsito, Sellout do dia anterior\n",
    "\n",
    "                    ou\n",
    "\n",
    "> __Ficheiro já completo__ (de vermelho a verde)\n",
    "> - Stocks e trânsito, Sellout do dia anterior\n",
    "\n",
    "- Outputs\n",
    "\n",
    "> __Ficheiro com produtos em causa__ em formato Long\n",
    "\n",
    "> __Métricas novas:__\n",
    "> - Roturas de Stock e Pré-rotura\n",
    "> - Sinal\n",
    "> - Ciclos e Adequação de Stock\n",
    "> - MSA (média de sellouts 10 dias antes)\n",
    "> - STK (Stock disponível + trânsito)\n",
    "> - (Novo) Balanço médio, mediano, liberal e conservador \n",
    "> - (Novo) Dias para a rotura de stock e de prateleira\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 516 ms\n",
      "Wall time: 555 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import clickhouse_connect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:Blue\">Juntar Ficheiros</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importar do Clickhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = clickhouse_connect.get_client(host='e28fluocjc.europe-west4.gcp.clickhouse.cloud', \n",
    "                                       port=8443, \n",
    "                                       username='default', \n",
    "                                       password='eKn4CWkTDFpi_',\n",
    "                                       database='Delta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ler o ficheiro\n",
    "\n",
    "dfClick = client.query_df('SELECT * FROM FinalDataBaseDelta2023')\n",
    "\n",
    "dfClick = dfClick[dfClick.DATA != dfClick.DATA.unique()[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importar ficheiros novos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNovo = pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Diário\\\\dia_actual.xlsb\") #xlsx\n",
    "\n",
    "\n",
    "dfNovo = dfNovo[['DATA', 'EAN', 'DESC_ARTIGO', 'STORE', \"STORE_NAME\", \n",
    "                         \"SOH\", \"INTRANSIT\", \"EXPECTED\", \"PRES_STOCK\", \"VND (D-1)\"]]\n",
    "\n",
    "# se xlsx\n",
    "#dfNovo['DATA'] = pd.to_datetime(dfNovo['DATA'], format='%d-%m-%Y') \n",
    "\n",
    "# se xlsb\n",
    "dfNovo['DATA'] = pd.to_datetime(dfNovo['DATA'], unit='d', origin=datetime.datetime(1899, 12, 30)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Produtos específicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 433 ms\n"
     ]
    }
   ],
   "source": [
    "# Passar produtos e lojas para listas\n",
    "\n",
    "produtos = dfClick.DESC_ARTIGO.unique().tolist()\n",
    "lojas = dfClick.STORE.unique().tolist()\n",
    "\n",
    "# Alterar o dataframe para apenas incluir os produtos e lojas em causa\n",
    "\n",
    "dfNovo = dfNovo[(dfNovo[\"DESC_ARTIGO\"].isin(produtos)) & (dfNovo[\"STORE\"].isin(lojas))].copy()\n",
    "\n",
    "# Renomear colunas e criar as do dia\n",
    "\n",
    "dfNovo = dfNovo.rename(columns={\"VND (D-1)\": \"SELLOUT_1_Dias_Antes\", \"SOH\": \"STOCK_1_Dias_Antes\"})\n",
    "dfNovo['SELLOUT'] = dfNovo.groupby([\"STORE\",\"EAN\"])['SELLOUT_1_Dias_Antes'].shift(-1)\n",
    "dfNovo['STOCK'] = dfNovo.groupby([\"STORE\",\"EAN\"])['STOCK_1_Dias_Antes'].shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Juntar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDiario = pd.concat([\"dfClick\", \"dfNovo\"], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=green>Ficheiro Lido<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colunas de métricas interessantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - ROTURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir coluna de rotura (se stock menor ou igual a 0 e existe Linear)\n",
    "\n",
    "dfFinal[\"ROTURA\"] = np.where((dfFinal[\"STOCK\"] <= 0) & (dfFinal[\"PRES_STOCK\"] > 0), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - PRÉ_ROTURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir coluna de rotura (se stock menor ou igual a 0)\n",
    "\n",
    "dfFinal[\"PRE_ROTURA\"] = (dfFinal[\"STOCK\"] < dfFinal[\"PRES_STOCK\"]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colunas de métricas 30, 60, 120 e 180 dias antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "diasMetHist = [30, 60, 120, 180]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Volatilidade de Procura: <br>\n",
    "coeficiente de variação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal=dfClick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Volatilidade_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=i, min_periods=1).std())/\n",
    "                             dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=i, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 62.5 ms\n",
      "Wall time: 59.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfFinal[\"Volatilidade_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).std())/\n",
    "                             dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).mean()))\n",
    "\n",
    "dfFinal[\"Volatilidade_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).std())/\n",
    "                             dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).mean()))\n",
    "\n",
    "dfFinal[\"Volatilidade_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).std())/\n",
    "                              dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).mean()))\n",
    "\n",
    "dfFinal[\"Volatilidade_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).std())/\n",
    "                              dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).mean()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Percentagem de Rotura: <br>\n",
    "média de roturas $* 100$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Roturas_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA'].shift(1).transform(lambda x: x.rolling(window=i, min_periods=1).mean()))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.19 s\n",
      "Wall time: 2.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#historico(\"Percentagem_Roturas\", \"ROTURA\", pd.Series.mean)\n",
    "\n",
    "dfFinal[\"Percentagem_Roturas_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Percentagem_Roturas_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Percentagem_Roturas_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Percentagem_Roturas_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Percentagem de Supply:<br>\n",
    "média de vezes que foi pedido stock $*100$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"New_Supply\"] = np.where((dfFinal[\"EXPECTED\"].shift(1)==0) & (dfFinal[\"EXPECTED\"]>0), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Percentagem_Supply_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['New_Supply'].shift(1).transform(lambda x: x.rolling(window=i, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historico(\"Percentagem_Supply\", \"New_Supply\", pd.Series.mean)\n",
    "\n",
    "dfFinal[\"Percentagem_Supply_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['New_Supply'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).sum())/30)*100\n",
    "\n",
    "dfFinal[\"Percentagem_Supply_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['New_Supply'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).sum())/60)*100\n",
    "\n",
    "dfFinal[\"Percentagem_Supply_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['New_Supply'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).sum())/120)*100\n",
    "\n",
    "dfFinal[\"Percentagem_Supply_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['New_Supply'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).sum())/180)*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Efeito fim de semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal['SELLOUT_fds'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([4,5,6])][\"SELLOUT\"].copy()\n",
    "dfFinal['SELLOUT_semana'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([0,1,2,3])][\"SELLOUT\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Efeito_Fds_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=i, min_periods=1).median())/\n",
    "                            (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=i, min_periods=1).median())))-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Efeito_Fds_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).median())/\n",
    "                            (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).median())))-1\n",
    "\n",
    "dfFinal[\"Efeito_Fds_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).median())/\n",
    "                            (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).median())))-1\n",
    "\n",
    "dfFinal[\"Efeito_Fds_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).median())/\n",
    "                            (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).median())))-1\n",
    "\n",
    "dfFinal[\"Efeito_Fds_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).median())/\n",
    "                            (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).median())))-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Tempo médio inter-supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"InterSupply\"] = np.where(dfFinal[\"EXPECTED\"]==0, 1, 0)\n",
    "\n",
    "groups = (dfFinal['InterSupply'] != dfFinal['InterSupply'].shift()).cumsum()\n",
    "result = dfFinal.groupby(groups).agg({'DATA': 'first', 'DESC_ARTIGO': 'first', 'STORE': 'first', 'InterSupply': 'sum'}).reset_index(drop=True)\n",
    "result = result[result['InterSupply'] > 0]\n",
    "\n",
    "dfFinal = dfFinal.drop(columns=['InterSupply'])\n",
    "\n",
    "dfFinal = pd.merge(dfFinal, result, how=\"left\", on=[\"DATA\",\"DESC_ARTIGO\", \"STORE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in diasMetHist:\n",
    "    dfFinal[f\"InterSupplyMed_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['InterSupply'].transform(lambda x: x.rolling(window=i, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historico(\"InterSupplyMed\", \"InterSupply\", pd.Series.mean)\n",
    "\n",
    "dfFinal[\"InterSupplyMed_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['InterSupply'].transform(lambda x: x.rolling(window=30, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"InterSupplyMed_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['InterSupply'].transform(lambda x: x.rolling(window=60, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"InterSupplyMed_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['InterSupply'].transform(lambda x: x.rolling(window=120, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"InterSupplyMed_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['InterSupply'].transform(lambda x: x.rolling(window=180, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Tempo indisponível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''O que vai acontecer é: no primeiro dia em que há rotura vai aparecer a soma de todos os dias com rotura a seguir a esse!\n",
    "Todos os outros valores serão NaN para não serem considerados quando for feita a média. Assim a média corresponderá ao\n",
    "número médio de dias em que se deixa um produto em rotura.'''\n",
    "\n",
    "dfFinal[\"Tempo_Indisponível\"] = np.where(dfFinal[\"ROTURA\"]==1, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Tempo_Indisponível_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Tempo_Indisponível'].shift(1).transform(lambda x: x.rolling(window=i, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historico(\"Percentagem_Supply\", \"New_Supply\", pd.Series.mean)\n",
    "\n",
    "dfFinal[\"Tempo_Indisponível_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Tempo_Indisponível'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Tempo_Indisponível_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Tempo_Indisponível'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Tempo_Indisponível_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Tempo_Indisponível'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Tempo_Indisponível_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Tempo_Indisponível'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Percentagem de dias em Stock Borderline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Stock_Borderline\"] = np.where(dfFinal[\"STOCK\"]<0.2*dfFinal[\"PRES_STOCK\"], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Tempo_Stock_Borderline_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Stock_Borderline'].shift(1).transform(lambda x: x.rolling(window=i, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Tempo_Stock_Borderline_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Stock_Borderline'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Tempo_Stock_Borderline_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Stock_Borderline'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Tempo_Stock_Borderline_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Stock_Borderline'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Tempo_Stock_Borderline_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Stock_Borderline'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Percentagem de dias de Linear Incompleto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Linear_Incompleto\"] = np.where(dfFinal[\"STOCK\"]<dfFinal[\"PRES_STOCK\"], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Tempo_Linear_Incompleto_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Linear_Incompleto'].shift(1).transform(lambda x: x.rolling(window=i, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Tempo_Linear_Incompleto_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Linear_Incompleto'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Tempo_Linear_Incompleto_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Linear_Incompleto'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Tempo_Linear_Incompleto_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Linear_Incompleto'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Tempo_Linear_Incompleto_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Linear_Incompleto'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Percentagem de dias sem vendas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Sem_Vendas\"] = np.where(dfFinal[\"SELLOUT\"] == 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Sem_Vendas_{i}\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Sem_Vendas'].shift(1).transform(lambda x: x.rolling(window=i, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historico(\"Sem_Vendas\", \"Sem_Vendas\", pd.Series.mean)\n",
    "\n",
    "dfFinal[\"Sem_Vendas_30\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Sem_Vendas'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Sem_Vendas_60\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Sem_Vendas'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Sem_Vendas_120\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Sem_Vendas'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).mean()))*100\n",
    "\n",
    "dfFinal[\"Sem_Vendas_180\"] = (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['Sem_Vendas'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).mean()))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Vendas perdidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal['ROTURA_fds'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([4,5,6])][\"ROTURA\"].copy()\n",
    "dfFinal['ROTURA_semana'] = dfFinal[dfFinal['DATA'].dt.weekday.isin([0,1,2,3])][\"ROTURA\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in diasMetHist:\n",
    "    dfFinal[f\"Vendas_Perdidas_{i}\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_fds'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=i, min_periods=1).median())) + \n",
    "                                       (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_semana'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=i, min_periods=1).median())))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Mediana de fins de semana e mediana de semana a multiplicar pelo nº de dias em que há rotura, soma dos valores para\n",
    "ter as perdas de vendas estimadas'''\n",
    "\n",
    "#mediana fds*roturas fds + mediana semana*roturas semana\n",
    "\n",
    "dfFinal[\"Vendas_Perdidas_30\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_fds'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).median())) + \n",
    "                                (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_semana'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=30, min_periods=1).median()))\n",
    ")\n",
    "dfFinal[\"Vendas_Perdidas_60\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_fds'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).median())) + \n",
    "                                (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_semana'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=60, min_periods=1).median()))\n",
    ")\n",
    "dfFinal[\"Vendas_Perdidas_120\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_fds'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).median())) + \n",
    "                                 (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_semana'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=120, min_periods=1).median()))\n",
    ")\n",
    "dfFinal[\"Vendas_Perdidas_180\"] = ((dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_fds'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).median())) + \n",
    "                                 (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['ROTURA_semana'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).sum()) * dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].shift(1).transform(lambda x: x.rolling(window=180, min_periods=1).median()))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas até 10 dias antes:\n",
    "\n",
    "- INSTRANSIT\n",
    "- EXPECTED\n",
    "- SELLOUT\n",
    "- CICLOS\n",
    "- Dias para Rotura\n",
    "- Adequação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantos dias antes:\n",
    "\n",
    "diaI=4         #dia inicial\n",
    "diaF=5       #dia final\n",
    "\n",
    "diasMet = [4, 5, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para colunas de dias anteriores\n",
    "def dias(df, dia, coluna):         #dia é quantos dias antes\n",
    "    a=int(dia)\n",
    "\n",
    "    valores = df.groupby(['DESC_ARTIGO', 'STORE'])[coluna].transform(lambda x: x.shift(a))\n",
    "    valores[:a] = np.nan\n",
    "    \n",
    "    df.loc[:,'%s_%s_Dias_Antes' % (coluna, a)] = valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - SELLOUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.66 s\n",
      "Wall time: 1.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Usar função para sellouts até 10 dias antes\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"SELLOUT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - STOCKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar função para Stocks até 10 dias antes\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"STOCK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> > - Ordenar"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "previsões = 2\n",
    "dfOrg = dfFinal.iloc[:, np.r_[:9, 10, 12, 13, 12+previsões, 13+previsões, 9, \n",
    "                                (23+previsões):(32+previsões), 11, (14+previsões):(23+previsões)]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "df_columns = dfOrg.columns.tolist()\n",
    "indexed_columns = [f\"{index}: {column}\" for index, column in enumerate(df_columns)]\n",
    "indexed_columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dfFinal = dfFinal.iloc[:, np.r_[:9, 10, 12, 13, 12+previsões, 13+previsões, 9, \n",
    "                                (23+previsões):(32+previsões), 11, (14+previsões):(23+previsões)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - INTRANSIT e EXPECTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar função para Trânsito até 10 dias antes\n",
    "\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"INTRANSIT\")\n",
    "    \n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"EXPECTED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - STK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STK do dia = soma dos stocks em loja com os stocks em trânsito no próprio dia\n",
    "\n",
    "dfFinal[\"STK\"] = dfFinal[\"STOCK\"] + dfFinal[\"INTRANSIT\"] + dfFinal[\"EXPECTED\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"STK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - MSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSA do dia = média dos sellouts dos 10 dias anteriores ao dia em causa\n",
    "\n",
    "dfFinal[\"MSA10\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10, min_periods=1).mean())\n",
    "dfFinal[\"MSA10Dp\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=10, min_periods=1).std())\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"MSA10\")\n",
    "\n",
    "    \n",
    "dfFinal[\"MSA20\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=20, min_periods=1).mean())\n",
    "dfFinal[\"MSA20Dp\"] = dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT'].shift(1).transform(lambda x: x.rolling(window=20, min_periods=1).std())\n",
    "  \n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"MSA20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - CICLOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coluna de Ciclos de reposição\n",
    "\n",
    "dfFinal[\"CICLOS\"] = dfFinal[\"STOCK\"]/dfFinal[\"PRES_STOCK\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"CICLOS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Dias para rotura de Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfFinal = dfFinal.copy()\n",
    "# Dias para a rotura mas com o Sellout médio (móvel) dos últimos 10 dias \n",
    "dfFinal[\"Dias_para_Rotura_Stock\"] = dfFinal[\"STOCK\"] / dfFinal[\"MSA10\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"Dias_para_Rotura_Stock\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Dias para rotura de Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a métrica: Preslinear / med(Sellouts 10 dias)\n",
    "dfFinal['Dias_Duração_Linear'] = dfFinal[\"PRES_STOCK\"] / dfFinal[\"MSA10\"]\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"Dias_Duração_Linear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Adequação de Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coluna de adequação de stock\n",
    "\n",
    "\n",
    "dfFinal[\"Adequação\"]= np.where(dfFinal[\"CICLOS\"] > 1.1, \"Stock Suficiente\", \n",
    "                      np.where((dfFinal[\"CICLOS\"] <= 1.1) & (dfFinal[\"INTRANSIT\"]+dfFinal[\"EXPECTED\"]+dfFinal[\"STOCK\"]>=dfFinal[\"PRES_STOCK\"]), \"Stock Insuf c Forn Adequado\", \n",
    "                      np.where((dfFinal[\"CICLOS\"] <= 1.1) & (dfFinal[\"INTRANSIT\"]+dfFinal[\"EXPECTED\"]+dfFinal[\"STOCK\"]<dfFinal[\"PRES_STOCK\"]), \"Stock Insuf c Forn Desadequado\", \n",
    "                      \"\")))\n",
    "\n",
    "for i in diasMet:\n",
    "    dias(dfFinal, i, \"Adequação\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Smart é com semana e fim de semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# Define a function to calculate weekday and weekend counts\n",
    "def calculate_weekday_weekend_counts(date):\n",
    "    weekday_count = 0\n",
    "    weekend_count = 0\n",
    "    \n",
    "    for _ in range(5):\n",
    "        if date.weekday() < 4:  # Monday to Thursday\n",
    "            weekday_count += 1\n",
    "        else:  # Friday to Sunday\n",
    "            weekend_count += 1\n",
    "        \n",
    "        date += timedelta(days=1)\n",
    "    \n",
    "    return pd.Series({\"CONTAGEM_SEMANA\": weekday_count, \"CONTAGEM_FIMSEMANA\": weekend_count})\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "dfFinal[[\"CONTAGEM_SEMANA\", \"CONTAGEM_FIMSEMANA\"]] = dfFinal[\"DATA\"].apply(calculate_weekday_weekend_counts)\n",
    "\n",
    "\n",
    "\n",
    "dfFinal[\"Balance_Smart_5_Dias_Antes\"] = ((\n",
    "    (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_fds'].transform(lambda x: x.rolling(window=30, min_periods=1).median())\n",
    "     * dfFinal['CONTAGEM_FIMSEMANA'])\n",
    "    +\n",
    "    (dfFinal.groupby(['DESC_ARTIGO', \"STORE\"])['SELLOUT_semana'].transform(lambda x: x.rolling(window=30, min_periods=1).median())\n",
    "     * dfFinal['CONTAGEM_SEMANA']))\n",
    "     / dfFinal[\"STK\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>Escrever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dias certos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ficheiro Dia\n",
    "dfEscreverDia = dfFinal[dfFinal.DATA == dfFinal.DATA.unique().tolist()[-1]].copy()\n",
    "\n",
    "#Ficheiro Mês\n",
    "dfEscreverMes = dfFinal[dfFinal.DATA >= dfClick.DATA.unique().tolist()[-30]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Passar para csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clickhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clickhouse_connect\n",
    "from clickhouse_driver import Client\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estabelecer a base a ser lida\n",
    "\n",
    "baseDay = dfEscreverDia\n",
    "baseMonth = dfEscreverMes\n",
    "\n",
    "tabelaDay = \"Day\"\n",
    "tabelaMonth = \"Month\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<clickhouse_connect.driver.summary.QuerySummary at 0x1defa82a5f0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "client = clickhouse_connect.get_client(host='e28fluocjc.europe-west4.gcp.clickhouse.cloud', \n",
    "                                       port=8443, \n",
    "                                       username='default', \n",
    "                                       password='N_Mx30OFTC1hN',\n",
    "                                       database='Delta')\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "baseDay['DATA']= pd.to_datetime(baseDay['DATA'], format='%Y-%m-%d')  # Passar para datetime\n",
    "new_columns = [unidecode(col) for col in baseDay.columns]           # Tirar acentos e afins\n",
    "baseDay.columns = new_columns                                       # Aplicar alterações da linha anterior\n",
    "###\n",
    "\n",
    "# Tipos de dados\n",
    "data = [\"DATA\"]\n",
    "texto = [col for col in baseDay.columns if baseDay[col].dtype == 'object']\n",
    "inteiros = [col for col in baseDay.columns if baseDay[col].dtype in ['int64', 'int32']]\n",
    "floats = [col for col in baseDay.columns if baseDay[col].dtype == 'float64']\n",
    "\n",
    "\n",
    "# Só floats é que permitem missing values\n",
    "for col_name in inteiros:\n",
    "    baseDay[col_name] = baseDay[col_name].astype(float)\n",
    "# Missing values em strings estragam tudo\n",
    "baseDay[texto] = baseDay[texto].fillna(\"-\")\n",
    "\n",
    "\n",
    "def schema(lista, tipo):\n",
    "    result_list = [f\"{element} {tipo}\" for element in lista]\n",
    "    return result_list\n",
    "\n",
    "data1 = schema(data, \"Date\")\n",
    "texto1 = schema(texto, \"String\")\n",
    "inteiros1 = schema(inteiros, \"Float64\")\n",
    "floats1 = schema(floats, \"Float64\")\n",
    "total = tuple(data1 + texto1 + inteiros1 + floats1)\n",
    "\n",
    "schema = ', '.join([column.replace(\"'\", \"\") for column in total])\n",
    "\n",
    "# Split the input string by commas\n",
    "parts = schema.split(', ')\n",
    "# Process each part and wrap the first word in double quotes\n",
    "output_parts = []\n",
    "for part in parts:\n",
    "    words = part.split()\n",
    "    if words:\n",
    "        first_word = words[0]\n",
    "        remaining_words = ' '.join(words[1:])\n",
    "        output_part = f'\"{first_word}\" {remaining_words}'\n",
    "        output_parts.append(output_part)\n",
    "# Join the modified parts back into a string\n",
    "schema = ', '.join(output_parts)\n",
    "\n",
    "\n",
    "\n",
    "# Eliminar tabela no CH\n",
    "client.command(f'DROP TABLE IF EXISTS {tabela}')\n",
    "\n",
    "# Criar tabela no CH\n",
    "client.command(f'''\n",
    "    CREATE TABLE IF NOT EXISTS {tabela} (\n",
    "        {schema}\n",
    "        ) ENGINE = MergeTree\n",
    "        ORDER BY (DATA)\n",
    "''')\n",
    "\n",
    "client.insert_df(tabela, baseDay, column_names=baseDay.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA</th>\n",
       "      <th>EAN</th>\n",
       "      <th>DESC_ARTIGO</th>\n",
       "      <th>STORE</th>\n",
       "      <th>STORE_NAME</th>\n",
       "      <th>INTRANSIT</th>\n",
       "      <th>EXPECTED</th>\n",
       "      <th>PRES_STOCK</th>\n",
       "      <th>STOCK</th>\n",
       "      <th>STOCK_1_Dias_Antes</th>\n",
       "      <th>...</th>\n",
       "      <th>Balance_Optimized_5_Dias_Antes</th>\n",
       "      <th>Balance_Mediano</th>\n",
       "      <th>Balance_Mediano_4_Dias_Antes</th>\n",
       "      <th>Balance_Mediano_5_Dias_Antes</th>\n",
       "      <th>Balance_Liberal</th>\n",
       "      <th>Balance_Liberal_4_Dias_Antes</th>\n",
       "      <th>Balance_Liberal_5_Dias_Antes</th>\n",
       "      <th>Balance_Conservador</th>\n",
       "      <th>Balance_Conservador_4_Dias_Antes</th>\n",
       "      <th>Balance_Conservador_5_Dias_Antes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>5.609060e+12</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>5.609060e+12</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>5.609060e+12</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>5.609060e+12</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>5.609060e+12</td>\n",
       "      <td>BEBIDA CEREAIS DELTA C/20%CAFE FR 200G</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CNT MATOSINHOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATA           EAN                             DESC_ARTIGO  STORE  \\\n",
       "0 2022-01-01  5.609060e+12  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G    1.0   \n",
       "1 2022-01-02  5.609060e+12  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G    1.0   \n",
       "2 2022-01-03  5.609060e+12  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G    1.0   \n",
       "3 2022-01-04  5.609060e+12  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G    1.0   \n",
       "4 2022-01-05  5.609060e+12  BEBIDA CEREAIS DELTA C/20%CAFE FR 200G    1.0   \n",
       "\n",
       "       STORE_NAME  INTRANSIT  EXPECTED  PRES_STOCK  STOCK  STOCK_1_Dias_Antes  \\\n",
       "0  CNT MATOSINHOS        0.0      48.0       120.0  151.0               151.0   \n",
       "1  CNT MATOSINHOS        0.0      48.0       120.0  137.0               151.0   \n",
       "2  CNT MATOSINHOS       48.0       0.0       120.0  175.0               137.0   \n",
       "3  CNT MATOSINHOS        0.0       0.0       120.0  162.0               175.0   \n",
       "4  CNT MATOSINHOS        0.0      48.0       120.0  195.0               162.0   \n",
       "\n",
       "   ...  Balance_Optimized_5_Dias_Antes  Balance_Mediano  \\\n",
       "0  ...                             NaN              NaN   \n",
       "1  ...                             NaN              NaN   \n",
       "2  ...                             NaN              NaN   \n",
       "3  ...                             NaN              NaN   \n",
       "4  ...                             NaN              NaN   \n",
       "\n",
       "   Balance_Mediano_4_Dias_Antes  Balance_Mediano_5_Dias_Antes  \\\n",
       "0                           NaN                           NaN   \n",
       "1                           NaN                           NaN   \n",
       "2                           NaN                           NaN   \n",
       "3                           NaN                           NaN   \n",
       "4                           NaN                           NaN   \n",
       "\n",
       "   Balance_Liberal  Balance_Liberal_4_Dias_Antes  \\\n",
       "0              NaN                           NaN   \n",
       "1              NaN                           NaN   \n",
       "2              NaN                           NaN   \n",
       "3              NaN                           NaN   \n",
       "4              NaN                           NaN   \n",
       "\n",
       "   Balance_Liberal_5_Dias_Antes  Balance_Conservador  \\\n",
       "0                           NaN                  NaN   \n",
       "1                           NaN                  NaN   \n",
       "2                           NaN                  NaN   \n",
       "3                           NaN                  NaN   \n",
       "4                           NaN                  NaN   \n",
       "\n",
       "   Balance_Conservador_4_Dias_Antes  Balance_Conservador_5_Dias_Antes  \n",
       "0                               NaN                               NaN  \n",
       "1                               NaN                               NaN  \n",
       "2                               NaN                               NaN  \n",
       "3                               NaN                               NaN  \n",
       "4                               NaN                               NaN  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFinal.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
