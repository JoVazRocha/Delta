{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumo do código\n",
    "\n",
    "### Código que gera o ficheiro OUT_DataFusion_Long\n",
    "---\n",
    "O objectivo é receber dados dos Ninjas e da Delta e devolver um conjunto de métricas para estudar o comportamento de vários produtos em diversas lojas. \n",
    "\n",
    "---\n",
    "- Inputs\n",
    "\n",
    "> __Dados dos ninjas__ em formato Wide\n",
    "> - 1's e 0's consoante a presença e ausência do produto, Data e Loja\n",
    "\n",
    "> __Dados da Delta__ em formato Long\n",
    "> - Stocks e trânsito, Sellout dia anterior\n",
    "\n",
    "- Outputs\n",
    "\n",
    "> __Ficheiro Long__ (artigos na mesma coluna)\n",
    "\n",
    "> __Métricas novas:__\n",
    "> - Sinal\n",
    "> - Ciclos e Adequação de Stock\n",
    "> - Restock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def escrever_excel(dataFrame, nomeFicheiro):\n",
    "    dataFrame.to_excel('D:\\\\B&N Dados\\\\Delta\\\\Padrão\\\\Padrão_xx_2023\\\\%s.xlsx' %nomeFicheiro, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # `Ninjas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Info Ninja\n",
    "\n",
    "dfNinjas=pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Padrão\\\\Padrão_xx_2023\\\\1_Ninjas_Limpo.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Definir variáveis importantes\n",
    "> - Se houver um ficheiro com os produtos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler ficheiro para dataframe\n",
    "df_produtos = pd.read_csv('D:\\\\B&N Dados\\\\Delta\\\\Padrão\\\\Padrão_xx_2023\\\\produtos.txt', header=None)\n",
    "\n",
    "# Passar para uma lista\n",
    "produtos = df_produtos[0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Se se quiser usar o primeiro e o último produtos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Nomes de entrada\n",
    "x= input(\"Primeiro produto: \")                # CAFÉ DELTA Q MYTHIQ 80CAP\n",
    "y= input(\"Último produto: \")                  # Delta Cafés Mistura + café 200grs\n",
    "\n",
    "# Passar para uma lista\n",
    "produtos = dfNinjas.columns[dfNinjas.columns.get_loc(x): dfNinjas.columns.get_loc(y)+1].tolist()\n",
    "resto = dfNinjas.columns.difference(produtos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reposição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler o ficheiro com os nomes das lojas que fazem reposição\n",
    "dfRepos=pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Reposição_Sonae_Código.xlsx\")\n",
    "\n",
    "# Criar coluna que determina quais lojas têm reposição\n",
    "dfNinjas['Reposição'] = [1 if val in dfRepos['STORE'].values else 0 for val in dfNinjas['STORE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Vendedor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler ficheiro\n",
    "dfVendedor=pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Vendedor.xlsx\", sheet_name = \"Lista Lojas Sonae\")\n",
    "dfVendedor = dfVendedor.rename(columns={\"Cód. Loja\":\"STORE\"})\n",
    "\n",
    "# Criar coluna de reposição\n",
    "dfNinjas = pd.merge(dfNinjas, dfVendedor[[\"STORE\",\"Vendedor\"]], how=\"left\", on = \"STORE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # `Delta`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler o ficheiro long com Stocks e Fornecimento\n",
    "dfDelta=pd.read_excel(\"D:\\\\B&N Dados\\\\Delta\\\\Padrão\\\\Padrão_xx_2023\\\\2_Delta_Limpo.xlsx\", sheet_name=\"Sheet1\")\n",
    "\n",
    "# Renomear\n",
    "dfDelta = dfDelta.rename(columns={\"STORE_NAME\":\"Loja\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que tem cada ficheiro:\n",
    "\n",
    "### **dfDelta**:\n",
    "1. Formato long (produtos numa única coluna \"DESC_ARTIGO\")\n",
    "2. Stocks, em Trânsito, Esperado, Linear, sellout dia anterior\t\n",
    "\n",
    "\n",
    "### **dfNinjas**:\n",
    "1. Formato wide (cada produto numa coluna)\n",
    "2. Presença de produto em linear para cada produto\n",
    "\n",
    "### **dfSonae**:\n",
    "1. Formato wide\n",
    "2. Sellouts, Vendedores, Reposição\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:green\"><u> Mergir</u> </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resto = dfNinjas.columns.difference(produtos)\n",
    "# Passar ficheiro ninjas para long\n",
    "dfNinjasLong = dfNinjas.melt(id_vars=resto, value_vars=produtos, var_name='DESC_ARTIGO', value_name='NinjaInfo')\n",
    "\n",
    "\n",
    "#Mergir\n",
    "dfMeio = pd.merge(dfNinjasLong, dfDelta, how=\"left\", on = [\"DATA\",\"STORE\", \"DESC_ARTIGO\"]) \n",
    "dfMeio = dfMeio.drop(columns=[\"Loja\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal=dfMeio.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:green\">Fim</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Já temos DataFrame com:\n",
    "- Informação Ninjas\n",
    "- Informação Stocks, Linear, Intransit e Expected\n",
    "- Informação Sellouts, Vendedor, Reposição\n",
    "\n",
    "## Fazer:\n",
    "\n",
    "- Rotura\n",
    "- Sinal -> Avaliação da informação ninja vs stock\n",
    "- Ciclos\n",
    "- Adequação de Stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> STK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir coluna de STK (soma de stocks com stock em trânsito)\n",
    "\n",
    "dfFinal[\"STK\"] = dfFinal[\"STOCK\"] + dfFinal[\"INTRANSIT\"] + dfFinal[\"EXPECTED\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Balanço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir coluna de Balanço (razão entre sellout e stock total)\n",
    "\n",
    "dfFinal[\"Balanço\"] = dfFinal[\"SELLOUT\"] / dfFinal[\"STK\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Rotura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir coluna de rotura (se stock menor ou igual a 0 e existe Linear)\n",
    "\n",
    "dfFinal[\"ROTURA\"] = np.where((dfFinal[\"STOCK\"] <= 0) & (dfFinal[\"PRES_STOCK\"] > 0), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Sinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorias possíveis\n",
    "mapping = {1: \"Presente com Stock\",\n",
    "           2: \"Ausente com Stock\",\n",
    "           3: \"Presente sem Stock\",\n",
    "           4: \"Ausente sem Stock\",\n",
    "           5: \"Presente sem Registo\",\n",
    "           6: \"Ausente sem Registo\"}\n",
    "\n",
    "# Definir coluna de sinal\n",
    "dfFinal[\"Sinal\"] = np.where((dfFinal[\"STOCK\"] > 0) & (dfFinal[\"NinjaInfo\"] == 1), 1,\n",
    "                     np.where((dfFinal[\"STOCK\"] > 0) & (dfFinal[\"NinjaInfo\"] == 0), 2,\n",
    "                     np.where((dfFinal[\"STOCK\"] <= 0) & (dfFinal[\"NinjaInfo\"] == 1), 3,\n",
    "                     np.where((dfFinal[\"STOCK\"] <= 0) & (dfFinal[\"NinjaInfo\"] == 0), 4,\n",
    "                     np.where((dfFinal[\"STOCK\"].isna()) & (dfFinal[\"NinjaInfo\"] == 1), 5,\n",
    "                     np.where((dfFinal[\"STOCK\"].isna()) & (dfFinal[\"NinjaInfo\"] == 0), 6,\n",
    "                     np.nan))))))\n",
    "\n",
    "# Substituir números pelas expressões escolhidas\n",
    "dfFinal[\"Sinal\"] = dfFinal[\"Sinal\"].map(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ciclos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Ciclos\"]=dfFinal[\"STOCK\"]/dfFinal[\"PRES_STOCK\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Adequação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Adequação\"] = np.where(\n",
    "                        dfFinal[\"Ciclos\"] > 1.1,\n",
    "                        \"Stock Suficiente\",\n",
    "                       np.where(\n",
    "                        (dfFinal[\"Ciclos\"] <= 1.1) & (dfFinal[\"INTRANSIT\"] + dfFinal[\"EXPECTED\"] + dfFinal[\"STOCK\"] >= dfFinal[\"PRES_STOCK\"]),\n",
    "                        \"Stock Insuf c Forn Adequado\",\n",
    "                       np.where(\n",
    "                        (dfFinal[\"Ciclos\"] <= 1.1) & (dfFinal[\"INTRANSIT\"] + dfFinal[\"EXPECTED\"] + dfFinal[\"STOCK\"] < dfFinal[\"PRES_STOCK\"]),\n",
    "                        \"Stock Insuf c Forn Desadequado\",\n",
    "                        \"\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Dias para a rotura de stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Dias_para_Rotura\"] = dfFinal[\"STOCK\"] / dfFinal[\"SELLOUT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Dias para a rotura de prateleira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal[\"Dias_para_Rotura_Linear\"] = dfFinal[\"PRES_STOCK\"] / dfFinal[\"SELLOUT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Roturas Linear (Ninjas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Quando detectada rotura\n",
    "dfFinal[\"Roturas_reais_dia\"] = dfFinal[dfFinal['NinjaInfo'] == 0].groupby(['STORE', 'DATA', 'DESC_ARTIGO'])['NinjaInfo'].transform('count')\n",
    "#0 Quando não há rotura\n",
    "dfFinal[\"Roturas_reais_dia\"] = np.where(dfFinal['NinjaInfo'] == 1, 0, dfFinal['Roturas_reais_dia'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acabamos com:\n",
    "- Informação Ninjas\n",
    "- Informação Stocks, Linear, Intransit e Expected\n",
    "- Informação Sellouts, Vendedor, Reposição\n",
    "- Rotura\n",
    "- Sinal \n",
    "- Ciclos\n",
    "- Adequação de Stock\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reomear e organizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escrever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0: DATA',\n",
       " '1: Hora',\n",
       " '2: Altura_do_Dia',\n",
       " '3: Dia',\n",
       " '4: Semana',\n",
       " '5: DESC_ARTIGO',\n",
       " '6: EAN',\n",
       " '7: Nome da Loja',\n",
       " '8: STORE',\n",
       " '9: NinjaInfo',\n",
       " '10: SOH',\n",
       " '11: INTRANSIT',\n",
       " '12: EXPECTED',\n",
       " '13: PRES_STOCK',\n",
       " '14: Dia_Actual',\n",
       " '15: 1_Dia_Antes',\n",
       " '16: Reposição',\n",
       " '17: Rotura',\n",
       " '18: Sinal',\n",
       " '19: Ciclos',\n",
       " '20: Adequação',\n",
       " '21: Restock',\n",
       " '22: Roturas_reais_dia',\n",
       " '23: Roturas_Consecutivas_dia',\n",
       " '24: Roturas_Consecutivas_fds',\n",
       " '25: Proporção_Consecutivas_dia',\n",
       " '26: Std_Consecutivas_dia',\n",
       " '27: Proporção_Consecutivas_fds',\n",
       " '28: Std_Consecutivas_fds']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_columns = dfFinalCorr.columns.tolist()\n",
    "indexed_columns = [f\"{index}: {column}\" for index, column in enumerate(df_columns)]\n",
    "indexed_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinalCorr = dfFinal.iloc[:, np.r_[0,4,3,15,14,2,7,5,1,6,8:14,16:29]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "escrever_excel(dfFinalCorr, \"OUT_1_DataFusion\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
